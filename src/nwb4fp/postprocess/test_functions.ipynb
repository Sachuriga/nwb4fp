{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 1,
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   "id": "b224f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'Q:\\sachuriga\\Sachuriga_Python/quattrocolo-nwb4fp\\src')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   "id": "2c13820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachur\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pickle import TRUE\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.postprocessing as post\n",
    "from nwb4fp.postprocess.Get_positions import load_positions,load_positions_h5,test_positions_h5\n",
    "from nwb4fp.postprocess.get_potential_merge import get_potential_merge\n",
    "from spikeinterface.preprocessing import (bandpass_filter,\n",
    "                                           common_reference,\n",
    "                                           whiten)\n",
<<<<<<< HEAD
    "import spikeinterface.exporters as sex\n",
    "\n",
    "from nwb4fp.preprocess.down_sample_lfp import down_sample_lfp_test\n",
    "\n",
=======
    "\n",
    "\n",
    "from nwb4fp.preprocess.down_sample_lfp import down_sample_lfp_test\n",
    "import spikeinterface.exporters as sex\n",
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
    "import spikeinterface.qualitymetrics as sqm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from nwb4fp.postprocess.extract_wf import wf4unim,divide_wf\n",
    "import spikeinterface.preprocessing as spre\n",
    "import numpy as np\n",
    "\n",
    "from spikeinterface.extractors.neoextractors.openephys import OpenEphysBinaryRecordingExtractor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": null,
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   "id": "c1cb483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Before mannual search the stream_name. Auto search result is Record Node 102#OE_FPGA_Acquisition_Board-101.Rhythm Data\n",
      "ASSY-236-F - cambridgeneurotech - 64ch - 6shanks\n",
      "removed ['CH12' 'CH18']\n",
=======
      "Before mannual search the stream_name. Auto search result is Record Node 101#Acquisition_Board-100.Rhythm Data\n",
      "ASSY-236-F - cambridgeneurotech - 64ch - 6shanks\n",
      "removed ['CH17']\n",
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
      "get times for raw sortsNone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7302/7302 [00:05<00:00, 1416.48it/s]\n",
=======
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 8505/8505 [00:08<00:00, 1038.80it/s] \n",
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\core\\recording_tools.py:786: UserWarning: get_noise_levels(recording, num_chunks_per_segment=20) is deprecated\n",
      "Now, you need to use get_noise_levels(recording, random_slices_kwargs=dict(num_chunks_per_segment=20, chunk_size=1000))\n",
      "Please read get_random_recording_slices() documentation for more options.\n",
      "  warnings.warn(msg)\n",
<<<<<<< HEAD
      "noise_level (workers: 12 processes): 100%|██████████| 20/20 [00:01<00:00, 10.36it/s]\n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7302/7302 [00:10<00:00, 689.41it/s] \n"
=======
      "noise_level (workers: 12 processes): 100%|██████████| 20/20 [00:04<00:00,  4.24it/s]\n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 8505/8505 [00:16<00:00, 530.35it/s]\n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing potential merge...\n",
      "\n",
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n",
<<<<<<< HEAD
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7302/7302 [00:04<00:00, 1691.51it/s] \n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7302/7302 [00:08<00:00, 833.87it/s] \n"
=======
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 8505/8505 [00:05<00:00, 1669.42it/s] \n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 8505/8505 [00:12<00:00, 693.77it/s] \n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing potential merge...\n",
      "\n",
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n",
<<<<<<< HEAD
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7302/7302 [00:04<00:00, 1630.62it/s]\n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7302/7302 [00:07<00:00, 1007.30it/s]\n"
=======
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 8505/8505 [00:05<00:00, 1619.89it/s] \n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 8505/8505 [00:12<00:00, 678.33it/s] \n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing potential merge...\n",
      "\n",
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "temp_folder = r\"C:/temp_lfp\"\n",
    "path = r\"S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k_manual/\"\n",
    "memory_size = 128\n",
    "global_job_kwargs = dict(n_jobs=32, total_memory=fr\"{memory_size}G\",mp_context= \"spawn\",progress_bar=True)\n",
    "si.set_global_job_kwargs(**global_job_kwargs)\n",
    "\n",
    "sorting = se.read_phy(folder_path=path, load_all_cluster_properties=True,exclude_cluster_groups = [\"noise\", \"mua\"])\n",
    "temp_path = path.split(\"_phy\")\n",
    "raw_path = temp_path[0]\n",
    "#stream_name = 'Record Node 101#OE_FPGA_Acquisition_Board-100.Rhythm Data'\n",
    "stream_name  = OpenEphysBinaryRecordingExtractor(raw_path,stream_id='0').get_streams(raw_path)[0][0]\n",
    "print(fr\"Before mannual search the stream_name. Auto search result is {stream_name}\")\n",
    "try:\n",
    "    recording = se.read_openephys(raw_path, stream_name=stream_name, load_sync_timestamps=True)\n",
    "except AssertionError:\n",
    "    try:\n",
    "        stream_name = 'Record Node 102#OE_FPGA_Acquisition_Board-101.Rhythm Data'\n",
    "        recording = se.read_openephys(raw_path, stream_name=stream_name, load_sync_timestamps=True)\n",
    "    except AssertionError:\n",
    "        stream_name = 'Record Node 101#Acquisition_Board-100.Rhythm Data'\n",
    "        recording = se.read_openephys(raw_path, stream_name=stream_name, load_sync_timestamps=True)\n",
    "\n",
    "import probeinterface as pi\n",
    "\n",
    "# from probeinterface import plotting\n",
    "manufacturer = 'cambridgeneurotech'\n",
    "probe_name = 'ASSY-236-F'\n",
    "probe = pi.get_probe(manufacturer, probe_name)\n",
    "print(probe)\n",
    "# probe.wiring_to_device('cambridgeneurotech_mini-amp-64')\n",
    "# map channels to device indices\n",
    "mapping_to_device = [\n",
    "    # connector J2 TOP\n",
    "    41, 39, 38, 37, 35, 34, 33, 32, 29, 30, 28, 26, 25, 24, 22, 20,\n",
    "    46, 45, 44, 43, 42, 40, 36, 31, 27, 23, 21, 18, 19, 17, 16, 14,\n",
    "    # connector J1 BOTTOM\n",
    "    55, 53, 54, 52, 51, 50, 49, 48, 47, 15, 13, 12, 11, 9, 10, 8,\n",
    "    63, 62, 61, 60, 59, 58, 57, 56, 7, 6, 5, 4, 3, 2, 1, 0\n",
    "]\n",
    "\n",
    "probe.set_device_channel_indices(mapping_to_device)\n",
    "probe.to_dataframe(complete=True).loc[:, [\"contact_ids\", \"shank_ids\", \"device_channel_indices\"]]\n",
    "probegroup = pi.ProbeGroup()\n",
    "probegroup.add_probe(probe)\n",
    "\n",
    "pi.write_prb(f\"{probe_name}.prb\", probegroup, group_mode=\"by_shank\")\n",
    "recording_prb = recording.set_probe(probe, group_mode=\"by_shank\")\n",
    "rec = bandpass_filter(recording_prb, freq_min=600, freq_max=8000)\n",
    "bad_channel_ids, channel_labels = spre.detect_bad_channels(recording_prb, method='coherence+psd',n_neighbors = 11)\n",
    "print(fr\"removed {bad_channel_ids}\")\n",
    "recording_good_ch= rec.remove_channels(bad_channel_ids)\n",
    "#recording_good_channels_f = spre.interpolate_bad_channels(rec,bad_channel_ids)\n",
    "\n",
    "rec_save = common_reference(recording_good_ch, reference='global', operator='median')\n",
    "rec_w = whiten(rec_save, int_scale=200, mode='local', radius_um=100.0)\n",
    "sorting.set_property(key='group', values = sorting.get_property(\"channel_group\"))\n",
    "print(f\"get times for raw sorts{sorting.get_times()}\")\n",
    "## step to analyzer\n",
    "GLOBAL_KWARGS = dict(n_jobs=16, total_memory=fr\"{memory_size}G\", progress_bar=True, mp_context= \"spawn\", chunk_size=5000, chunk_duration=\"1s\")\n",
    "si.set_global_job_kwargs(**GLOBAL_KWARGS)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(sorting=sorting, recording=rec_w, format='memory', folder=fr\"{temp_folder}\",overwrite=True)\n",
    "we1 = analyzer.compute(\"random_spikes\",\"waveforms\")\n",
    "we1 = analyzer.compute(\"noise_levels\")\n",
    "we1 = analyzer.compute(\"templates\")\n",
    "#get potential merging sorting objects\n",
    "print(\"processing potential merge...\\n\")\n",
    "## Step to creating analyzers\n",
    "unit_locations = analyzer.compute(input=\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "unit_ids = sorting.unit_ids\n",
    "phy_TRD = Path(path + \"_manual_reports\")\n",
    "sex.export_report(sorting_analyzer = analyzer, output_folder=phy_TRD, remove_if_exists=True)\n",
    "\n",
    "\n",
    "analyzer1 = si.create_sorting_analyzer(sorting=sorting, recording=rec_w, format='memory', folder=fr\"{temp_folder}\",overwrite=True)\n",
    "analyzer1.compute(\"random_spikes\",\"waveforms\")\n",
    "analyzer1.compute(\"noise_levels\")\n",
    "analyzer1.compute(\"templates\")\n",
    "#get potential merging sorting objects\n",
    "print(\"processing potential merge...\\n\")\n",
    "## Step to creating analyzers\n",
    "unit_locations = analyzer1.compute(input=\"unit_locations\", method=\"center_of_mass\")\n",
    "unit_ids = sorting.unit_ids\n",
    "phy_TRD = Path(path + \"_manual_mass\")\n",
    "sex.export_report(sorting_analyzer = analyzer1, output_folder=phy_TRD, remove_if_exists=True)\n",
    "\n",
    "\n",
    "analyzer2 = si.create_sorting_analyzer(sorting=sorting, recording=rec_w, format='memory', folder=fr\"{temp_folder}\",overwrite=True)\n",
    "analyzer2.compute(\"random_spikes\",\"waveforms\")\n",
    "analyzer2.compute(\"noise_levels\")\n",
    "analyzer2.compute(\"templates\")\n",
    "#get potential merging sorting objects\n",
    "print(\"processing potential merge...\\n\")\n",
    "## Step to creating analyzers\n",
    "unit_locations = analyzer2.compute(input=\"unit_locations\", method=\"grid_convolution\")\n",
    "unit_ids = sorting.unit_ids\n",
    "phy_TRD = Path(path + \"_manual_reports_grid\")\n",
    "sex.export_report(sorting_analyzer = analyzer2, output_folder=phy_TRD, remove_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   "id": "c2ae8fa2",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging step_Before mannual search the stream_name. Auto search result is Record Node 102#OE_FPGA_Acquisition_Board-101.Rhythm Data\n",
      "LFP downsampling steps. Auto search result is Record Node 102#OE_FPGA_Acquisition_Board-101.Rhythm Data\n",
      "ASSY-236-F - cambridgeneurotech - 64ch - 6shanks\n",
      "bad channels are [11, 17]\n",
      "bad channels labels ['good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'dead' 'good' 'good' 'good' 'good' 'good' 'dead' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good' 'good'\n",
      " 'good' 'good' 'good' 'good']\n",
      "['CH1' 'CH2' 'CH3' 'CH4' 'CH5' 'CH6' 'CH7' 'CH8' 'CH9' 'CH10' 'CH11'\n",
      " 'CH12' 'CH13' 'CH14' 'CH15' 'CH16' 'CH17' 'CH18' 'CH19' 'CH20' 'CH21'\n",
      " 'CH22' 'CH23' 'CH24' 'CH25' 'CH26' 'CH27' 'CH28' 'CH29' 'CH30' 'CH31'\n",
      " 'CH32' 'CH33' 'CH34' 'CH35' 'CH36' 'CH37' 'CH38' 'CH39' 'CH40' 'CH41'\n",
      " 'CH42' 'CH43' 'CH44' 'CH45' 'CH46' 'CH47' 'CH48' 'CH49' 'CH50' 'CH51'\n",
      " 'CH52' 'CH53' 'CH54' 'CH55' 'CH56' 'CH57' 'CH58' 'CH59' 'CH60' 'CH61'\n",
      " 'CH62' 'CH63' 'CH64']\n",
      "processing lfp data...\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=12 - samples_per_chunk=5,000 - chunk_memory=1.22 MiB - total_memory=14.65 MiB - chunk_duration=4.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (workers: 12 processes): 100%|██████████| 305/305 [02:40<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing lfp data...\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=12 - samples_per_chunk=5,000 - chunk_memory=625.00 KiB - total_memory=7.32 MiB - chunk_duration=4.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (workers: 12 processes): 100%|██████████| 305/305 [00:36<00:00,  8.26it/s]\n"
=======
     "ename": "ValueError",
     "evalue": "S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k is not a valid Open Ephys binary folder. No 'structure.oebin' files were found in sub-folders.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSachuriga\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEphys_Recording\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k_manual\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m raw_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSachuriga\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEphys_Recording\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdown_sample_lfp_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mraw_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mQ:\\sachuriga\\Sachuriga_Python\\quattrocolo-nwb4fp\\src\\nwb4fp\\preprocess\\down_sample_lfp.py:114\u001b[0m, in \u001b[0;36mdown_sample_lfp_test\u001b[1;34m(file_path, raw_path)\u001b[0m\n\u001b[0;32m    112\u001b[0m si\u001b[38;5;241m.\u001b[39mset_global_job_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mGLOBAL_KWARGS)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m#raw_path = r'S:\\Sachuriga/Ephys_Recording/CR_CA1/65409/65409_2023-12-04_15-42-35_A'\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m stream_name  \u001b[38;5;241m=\u001b[39m \u001b[43mOpenEphysBinaryRecordingExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstream_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_streams(raw_path)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerging step_Before mannual search the stream_name. Auto search result is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m record_node \u001b[38;5;241m=\u001b[39m stream_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\openephys.py:158\u001b[0m, in \u001b[0;36mOpenEphysBinaryRecordingExtractor.__init__\u001b[1;34m(self, folder_path, load_sync_channel, load_sync_timestamps, experiment_names, stream_id, stream_name, block_index, all_annotations)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    148\u001b[0m     folder_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m     all_annotations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    156\u001b[0m ):\n\u001b[0;32m    157\u001b[0m     neo_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_to_neo_kwargs(folder_path, load_sync_channel, experiment_names)\n\u001b[1;32m--> 158\u001b[0m     \u001b[43mNeoBaseRecordingExtractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mall_annotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_annotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mneo_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# get streams to find correct probe\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     stream_names, stream_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_streams(folder_path, experiment_names)\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:188\u001b[0m, in \u001b[0;36mNeoBaseRecordingExtractor.__init__\u001b[1;34m(self, stream_id, stream_name, block_index, all_annotations, use_names_as_ids, **neo_kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     stream_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    Initialize a NeoBaseRecordingExtractor instance.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     \u001b[43m_NeoBaseExtractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mneo_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(all_annotations\u001b[38;5;241m=\u001b[39mall_annotations)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m block_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:27\u001b[0m, in \u001b[0;36m_NeoBaseExtractor.__init__\u001b[1;34m(self, block_index, **neo_kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, block_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs):\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Avoids double initiation of the neo reader if it was already done in the __init__ of the child class\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo_reader\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneo_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_neo_io_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNeoRawIOClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mneo_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneo_reader\u001b[38;5;241m.\u001b[39mblock_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis dataset is multi-block. Spikeinterface can load one block at a time. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to select the block to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:66\u001b[0m, in \u001b[0;36m_NeoBaseExtractor.get_neo_io_reader\u001b[1;34m(cls, raw_class, **neo_kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m neoIOclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(rawio_module, raw_class)\n\u001b[0;32m     65\u001b[0m neo_reader \u001b[38;5;241m=\u001b[39m neoIOclass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mneo_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neo_reader\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\neo\\rawio\\baserawio.py:185\u001b[0m, in \u001b[0;36mBaseRawIO.parse_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m    This must parse the file header to get all stuff for fast use later on.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_stream_signal_channel_characteristics()\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_header_parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\neo\\rawio\\openephysbinaryrawio.py:80\u001b[0m, in \u001b[0;36mOpenEphysBinaryRawIO._parse_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 80\u001b[0m     folder_structure, all_streams, nb_block, nb_segment_per_block, possible_experiments \u001b[38;5;241m=\u001b[39m \u001b[43mexplore_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_names\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     check_folder_consistency(folder_structure, possible_experiments)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_structure \u001b[38;5;241m=\u001b[39m folder_structure\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\neo\\rawio\\openephysbinaryrawio.py:602\u001b[0m, in \u001b[0;36mexplore_folder\u001b[1;34m(dirname, experiment_names)\u001b[0m\n\u001b[0;32m    600\u001b[0m record_node_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(folder_structure\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(record_node_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid Open Ephys binary folder. No \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstructure.oebin\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles were found in sub-folders.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m recording_node \u001b[38;5;241m=\u001b[39m folder_structure[record_node_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    608\u001b[0m \u001b[38;5;66;03m# nb_block needs to be consistent across record nodes. Use the first one\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k is not a valid Open Ephys binary folder. No 'structure.oebin' files were found in sub-folders."
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    }
   ],
   "source": [
    "from nwb4fp.preprocess.down_sample_lfp import down_sample_lfp_test\n",
    "temp_folder = r\"C:/temp_lfp\"\n",
    "path = r\"S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k_manual\"\n",
<<<<<<< HEAD
    "raw_path = r\"S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C\"\n",
=======
    "raw_path = r\"S:\\Sachuriga\\Ephys_Recording\\CR_CA1/65091/65091_2023-08-01_15-16-29_C_phy_k\"\n",
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
    "down_sample_lfp_test(path,raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c0d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phy_TRD = Path(path + \"_manual_reports\")\n",
    "sex.export_report(sorting_analyzer = analyzer, output_folder=phy_TRD, remove_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": null,
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   "id": "f73f7342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7302/7302 [00:04<00:00, 1669.72it/s]\n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7302/7302 [00:07<00:00, 981.76it/s] \n"
=======
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7705/7705 [00:04<00:00, 1620.36it/s] \n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7705/7705 [00:10<00:00, 756.83it/s] \n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing potential merge...\n",
<<<<<<< HEAD
      "\n"
=======
      "\n",
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
     ]
    }
   ],
   "source": [
    "analyzer1 = si.create_sorting_analyzer(sorting=sorting, recording=rec_w, format='memory', folder=fr\"{temp_folder}\",overwrite=True)\n",
    "analyzer1.compute(\"random_spikes\",\"waveforms\")\n",
    "analyzer1.compute(\"noise_levels\")\n",
    "analyzer1.compute(\"templates\")\n",
    "#get potential merging sorting objects\n",
    "print(\"processing potential merge...\\n\")\n",
    "## Step to creating analyzers\n",
    "unit_locations = analyzer1.compute(input=\"unit_locations\", method=\"center_of_mass\")\n",
    "unit_ids = sorting.unit_ids\n",
    "phy_TRD = Path(path + \"_manual_mass\")\n",
<<<<<<< HEAD
    "#sex.export_report(sorting_analyzer = analyzer1, output_folder=phy_TRD, remove_if_exists=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba709346",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m unit_loc_mt\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(unit_ids))\n\u001b[0;32m      3\u001b[0m unit_loc_mt\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(unit_locations\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit_locations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mT))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munit_loc_mt.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_loc_mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\numpy\\lib\\npyio.py:545\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m--> 545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[0;32m    547\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "unit_loc_mt=[]\n",
    "unit_loc_mt.append(list(unit_ids))\n",
    "unit_loc_mt.append(list(unit_locations.data['unit_locations'].T))\n",
    "np.save('unit_loc_mt.npy', unit_loc_mt) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b0951a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 10, 11, 25, 29, 2, 3, 9, 14, 18, 20, 33, 30],\n",
       " [array([207.16263843, 202.82946004, 209.52251038, 203.74349041,\n",
       "         613.09690519, 604.14581035,  11.69277035,   5.23775735,\n",
       "         211.61895249, 407.45807776, 406.45500903, 403.39049644,\n",
       "         809.82154077, 605.02105199]),\n",
       "  array([ 47.12129809,  54.47187184,  55.11142142,  41.66844636,\n",
       "          34.90147152,  14.78394834,  32.78757262,  23.93706088,\n",
       "          54.14107789,  62.0514003 ,  33.5406549 ,  35.22035646,\n",
       "          52.89583812, 105.09188348])]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_loc_mt"
=======
    "sex.export_report(sorting_analyzer = analyzer1, output_folder=phy_TRD, remove_if_exists=True)\n"
>>>>>>> 816e0c07fb882e40df907d8fc611ee2746b5bee4
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6279e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimate_sparsity (workers: 12 processes): 100%|██████████| 7705/7705 [00:04<00:00, 1641.66it/s] \n",
      "estimate_templates_with_accumulator (workers: 12 processes): 100%|██████████| 7705/7705 [00:10<00:00, 765.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing potential merge...\n",
      "\n",
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'S:\\\\Sachuriga\\\\Ephys_Recording\\\\CR_CA1\\\\65588\\\\65588_2024-03-04_15-44-37_A_phy_k_manual\\\\_manual_reports_grid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m unit_ids \u001b[38;5;241m=\u001b[39m sorting\u001b[38;5;241m.\u001b[39munit_ids\n\u001b[0;32m     10\u001b[0m phy_TRD \u001b[38;5;241m=\u001b[39m Path(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_manual_reports_grid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43msex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorting_analyzer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manalyzer2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphy_TRD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_if_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\exporters\\report.py:98\u001b[0m, in \u001b[0;36mexport_report\u001b[1;34m(sorting_analyzer, output_folder, remove_if_exists, format, show_figures, peak_sign, force_computation, **job_kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 98\u001b[0m \u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# unit list\u001b[39;00m\n\u001b[0;32m    101\u001b[0m units \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39munit_ids)  \u001b[38;5;66;03m#  , columns=['max_on_channel_id', 'amplitude'])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\pathlib.py:1116\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;28mself\u001b[39m, mode)\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'S:\\\\Sachuriga\\\\Ephys_Recording\\\\CR_CA1\\\\65588\\\\65588_2024-03-04_15-44-37_A_phy_k_manual\\\\_manual_reports_grid'"
     ]
    }
   ],
   "source": [
    "analyzer2 = si.create_sorting_analyzer(sorting=sorting, recording=rec_w, format='memory', folder=fr\"{temp_folder}\",overwrite=True)\n",
    "analyzer2.compute(\"random_spikes\",\"waveforms\")\n",
    "analyzer2.compute(\"noise_levels\")\n",
    "analyzer2.compute(\"templates\")\n",
    "#get potential merging sorting objects\n",
    "print(\"processing potential merge...\\n\")\n",
    "## Step to creating analyzers\n",
    "unit_locations = analyzer2.compute(input=\"unit_locations\", method=\"grid_convolution\")\n",
    "unit_ids = sorting.unit_ids\n",
    "phy_TRD = Path(path + \"_manual_reports_grid\")\n",
    "sex.export_report(sorting_analyzer = analyzer2, output_folder=phy_TRD, remove_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b2d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_report(): spike_amplitudes will not be exported. Use sorting_analyzer.compute('spike_amplitudes') if you want to include them.\n",
      "export_report(): quality metrics will not be exported. Use sorting_analyzer.compute('quality_metrics') if you want to include them.\n",
      "export_report(): correlograms will not be exported. Use sorting_anlyzer.compute('correlograms') if you want to include them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sachur\\AppData\\Local\\anaconda3\\envs\\test1\\Lib\\site-packages\\spikeinterface\\widgets\\unit_waveforms.py:182: UserWarning: templates_percentile_shading can only be used if the 'waveforms' extension is available. Settimg templates_percentile_shading to None.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "sex.export_report(sorting_analyzer = analyzer2, output_folder=phy_TRD, remove_if_exists=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
