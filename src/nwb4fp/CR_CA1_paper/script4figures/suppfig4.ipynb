{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae138062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6955bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你的数据是一个Series\n",
    "df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_py = df_good[df_good['buzaki_py_cell_type']=='pyramidal']\n",
    "df = df_py\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\"]\n",
    "\n",
    "\n",
    "for session in sessions:\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "\n",
    "df_con_deep = control_df[control_df['sub_population']==\"deep\"].reset_index(drop=True)['Information_content_rate']\n",
    "df_con_superficial = control_df[control_df['sub_population']==\"superficial\"].reset_index(drop=True)['Information_content_rate']\n",
    "df_exp_deep = exp_df[exp_df['sub_population']==\"deep\"].reset_index(drop=True)['Information_content_rate']\n",
    "df_exp_superficial = exp_df[exp_df['sub_population']==\"superficial\"].reset_index(drop=True)['Information_content_rate']\n",
    "\n",
    "def group_indices_by_step(df_col, step=0.075):\n",
    "    used_indices = set()\n",
    "    result = []\n",
    "    values = df_col.copy()\n",
    "    max_val = values.max()\n",
    "\n",
    "    while len(used_indices) < len(values):\n",
    "        remaining = values[~values.index.isin(used_indices)]\n",
    "        if remaining.empty:\n",
    "            break\n",
    "\n",
    "        current_group = []\n",
    "        current_val = remaining.min()\n",
    "        current_idx = remaining.idxmin()\n",
    "        current_group.append(current_idx)\n",
    "        used_indices.add(current_idx)\n",
    "\n",
    "        while True:\n",
    "            target_val = current_val + step\n",
    "            remaining = values[~values.index.isin(used_indices)]\n",
    "            if remaining.empty:\n",
    "                break\n",
    "\n",
    "            # 找到大于等于 target_val 的值中最接近 target_val 的那个\n",
    "            diffs = remaining - target_val\n",
    "            diffs = diffs[diffs >= 0]\n",
    "            if diffs.empty:\n",
    "                break\n",
    "\n",
    "            next_idx = diffs.idxmin()\n",
    "            current_val = values[next_idx]\n",
    "            current_group.append(next_idx)\n",
    "            used_indices.add(next_idx)\n",
    "\n",
    "        result.append(current_group)\n",
    "\n",
    "    return result\n",
    "results_con_deep = group_indices_by_step(df_con_deep)\n",
    "results_con_superficial = group_indices_by_step(df_con_superficial)\n",
    "results_exp_deep = group_indices_by_step(df_exp_deep)\n",
    "results_exp_superficial = group_indices_by_step(df_exp_superficial)\n",
    "\n",
    "def plot_rate_map_panel(ax, results_con, df, sublayer=\"deep\", group = \"control\", map_color='jet'):\n",
    "    i_row = 0\n",
    "    base_y = 0.35\n",
    "    y_step = 0.5\n",
    "\n",
    "    for indices in results_con:\n",
    "        y_coord = base_y + (i_row * y_step)\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            values = [df[i] for i in indices]\n",
    "            num_ratemaps = len(indices)\n",
    "            for i, (idx, value) in enumerate(zip(indices, values)):\n",
    "                img_path = fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\{group}/{sublayer}/{map_color}/{idx}.png\"\n",
    "                plot_image_at_xy(ax, img_path, value, y_coord, max_size=0.014)\n",
    "        i_row += 1\n",
    "    ax.set_xlim(0, 4.5)\n",
    "    ax.set_ylim(0, 3.5)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.tick_params(axis='x', labelsize=10.5)\n",
    "    ax.set_xlabel(\"Information Content Rate (spikes / bit)\", fontsize=10.5)\n",
    "    ax.set_yticks([])\n",
    "    ax.vlines(x=[1, 2, 3, 4], ymin=0, ymax=8.5, colors='grey', linestyles='dashed', linewidth=3)\n",
    "    \n",
    "# Function to load and plot an image with dynamic size adjustment\n",
    "def plot_image_at_xy(ax, img_path, x, y, max_size=0.09):\n",
    "    if os.path.exists(img_path):\n",
    "        img = plt.imread(img_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        aspect_ratio = img_width / img_height\n",
    "\n",
    "        # Calculate zoom based on max_size and aspect ratio\n",
    "        trans = ax.transData\n",
    "        fig = ax.get_figure()\n",
    "        dpi = fig.dpi\n",
    "        xlim = ax.get_xlim()\n",
    "        data_width = xlim[1] - xlim[0]\n",
    "        bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axes_width_pixels = bbox.width * dpi\n",
    "        pixels_per_data = axes_width_pixels / data_width\n",
    "        size_pixels = max_size * pixels_per_data\n",
    "        # zoom = size_pixels / max(img_width, img_height / aspect_ratio)\n",
    "\n",
    "        # imagebox = OffsetImage(img, zoom=zoom)\n",
    "        # ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0)\n",
    "        # ax.add_artist(ab)\n",
    "\n",
    "\n",
    "        zoom = 0.017  # Adjust this value to control ratemap size\n",
    "        imagebox = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0)\n",
    "        ax.add_artist(ab)\n",
    "        return ab\n",
    "    else:\n",
    "        print(f\"Image {img_path} not found\")\n",
    "        return None\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp, shapiro, ttest_ind, mannwhitneyu\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import numpy as np\n",
    "\n",
    "# Data loading\n",
    "folder_path = r\"S:\\Sachuriga\\file_with_table\\ripple_ch\"\n",
    "\n",
    "def get_pkl_files(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    pkl_files = [f for f in all_files if f.endswith(\"withDLC.pkl\")]\n",
    "    return pkl_files\n",
    "\n",
    "target_prefixes_control = ['65165', '65091', '63383', '66539', '65622']\n",
    "target_prefixes_exp = ['65588', '63385', '66538', '66537', '66922']\n",
    "pkl_files = get_pkl_files(folder_path)\n",
    "\n",
    "# # Variables to analyze\n",
    "# variables = ['Information_content_rate', 'Sparsity', 'Field_size', 'Averate_rate', 'bursting_index', 'Selectivity']\n",
    "# titles = ['Information content rate\\n (spikes/bit)', 'Sparsity', 'Max Field Size', 'Firing Rate (Hz)', 'Bursting iondex', 'Selectivity']\n",
    "\n",
    "\n",
    "variables = ['amplitude_median','half_width','peak_to_valley','peak_trough_ratio', 'recovery_slope', 'repolarization_slope']\n",
    "titles = ['Amplitude median (mV)', 'Half width (ms)', 'Peak to valley (ms)', \n",
    "            'peak trough ratio', 'Recovery slope', 'repolarization_slope']\n",
    "        \n",
    "all_dfs = []\n",
    "scale_transefers = [0.001,1000,1000,1,0.00001,0.000001]\n",
    "\n",
    "\n",
    "# Process each pickle file\n",
    "for file in pkl_files:\n",
    "    try:\n",
    "        df = pd.read_pickle(os.path.join(folder_path, file))\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    #df = df[(df['cell_type'] == \"pyramidal\") & (df['session'] == \"A\")]\n",
    "\n",
    "    df = df[(df['buzaki_py_cell_type'] == \"pyramidal\") & (df['session'] == \"A\")  & (df['unit_quality'] == \"good\")]\n",
    "    #df = df[df['session'] == \"A\"]\n",
    "    if df.empty:\n",
    "        print(f\"Warning: File {file} has no pyramidal cells\")\n",
    "        continue\n",
    "    try:\n",
    "        animal_id = df['animal_id'].iloc[0]\n",
    "    except KeyError:\n",
    "        print(f\"Warning: File {file} does not have 'animal_id' column\")\n",
    "        continue\n",
    "    if any(animal_id.startswith(prefix) for prefix in target_prefixes_control):\n",
    "        df['group_ani'] = 'control'\n",
    "    elif any(animal_id.startswith(prefix) for prefix in target_prefixes_exp):\n",
    "        df['group_ani'] = 'exp'\n",
    "    else:\n",
    "        print(f\"Warning: animal_id {animal_id} does not match any group\")\n",
    "        continue\n",
    "    all_dfs.append(df)\n",
    "\n",
    "y_pos = \"addjust y r2\"\n",
    "combined_df=[]\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df['depth'] = combined_df[y_pos].apply(lambda x: 'deep' if x > 0 else 'superficial')\n",
    "combined_df['group_depth'] = combined_df['group_ani'] + '_' + combined_df['depth']\n",
    "\n",
    "# Convert variables to numeric and handle invalid values\n",
    "for var in variables:\n",
    "    combined_df[var] = pd.to_numeric(combined_df[var], errors='coerce')\n",
    "    if combined_df[var].isna().any():\n",
    "        print(f\"Warning: {var} contains NaN values after conversion to numeric\")\n",
    "\n",
    "# Function to test normality and choose test\n",
    "def choose_stat_test(data1, data2, var_name, group1_name, group2_name):\n",
    "    # Drop NaN values and ensure numeric\n",
    "    data1 = data1.dropna()\n",
    "    data2 = data2.dropna()\n",
    "    \n",
    "    # Check for non-numeric values\n",
    "    if not np.issubdtype(data1.dtype, np.number) or not np.issubdtype(data2.dtype, np.number):\n",
    "        print(f\"Error: Non-numeric data detected in {var_name} for {group1_name} or {group2_name}\")\n",
    "        print(f\"{group1_name} dtype: {data1.dtype}, {group2_name} dtype: {data2.dtype}\")\n",
    "        print(f\"{group1_name} sample: {data1.head()}\")\n",
    "        print(f\"{group2_name} sample: {data2.head()}\")\n",
    "        return \"Invalid\", np.nan, np.nan\n",
    "\n",
    "    # Check if data is empty after dropping NaNs\n",
    "    if len(data1) == 0 or len(data2) == 0:\n",
    "        print(f\"Error: Empty dataset for {var_name} in {group1_name} or {group2_name} after dropping NaNs\")\n",
    "        return \"Empty\", np.nan, np.nan\n",
    "\n",
    "    # Perform Shapiro-Wilk test for normality\n",
    "    stat1, p1 = shapiro(data1)\n",
    "    stat2, p2 = shapiro(data2)\n",
    "    \n",
    "    print(f\"{var_name} - {group1_name} Shapiro-Wilk: p={p1:.4f}\")\n",
    "    print(f\"{var_name} - {group2_name} Shapiro-Wilk: p={p2:.4f}\")\n",
    "    \n",
    "    # Choose test based on normality\n",
    "    if p1 > 0.05 and p2 > 0.05:  # Both are normal\n",
    "        print(f\"{var_name} - Using t-test (both groups normal)\")\n",
    "        stat, p = ttest_ind(data1, data2, equal_var=True)  # Assuming equal variances\n",
    "        test_name = \"t-test\"\n",
    "    else:\n",
    "        print(f\"{var_name} - Using Mann-Whitney U test (non-normal distribution)\")\n",
    "        stat, p = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "        test_name = \"Mann-Whitney U\"\n",
    "    \n",
    "    return test_name, stat, p\n",
    "\n",
    "group_ani = []\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "for index, row in combined_df.iterrows():\n",
    "    if str(row['matlab_animal']) in control_ids:\n",
    "        group_ani.append(\"control\")\n",
    "    else:\n",
    "        group_ani.append(\"exp\")\n",
    "combined_df['group_ani']=None\n",
    "combined_df['group_ani']=group_ani\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a57a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "control_df_deep = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'deep')]\n",
    "exp_df_deep = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'deep')]\n",
    "\n",
    "\n",
    "# # Control_superficial vs. Exp_superficial\n",
    "# control_superficial = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'superficial')][var]\n",
    "# exp_superficial = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'superficial')][var]\n",
    "\n",
    "control_df_place = control_df_deep[(control_df_deep['h_0_place_cell'] == 1) & \n",
    "                                (control_df_deep['Information_content_rate'] >= 1.68) & \n",
    "                                (control_df_deep['matlab_maxfsize'] >= 20) ]\n",
    "exp_df_place = exp_df_deep[(exp_df_deep['h_0_place_cell'] == 1) & \n",
    "                        (exp_df_deep['Information_content_rate'] >= 1.68) & \n",
    "                        (exp_df_deep['matlab_maxfsize'] >= 20) ]\n",
    "\n",
    "# Calculate numbers for pie charts\n",
    "control_place_deep = len(control_df_place)\n",
    "control_non_place_deep = len(control_df_deep) - control_place_deep\n",
    "exp_place_deep = len(exp_df_place)\n",
    "exp_non_place_deep = len(exp_df_deep) - exp_place_deep\n",
    "result = binomtest(exp_place_deep, len(exp_df_deep), p=(control_place_deep /len(control_df_deep)), alternative='less')\n",
    "p_value_deep = result.pvalue\n",
    "p_value_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a9313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "control_df_superficial = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'superficial')]\n",
    "exp_df_superficial = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'superficial')]\n",
    "\n",
    "# # Control_superficial vs. Exp_superficial\n",
    "# control_superficial = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'superficial')][var]\n",
    "# exp_superficial = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'superficial')][var]\n",
    "\n",
    "control_df_place_superficial = control_df_superficial[(control_df_superficial['h_0_place_cell'] == 1) & \n",
    "                                (control_df_superficial['Information_content_rate'] >= 1.68) & \n",
    "                                (control_df_superficial['matlab_maxfsize'] >= 20)]\n",
    "exp_df_place_superficial = exp_df_superficial[(exp_df_superficial['h_0_place_cell'] == 1) & \n",
    "                        (exp_df_superficial['Information_content_rate'] >= 1.68) & \n",
    "                        (exp_df_superficial['matlab_maxfsize'] >= 20) ]\n",
    "\n",
    "# Calculate numbers for pie charts\n",
    "control_place_superficial = len(control_df_place_superficial)\n",
    "control_non_place_superficial = len(control_df_superficial) - control_place_superficial\n",
    "exp_place_superficial = len(exp_df_place_superficial)\n",
    "exp_non_place_superficial = len(exp_df_superficial) - exp_place_superficial\n",
    "result = binomtest(exp_place_superficial, len(exp_df_superficial), p=(control_place_superficial /len(control_df_superficial)), alternative='less')\n",
    "p_value_superficial = result.pvalue\n",
    "p_value_superficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb846076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Create figure with high DPI\n",
    "fig = plt.figure(figsize=(7.2, 3.6), dpi=1200, constrained_layout=False)  # Switch to manual layout for fine control\n",
    "plt.rcParams.update({'font.size': 8})  # Keep font size at 8 for consistency\n",
    "\n",
    "# Define GridSpec with adjusted ratios\n",
    "gs = gridspec.GridSpec(2, 6, height_ratios=[1, 1], width_ratios=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6])\n",
    "\n",
    "# Adjust global padding parameters to prevent overlap\n",
    "plt.rcParams.update({\n",
    "    'axes.labelpad': 4,  # Increase label padding for better spacing\n",
    "    'ytick.major.pad': 2,  # Increase y-tick padding\n",
    "    'xtick.major.pad': 4,  # Increase x-tick padding\n",
    "    'ytick.major.size': 2,\n",
    "    'xtick.major.size': 2\n",
    "})\n",
    "\n",
    "linewidth = 0.5\n",
    "\n",
    "# Define axes for the first row (deep)\n",
    "ax4_1 = fig.add_subplot(gs[0, 0])\n",
    "ax4_2 = fig.add_subplot(gs[0, 1])\n",
    "ax4_3 = fig.add_subplot(gs[0, 2])\n",
    "ax4_4 = fig.add_subplot(gs[0, 3])\n",
    "ax4_5 = fig.add_subplot(gs[0, 4])\n",
    "ax4_6 = fig.add_subplot(gs[0, 5])\n",
    "axis_deep = [ax4_1, ax4_2, ax4_3, ax4_4, ax4_5, ax4_6]\n",
    "\n",
    "# Define axes for the second row (superficial)\n",
    "ax7_1 = fig.add_subplot(gs[1, 0])\n",
    "ax7_2 = fig.add_subplot(gs[1, 1])\n",
    "ax7_3 = fig.add_subplot(gs[1, 2])\n",
    "ax7_4 = fig.add_subplot(gs[1, 3])\n",
    "ax7_5 = fig.add_subplot(gs[1, 4])\n",
    "ax7_6 = fig.add_subplot(gs[1, 5])\n",
    "axis_superficial = [ax7_1, ax7_2, ax7_3, ax7_4, ax7_5, ax7_6]\n",
    "\n",
    "# Define axis limits dictionary\n",
    "xlim_dict = {\n",
    "    'half_width': (None, 0.0003),\n",
    "    'recovery_slope': (None, None),\n",
    "    'repolarization_slope': None,\n",
    "    'mean_firing_rate': (0, 8),\n",
    "    'peak_trough_ratio': (None, None),\n",
    "    'peak_to_valley': (None, 0.001),\n",
    "    'bursting_index': (-1, 1),\n",
    "    'mean_inter_spike_interval': (0.1, 8),\n",
    "    'amplitude_median': None,\n",
    "    'mode_inter_spike_interval': (0, 0.02)\n",
    "}\n",
    "\n",
    "palette = {'control': 'blue', 'exp': 'red'}\n",
    "\n",
    "# Plot for deep layer\n",
    "for i, (var, title) in enumerate(zip(variables, titles)):\n",
    "    # Data for deep layer\n",
    "    control_deep = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'deep')][var]\n",
    "    exp_deep = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'deep')][var]\n",
    "    \n",
    "    # Statistical test for deep\n",
    "    test_name_deep, stat_deep, p_valued = choose_stat_test(control_deep, exp_deep, title, \"Control_deep\", \"Exp_deep\")\n",
    "    print(f\"{title} - Control_deep vs. Exp_deep ({test_name_deep}): statistic={stat_deep:.3f}, p-value={p_valued:.4f}\")\n",
    "    \n",
    "    # KS test\n",
    "    ks_stat_deep, p_value_d = ks_2samp(control_deep, exp_deep, nan_policy='omit')\n",
    "\n",
    "    # Violin and swarm plots\n",
    "    sns.violinplot(\n",
    "        data=combined_df[combined_df['depth'] == 'deep'], x='group_ani', y=var, ax=axis_deep[i],\n",
    "        hue='group_ani', inner=\"quartiles\", palette=palette, cut=0, edgecolor='white'\n",
    "    )\n",
    "    sns.swarmplot(\n",
    "        data=combined_df[combined_df['depth'] == 'deep'], x='group_ani', y=var, ax=axis_deep[i], size=0.5,\n",
    "        hue='group_ani', palette=palette, alpha=1, legend=False\n",
    "    )\n",
    "    \n",
    "    # Axis customization\n",
    "    axis_deep[i].set_xlabel('')  # Remove x-label to reduce clutter\n",
    "    axis_deep[i].set_ylabel(title, fontsize=8, labelpad=5)  # Set y-label with padding\n",
    "    axis_deep[i].legend().set_visible(False)\n",
    "    axis_deep[i].spines['top'].set_visible(False)\n",
    "    axis_deep[i].spines['right'].set_visible(False)\n",
    "    axis_deep[i].set_ylim(xlim_dict[var])\n",
    "    axis_deep[i].set_xticklabels(['CRs +', 'CRs -'], rotation=-45, ha='left', fontsize=7)  # Rotate and align labels\n",
    "    \n",
    "    # Add significance bar\n",
    "    y_max = axis_deep[i].get_ylim()[1]\n",
    "    bar_height = y_max * 0.1\n",
    "    x_positions = [0, 1]\n",
    "    p_val = p_valued\n",
    "    if 0.01 < p_val < 0.05:\n",
    "        axis_deep[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_deep[i].text(0.5, y_max + bar_height * 1.1, '*', ha='center', va='bottom', fontsize=8)\n",
    "    elif 0.001 < p_val <= 0.01:\n",
    "        axis_deep[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_deep[i].text(0.5, y_max + bar_height * 1.1, '**', ha='center', va='bottom', fontsize=8)\n",
    "    elif p_val <= 0.001:\n",
    "        axis_deep[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_deep[i].text(0.5, y_max + bar_height * 1.1, '***', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Plot for superficial layer\n",
    "for i, (var, title) in enumerate(zip(variables, titles)):\n",
    "    # Data for superficial layer\n",
    "    control_superficial = combined_df[(combined_df['group_ani'] == 'control') & (combined_df['depth'] == 'superficial')][var]\n",
    "    exp_superficial = combined_df[(combined_df['group_ani'] == 'exp') & (combined_df['depth'] == 'superficial')][var]\n",
    "    \n",
    "    # Statistical test for superficial\n",
    "    test_name_sup, stat_sup, p_values = choose_stat_test(control_superficial, exp_superficial, title, \"Control_superficial\", \"Exp_superficial\")\n",
    "    print(f\"{title} - Control_superficial vs. Exp_superficial ({test_name_sup}): statistic={stat_sup:.3f}, p-value={p_values:.4f}\")\n",
    "    \n",
    "    # KS test\n",
    "    ks_stat_sup, p_values_s = ks_2samp(control_superficial, exp_superficial, nan_policy='omit')\n",
    "\n",
    "    # Violin and swarm plots\n",
    "    sns.violinplot(\n",
    "        data=combined_df[combined_df['depth'] == 'superficial'], x='group_ani', y=var, ax=axis_superficial[i],\n",
    "        hue='group_ani', inner=\"quartiles\", palette=palette, cut=0, edgecolor='white'\n",
    "    )\n",
    "    sns.swarmplot(\n",
    "        data=combined_df[combined_df['depth'] == 'superficial'], x='group_ani', y=var, ax=axis_superficial[i], size=0.5,\n",
    "        hue='group_ani', palette=palette, alpha=1, legend=False\n",
    "    )\n",
    "    \n",
    "    # Axis customization\n",
    "    axis_superficial[i].set_xlabel('')  # Remove x-label to reduce clutter\n",
    "    axis_superficial[i].set_ylabel(title, fontsize=8, labelpad=5)  # Set y-label with padding\n",
    "    axis_superficial[i].legend().set_visible(False)\n",
    "    axis_superficial[i].spines['top'].set_visible(False)\n",
    "    axis_superficial[i].spines['right'].set_visible(False)\n",
    "    axis_superficial[i].set_ylim(xlim_dict[var])\n",
    "    axis_superficial[i].set_xticklabels(['CRs +', 'CRs -'], rotation=-45, ha='left', fontsize=7)  # Rotate and align labels\n",
    "    \n",
    "    # Add significance bar\n",
    "    y_max = axis_superficial[i].get_ylim()[1]\n",
    "    bar_height = y_max * 0.1\n",
    "    x_positions = [0, 1]\n",
    "    p_val = p_values\n",
    "    if 0.01 < p_val < 0.05:\n",
    "        axis_superficial[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_superficial[i].text(0.5, y_max + bar_height * 1.1, '*', ha='center', va='bottom', fontsize=8)\n",
    "    elif 0.001 < p_val <= 0.01:\n",
    "        axis_superficial[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_superficial[i].text(0.5, y_max + bar_height * 1.1, '**', ha='center', va='bottom', fontsize=8)\n",
    "    elif p_val <= 0.001:\n",
    "        axis_superficial[i].plot(x_positions, [y_max + bar_height, y_max + bar_height], color='black', lw=1.5)\n",
    "        axis_superficial[i].text(0.5, y_max + bar_height * 1.1, '***', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.subplots_adjust(top=0.95, bottom=0.15, left=0.1, right=0.95, hspace=0.4, wspace=0.3)  # Increased hspace and wspace\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
