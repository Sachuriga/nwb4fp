{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"Q:/sachuriga/Sachuriga_Python/quattrocolo-nwb4fp/src\")\n",
    "import pandas as pd\n",
    "from neurochat.nc_data import NData\n",
    "from neurochat.nc_spike import NSpike\n",
    "from neurochat.nc_spatial import NSpatial\n",
    "import neurochat.nc_plot as nc_plot\n",
    "from neurochat.nc_lfp import NLfp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import sys\n",
    "import nwb4fp.analyses.maps as mapp\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap_ax,plot_path\n",
    "from nwb4fp.analyses.fields import separate_fields_by_laplace, separate_fields_by_dilation,find_peaks,separate_fields_by_laplace_of_gaussian,calculate_field_centers,distance_to_edge_function, remove_fields_by_area, map_pass_to_unit_circle,which_field,compute_crossings\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from nwb4fp.analyses import maps\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,unit_location_ch,calculate_spatial_coherence,calculate_spatial_stability,coherence, find_run_indices\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1858842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "## add new measurements to pkl\n",
    "df_loaded_cell_type = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speed score collections\n",
    "\n",
    "u_files = np.unique(df_loaded_cell_type['session_id'])\n",
    "base_folder = r\"S:\\Sachuriga\\nwb\\test4neo\"\n",
    "\n",
    "speed_scores = []\n",
    "FR = []\n",
    "shuffle_speed_scores = []\n",
    "speed_collect = []\n",
    "speed_t = []\n",
    "\n",
    "for file in u_files:\n",
    "    temp_nwb =  nap.load_file(fr'{base_folder}/{file}')\n",
    "    pkl = df_loaded_cell_type[df_loaded_cell_type['session_id']==file].copy().reset_index(drop=True)\n",
    "    units_data = temp_nwb['units']\n",
    "    units = units_data[units_data['unit_name'].isin(pkl['unit_name'])]\n",
    "    pos_cord = load_speed_fromNWB(temp_nwb['XY_mid_brain'])\n",
    "    t=pos_cord[:,0]\n",
    "    ## filter speed\n",
    "    raw_pos,combined_array, mask,speeds,smoothed_speed,filtered_speed = pos2speed(pos_cord[:,0], # times\n",
    "                                pos_cord[:,1], # x\n",
    "                                pos_cord[:,2], # y\n",
    "                                filter_speed=True, \n",
    "                                min_speed = 0.05)\n",
    "    dt = np.diff(t)\n",
    "    # Use scipy.stats.mode (scipy < 1.9)\n",
    "    mode_val = round(stats.mode(dt, keepdims=True).mode[0],2)\n",
    "\n",
    "    for i in units.index:\n",
    "        speed_t.append(t)\n",
    "\n",
    "        # --- Example data ---\n",
    "        # Simulated spike times (in seconds)\n",
    "        spike_times = units[i].index.values  # 500 spikes over 10 seconds\n",
    "\n",
    "        # Simulated frame times (e.g., 30 Hz video = frame every ~33.3 ms)\n",
    "        frame_rate = 1 / mode_val # Hz\n",
    "        frame_times = t  # From 0 to 10 seconds\n",
    "\n",
    "        # --- 1. Bin spike times into spike counts per frame interval ---\n",
    "        spike_counts, _ = np.histogram(spike_times, bins=frame_times)\n",
    "\n",
    "        # --- 2. Estimate dt (inter-frame interval) ---\n",
    "        dt = mode_val  # Should be ~1 / frame_rate\n",
    "\n",
    "        # --- 3. Create Gaussian smoothing kernel with sigma = 250 ms ---\n",
    "        sigma_ms = 100  # in milliseconds\n",
    "        sigma_samples = sigma_ms / 1000 / dt  # convert ms to samples\n",
    "\n",
    "        # --- 4. Smooth the spike counts to get firing rate (spikes/s) ---\n",
    "        firing_rate = gaussian_filter1d(spike_counts / dt, sigma=sigma_samples)\n",
    "\n",
    "        # --- Optional: plot the result ---\n",
    "        time_axis = frame_times[:-1] + dt / 2  # center of each bin\n",
    "        speed = smoothed_speed[:len(firing_rate)]  # make sure dimensions match\n",
    "\n",
    "        # --- Compute Pearson correlation ---\n",
    "        valid = ~np.isnan(firing_rate) & ~np.isnan(speed)\n",
    "        r, pval = pearsonr(firing_rate[valid], speed[valid])\n",
    "        speed_scores.append(r)\n",
    "        speed_collect.append(smoothed_speed)\n",
    "        FR.append(firing_rate)\n",
    "        temp_shuffle = []\n",
    "        shift_range=90\n",
    "\n",
    "        for ii in range(100):\n",
    "            # Random circular shift\n",
    "            max_shift_bins = int(shift_range / mode_val)\n",
    "            shift = np.random.randint(-max_shift_bins, max_shift_bins + 1)\n",
    "            firing_rate_shifted = np.roll(firing_rate, shift)\n",
    "            r_shuffle, pval = pearsonr(firing_rate_shifted[valid], speed[valid])\n",
    "            temp_shuffle.append(r_shuffle)\n",
    "        shuffle_speed_scores.append(temp_shuffle)\n",
    "\n",
    "df_loaded_cell_type['speed_scores']=None\n",
    "df_loaded_cell_type['speed_collect']=None\n",
    "df_loaded_cell_type['speed_fr']=None\n",
    "df_loaded_cell_type['shuffle_speed_scores']=None\n",
    "df_loaded_cell_type['speed']=None\n",
    "df_loaded_cell_type['speed_t'] = None\n",
    "\n",
    "df_loaded_cell_type['speed_t'] = speed_t\n",
    "df_loaded_cell_type['speed_scores']=speed_scores\n",
    "df_loaded_cell_type['speed_collect']=speed_collect\n",
    "df_loaded_cell_type['speed_fr']=FR\n",
    "df_loaded_cell_type['shuffle_speed_scores']=shuffle_speed_scores\n",
    "df_loaded_cell_type.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705e109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8043ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "\n",
    "df_int=None\n",
    "df_py=None\n",
    "units=df_loaded.reset_index(drop=True)\n",
    "scores=[]\n",
    "\n",
    "\n",
    "for i in units.index:\n",
    "    \n",
    "    t = units['speed_t'].loc[i]\n",
    "    dt= np.diff(t)\n",
    "    mode_val = round(stats.mode(dt, keepdims=True).mode[0],2)\n",
    "    # --- Example data ---\n",
    "    # Simulated spike times (in seconds)\n",
    "    spike_times = units['spike_times'].loc[i]  # 500 spikes over 10 seconds\n",
    "\n",
    "    # Simulated frame times (e.g., 30 Hz video = frame every ~33.3 ms)\n",
    "    frame_rate = 1 / mode_val # Hz\n",
    "    frame_times =  units['speed_t'].loc[i]  # From 0 to 10 seconds\n",
    "\n",
    "    # --- 1. Bin spike times into spike counts per frame interval ---\n",
    "    spike_counts, _ = np.histogram(spike_times, bins=frame_times)\n",
    "\n",
    "    # --- 2. Estimate dt (inter-frame interval) ---\n",
    "    dt = mode_val  # Should be ~1 / frame_rate\n",
    "\n",
    "    # --- 3. Create Gaussian smoothing kernel with sigma = 250 ms ---\n",
    "    sigma_ms = 250  # in milliseconds\n",
    "    sigma_samples = sigma_ms / 1000 / dt  # convert ms to samples\n",
    "\n",
    "    # --- 4. Smooth the spike counts to get firing rate (spikes/s) ---\n",
    "    firing_rate = gaussian_filter1d(spike_counts / dt, sigma=sigma_samples)\n",
    "    smoothed_speed = units['speed_collect'].loc[i]\n",
    "    # --- Optional: plot the result ---\n",
    "    time_axis = frame_times[:-1] + dt / 2  # center of each bin\n",
    "    speed = smoothed_speed[:len(firing_rate)]  # make sure dimensions match\n",
    "\n",
    "    # --- Compute Pearson correlation ---\n",
    "    valid = ~np.isnan(firing_rate) & ~np.isnan(speed)\n",
    "    r, pval = pearsonr(firing_rate[valid], speed[valid])\n",
    "    print(r)\n",
    "    scores.append(r)\n",
    "\n",
    "df_good = units\n",
    "units['speed_score']=None\n",
    "units['speed_score']=scores\n",
    "df_int = df_good[(df_good['buzaki_py_cell_type'] == \"narrow_spike_interneurons\") & (df_good['session'] == \"A\")]\n",
    "df_py = df_good[(df_good['buzaki_py_cell_type'] == \"pyramidal\") & (df_good['session'] == \"A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "scores=[]\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "units=df_loaded.reset_index(drop=True)\n",
    "fr = []\n",
    "for i in units.index:\n",
    "\n",
    "    t = units['speed_t'].loc[i]\n",
    "    dt= np.diff(t)\n",
    "    mode_val = round(stats.mode(dt, keepdims=True).mode[0],2)\n",
    "    # --- Example data ---\n",
    "    # Simulated spike times (in seconds)\n",
    "    spike_times = units['spike_times'].loc[i]  # 500 spikes over 10 seconds\n",
    "\n",
    "    # Simulated frame times (e.g., 30 Hz video = frame every ~33.3 ms)\n",
    "    frame_rate = 1 / mode_val # Hz\n",
    "    frame_times =  units['speed_t'].loc[i]  # From 0 to 10 seconds\n",
    "\n",
    "    # --- 1. Bin spike times into spike counts per frame interval ---\n",
    "    spike_counts, _ = np.histogram(spike_times, bins=frame_times)\n",
    "\n",
    "    # --- 2. Estimate dt (inter-frame interval) ---\n",
    "    dt = mode_val  # Should be ~1 / frame_rate\n",
    "\n",
    "    # --- 3. Create Gaussian smoothing kernel with sigma = 250 ms ---\n",
    "    sigma_ms = 250  # in milliseconds\n",
    "    sigma_samples = sigma_ms / 1000 / dt  # convert ms to samples\n",
    "\n",
    "    # --- 4. Smooth the spike counts to get firing rate (spikes/s) ---\n",
    "    firing_rate = gaussian_filter1d(spike_counts / dt, sigma=sigma_samples)\n",
    "    smoothed_speed = units['speed_collect'].loc[i]\n",
    "    # --- Optional: plot the result ---\n",
    "    time_axis = frame_times[:-1] + dt / 2  # center of each bin\n",
    "    speed = smoothed_speed[:len(firing_rate)]  # make sure dimensions match\n",
    "\n",
    "    # --- Compute Pearson correlation ---\n",
    "    valid = ~np.isnan(firing_rate) & ~np.isnan(speed)\n",
    "    r, pval = pearsonr(firing_rate[valid], speed[valid])\n",
    "    print(r)\n",
    "    scores.append(r)\n",
    "    fr.append(firing_rate)\n",
    "units['speed_score']=None\n",
    "units['speed_score']=scores\n",
    "\n",
    "units['speed_fr']=None\n",
    "units['speed_fr']=fr\n",
    "\n",
    "\n",
    "df_good=units\n",
    "df_good=df_good[df_good['session'] == \"A\"]\n",
    "df_int = df_good[(df_good['buzaki_py_cell_type'] == \"narrow_spike_interneurons\") & (df_good['session'] == \"A\")]\n",
    "df_py = df_good[(df_good['buzaki_py_cell_type'] == \"pyramidal\") & (df_good['session'] == \"A\")]\n",
    "\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "control_df = df_int[df_int['animal_id'].isin(control_ids)]\n",
    "exp_df = df_int[df_int['animal_id'].isin(exp_ids)]\n",
    "top_10_indices_exp = exp_df['speed_score'].nlargest(12).index.values\n",
    "top_10_indices_control = control_df['speed_score'].nlargest(12).index.values\n",
    "units.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_a  = df_good[(df_good['buzaki_cell_type']=='narrow_spike_interneurons') & (df_good['session'] == \"A\")]\n",
    "\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "\n",
    "# Separate into control and experimental groups\n",
    "control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "exp_df = df_a[df_a['animal_id'].isin(exp_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    [round(78/113,2)*100, round((113-78)/113,2)*100],  # Group 1: Dark blue (71.4%), Light blue (28.6%)\n",
    "    [round(64/94,2)*100, round((94-64)/94,2)*100],  # Group 2: Dark blue (71.1%), Light blue (28.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(64/94,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e420ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats  # For Gaussian smoothing (placeholder)\n",
    "from numpy import quantile  # For quantile calculation\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(7.2, 8), dpi=2400)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "gs = gridspec.GridSpec(6, 6, height_ratios=[.8, .8, .8, .8, 1, 1], width_ratios=[0.8, 0.8, 0.8, 0.8, 0.8, 0.8])  # First row taller\n",
    "plt.rcParams.update({\n",
    "    'axes.labelpad': -0.1,\n",
    "    'ytick.major.pad': -0.1,\n",
    "    'xtick.major.pad': -0.1,\n",
    "    'ytick.major.size': 2,\n",
    "    'xtick.major.size': 2\n",
    "})\n",
    "\n",
    "ax1_1 = fig.add_subplot(gs[0, 0])\n",
    "ax1_2 = fig.add_subplot(gs[0, 1])\n",
    "ax1_3 = fig.add_subplot(gs[0, 2])\n",
    "ax1_4 = fig.add_subplot(gs[0, 3])\n",
    "ax1_5 = fig.add_subplot(gs[0, 4])\n",
    "ax1_6 = fig.add_subplot(gs[0, 5])\n",
    "\n",
    "ax2_1 = fig.add_subplot(gs[1, 0])\n",
    "ax2_2 = fig.add_subplot(gs[1, 1])\n",
    "ax2_3 = fig.add_subplot(gs[1, 2])\n",
    "ax2_4 = fig.add_subplot(gs[1, 3])\n",
    "ax2_5 = fig.add_subplot(gs[1, 4])\n",
    "ax2_6 = fig.add_subplot(gs[1, 5])\n",
    "\n",
    "ax3_1 = fig.add_subplot(gs[2, 0])\n",
    "ax3_2 = fig.add_subplot(gs[2, 1])\n",
    "ax3_3 = fig.add_subplot(gs[2, 2])\n",
    "ax3_4 = fig.add_subplot(gs[2, 3])\n",
    "ax3_5 = fig.add_subplot(gs[2, 4])\n",
    "ax3_6 = fig.add_subplot(gs[2, 5])\n",
    "\n",
    "ax4_1 = fig.add_subplot(gs[3, 0])\n",
    "ax4_2 = fig.add_subplot(gs[3, 1])\n",
    "ax4_3 = fig.add_subplot(gs[3, 2])\n",
    "ax4_4 = fig.add_subplot(gs[3, 3])\n",
    "ax4_5 = fig.add_subplot(gs[3, 4])\n",
    "ax4_6 = fig.add_subplot(gs[3, 5])\n",
    "\n",
    "\n",
    "ax5_1 = fig.add_subplot(gs[4, 0])\n",
    "flattened_list = [item for sublist in df_int['shuffle_speed_scores'] for item in sublist]\n",
    "counts, bin_edges = np.histogram(flattened_list, bins=200,density=True)\n",
    "fractions = counts / np.sum(counts)\n",
    "ax5_1.stairs(counts , bin_edges, color='red')\n",
    "\n",
    "counts_real, bin_edges_real = np.histogram(df_good['speed_score'], bins=100,density=True)\n",
    "fractions_real = counts_real / np.sum(counts_real)\n",
    "ax5_1.stairs(counts_real , bin_edges_real, color='black')\n",
    "ax5_1.spines['top'].set_visible(False)\n",
    "ax5_1.spines['right'].set_visible(False)\n",
    "ax5_1.spines['bottom'].set_visible(True)\n",
    "ax5_1.spines['left'].set_visible(True)\n",
    "y_max = ax5_1.get_ylim()[1]\n",
    "bar_height = y_max * 0.1\n",
    "ax5_1.text(-0.6, y_max * 1.1, f'Shuffled data', color='red',fontsize=4)\n",
    "ax5_1.text(-0.6, y_max * 1.05, f'All units from CA1', color='black',fontsize=4)\n",
    "ax5_1.axvline(x=0.3, color='red', linestyle='--', linewidth=1)\n",
    "ax5_1.axvline(x=-0.3, color='red', linestyle='--', linewidth=1)\n",
    "ax5_1.set_xlabel('Speed score')\n",
    "ax5_1.set_ylabel('Density')\n",
    "\n",
    "\n",
    "ax5_2 = fig.add_subplot(gs[4, 1])\n",
    "\n",
    "counts, bin_edges = np.histogram(df_int['speed_score'], bins=50,density=True)\n",
    "fractions = counts / np.sum(counts)\n",
    "ax5_2.stairs(counts , bin_edges, color='red')\n",
    "\n",
    "counts_real, bin_edges_real = np.histogram(df_py['speed_score'], bins=50,density=True)\n",
    "fractions_real = counts_real / np.sum(counts_real)\n",
    "ax5_2.stairs(counts_real , bin_edges_real, color='black')\n",
    "ax5_2.spines['top'].set_visible(False)\n",
    "ax5_2.spines['right'].set_visible(False)\n",
    "ax5_2.spines['bottom'].set_visible(True)\n",
    "ax5_2.spines['left'].set_visible(True)\n",
    "y_max = ax5_2.get_ylim()[1]\n",
    "bar_height = y_max * 0.1\n",
    "ax5_2.text(-0.6, y_max * 1.1, f'Interneurons', color='red',fontsize=4)\n",
    "ax5_2.text(-0.6, y_max * 1.05, f'Pyramidal neurons', color='black',fontsize=4)\n",
    "ax5_2.axvline(x=0.3, color='red', linestyle='--', linewidth=1)\n",
    "ax5_2.axvline(x=-0.3, color='red', linestyle='--', linewidth=1)\n",
    "ax5_2.set_xlabel('Speed score')\n",
    "ax5_2.set_ylabel('Density')\n",
    "\n",
    "ax5_3 = fig.add_subplot(gs[4, 2])\n",
    "\n",
    "ratios =  [len(df_py[df_py['speed_score'] > 0.3])/len(df_py), len(df_int[df_int['speed_score']>0.3])/len(df_int)]\n",
    "colors = ['black', 'red']\n",
    "ax5_3.bar([0,1],ratios, color=colors)\n",
    "ax5_3.set_ylabel(\"% Neurons\")\n",
    "ax5_3.set_xticks([0,1])\n",
    "ax5_3.set_xticklabels([\"Pyramidal\",\"Interneuron\"],rotation=-15)\n",
    "\n",
    "ax5_3.set_yticks([0,0.5,1])\n",
    "ax5_3.set_yticklabels([0,50,100])\n",
    "\n",
    "ax5_3.spines['top'].set_visible(False)\n",
    "ax5_3.spines['right'].set_visible(False)\n",
    "ax5_3.spines['bottom'].set_visible(True)\n",
    "ax5_3.spines['left'].set_visible(True)\n",
    "ax5_3.set_ylim([0,1])\n",
    "\n",
    "ax5_4 = fig.add_subplot(gs[4, 3])\n",
    "ax5_5 = fig.add_subplot(gs[4, 4])\n",
    "idx=0\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "test_hy = ['two-sided','two-sided']\n",
    "for ax in [ax5_4,ax5_5]:\n",
    "    # Load Good units\n",
    "\n",
    "    df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "    df_a  = df_good[(df_good['buzaki_cell_type']=='narrow_spike_interneurons') & (df_good['session'] == \"A\")]\n",
    "\n",
    "    base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "    control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "    exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "    # Statistical comparisons for scalar metrics\n",
    "    metrics = ['mean_firing_rate','speed_score']\n",
    "    titles = ['Firing rate (Hz)', 'Speed score']\n",
    "\n",
    "    # Define custom colors\n",
    "    control_color = 'cyan'  # Dark blue for Control\n",
    "    exp_color = \"magenta\"  # Light blue for Experimental\n",
    "    metric=metrics[idx]\n",
    "    control_values = control_df[metric].dropna()\n",
    "    exp_values = exp_df[metric].dropna()\n",
    "    \n",
    "    if len(control_values) > 0 and len(exp_values) > 0:\n",
    "        control_mean = control_values.mean()\n",
    "        exp_mean = exp_values.mean()\n",
    "        control_sem = control_values.sem()\n",
    "        exp_sem = exp_values.sem()\n",
    "        print(f\"\\nComparison for {metric}:\")\n",
    "        print(f\"Control mean: {control_mean:.2f} ± {control_sem:.2f}\")\n",
    "        print(f\"Experimental mean: {exp_mean:.2f} ± {exp_sem:.2f}\")\n",
    "        \n",
    "        # Mann-Whitney U test\n",
    "        control_array = np.asarray(control_values.values, dtype=float)\n",
    "        exp_array = np.asarray(exp_values.values, dtype=float)\n",
    "\n",
    "        # Remove NaN values\n",
    "        control_clean = control_array[~np.isnan(control_array)]\n",
    "        exp_clean = exp_array[~np.isnan(exp_array)]\n",
    "\n",
    "        u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative = test_hy[idx])\n",
    "\n",
    "        # Prepare data for Seaborn plotting\n",
    "        plot_df = pd.DataFrame({\n",
    "            'value': pd.concat([control_values, exp_values]),\n",
    "            'group': ['Control'] * len(control_values) + ['Experimental'] * len(exp_values)\n",
    "        })\n",
    "        \n",
    "        # Check if deviation is \"too large\" (using coefficient of variation > 1 as threshold)\n",
    "        all_values = plot_df['value']\n",
    "        cv = all_values.std() / all_values.mean()  # Coefficient of variation\n",
    "        use_log_scale = cv > 1 and all_values.min() > 0  # Ensure positive values for log scale\n",
    "        \n",
    "        # Filter out outliers (e.g., beyond 3 standard deviations)\n",
    "        mean_val = all_values.mean()\n",
    "        std_val = all_values.std()\n",
    "        plot_df_filtered = plot_df[(plot_df['value'] >= mean_val - 3 * std_val) & \n",
    "                                (plot_df['value'] <= mean_val + 3 * std_val)]\n",
    "        \n",
    "        sns.violinplot(\n",
    "                data=plot_df_filtered, x='group', y='value', ax=ax,inner = \"quartiles\",\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color}, width=0.8, cut=0, edgecolor='white'\n",
    "            )\n",
    "        # Add individual points with matching colors\n",
    "        sns.swarmplot(\n",
    "                    data=plot_df_filtered, x='group', y='value', ax=ax, size=0.5,\n",
    "                    hue='group', palette={\"Control\": \"black\", \"Experimental\": \"black\"},\n",
    "                    alpha=1, legend=False\n",
    "                )\n",
    "        ax.set_ylabel(titles[idx])\n",
    "        ax.set_xlabel('')\n",
    "        ax.yaxis.grid(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['left'].set_visible(True)\n",
    "        ax.set_xticklabels(['CRs +', 'CRs -'], rotation = -30)\n",
    "        y_max = ax.get_ylim()[1]\n",
    "        bar_height = y_max * 0.1  # Adjust this value to position the bar above the plot\n",
    "        x_positions = [0, 1]  # Adjusted positions for 'Control' and 'Experimental' groups\n",
    "        if (p_val < 0.05) & (p_val > 0.01):\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'*', ha='center', va='bottom')\n",
    "        elif (p_val < 0.01) & (p_val > 0.001):\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'**', ha='center', va='bottom')\n",
    "        elif p_val < 0.001:\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'***', ha='center', va='bottom')\n",
    "    idx += 1\n",
    "    print(idx)\n",
    "\n",
    "\n",
    "ax5_6 = fig.add_subplot(gs[4, 5])\n",
    "\n",
    "# Data\n",
    "groups = ['CRs +', 'CRs -']\n",
    "counts = [\n",
    "    [round(78/113,2)*100, round((113-78)/113,2)*100],  # Group 1: Dark blue (71.4%), Light blue (28.6%)\n",
    "    [round(64/94,2)*100, round((94-64)/94,2)*100],  # Group 2: Dark blue (71.1%), Light blue (28.9%)\n",
    "]\n",
    "percentages = [\n",
    "    [round(78/113,2)*100, round((113-78)/113,2)*100],  # Group 1: Dark blue (71.4%), Light blue (28.6%)\n",
    "    [round(64/94,2)*100, round((94-64)/94,2)*100],  # Group 2: Dark blue (71.1%), Light blue (28.9%)\n",
    "]\n",
    "\n",
    "# Colors\n",
    "colors = ['cyan', '#C7FDFD']  # For CRs +\n",
    "colors1 = ['magenta', \"#FDC7F8\"]    # For CRs -\n",
    "\n",
    "# Create bar chart\n",
    "ax = ax5_6 \n",
    "\n",
    "# Set positions for bars to be closer\n",
    "bar_width = 0.35  # Reduced width to bring bars closer\n",
    "x = np.arange(len(groups))  # Create positions for the bars\n",
    "x = x * 0.5  # Scale x positions to reduce gap between bars\n",
    "\n",
    "# Plot stacked bars\n",
    "bars = []\n",
    "for i in range(len(counts[0])):  # For each category (0 and 1)\n",
    "    # Create bars for each group with appropriate colors\n",
    "    bar = ax.bar(x, [counts[j][i] for j in range(len(counts))], \n",
    "                 bottom=[sum(counts[j][:i]) for j in range(len(counts))], \n",
    "                 color=[colors[i] if j == 0 else colors1[i] for j in range(len(counts))], \n",
    "                 label=f'Category {i+1}' if i == 0 else None, \n",
    "                 width=bar_width)\n",
    "    bars.append(bar)\n",
    "\n",
    "# Add count and percentage labels on top of each segment\n",
    "for i, bar_group in enumerate(bars):\n",
    "    if i==0:\n",
    "        cell_type = \"(Speed cell)\"\n",
    "    else:\n",
    "        cell_type = \"(None \\nspeed cell)\"\n",
    "    for j, bar in enumerate(bar_group):\n",
    "        height = bar.get_height()\n",
    "        total = sum(counts[j])\n",
    "        bottom = sum(counts[j][:i])\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bottom + height/2, \n",
    "                f'{percentages[j][i]}%\\n {cell_type}', ha='center', va='center', rotation=0, color='black',fontsize=4)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('%Neurons')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(groups, rotation = -30)\n",
    "ax.legend().set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "y_max = ax.get_ylim()[1]\n",
    "bar_height = y_max * 0.1  # Adjust this value to position the bar above the plot\n",
    "x_positions = x  # Adjusted positions for 'Control' and 'Experimental' groups\n",
    "\n",
    "\n",
    "\n",
    "units = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good=df_good[df_good['session'] == \"A\"]\n",
    "df_int = df_good[(df_good['buzaki_py_cell_type'] == \"narrow_spike_interneurons\") & (df_good['session'] == \"A\")]\n",
    "df_py = df_good[(df_good['buzaki_py_cell_type'] == \"pyramidal\") & (df_good['session'] == \"A\")]\n",
    "\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "control_df = df_int[df_int['animal_id'].isin(control_ids)]\n",
    "exp_df = df_int[df_int['animal_id'].isin(exp_ids)]\n",
    "top_10_indices_exp = exp_df['speed_score'].nlargest(12).index.values\n",
    "top_10_indices_control = control_df['speed_score'].nlargest(12).index.values\n",
    "\n",
    "axes = [ax1_1,ax1_2 ,ax1_3 ,ax1_4 ,ax1_5 ,ax1_6, ax2_1,ax2_2 ,ax2_3 ,ax2_4 ,ax2_5,ax2_6 ]\n",
    "axes1 = [ax3_1,ax3_2 ,ax3_3 ,ax3_4 ,ax3_5 ,ax3_6, ax4_1,ax4_2 ,ax4_3 ,ax4_4 ,ax4_5,ax4_6 ]\n",
    "i=0\n",
    "df = control_df.loc[top_10_indices_control]\n",
    "for index in df.index.values:\n",
    "    ax=axes[i]\n",
    "    smoothed_speed= df['speed_collect'].loc[index] # Example velocity array\n",
    "    smooth_spk = df['speed_fr'].loc[index]\n",
    "    velocity =smoothed_speed[:len(smooth_spk)] \n",
    "\n",
    "    #spike = {'spike_t': [np.random.rand(100) for _ in range(5)]}  # Example spike data\n",
    "    #positions = np.random.rand(1000)  # Example positions\n",
    "    #unit_id = np.arange(1, 6)  # Example unit IDs\n",
    "    # Define bin points and window\n",
    "    bin_point = np.arange(0, np.nanmax(velocity), 0.04)  # 0 to 0.6 with step 0.04\n",
    "    window = 0.04 * 1.5\n",
    "    \n",
    "    p25, p50, p75 = [], [], []\n",
    "\n",
    "    # --- Quantile sliding window ---\n",
    "    for center in bin_point:\n",
    "        mask = (velocity >= center - window) & (velocity <= center + window)\n",
    "        qt_spike = smooth_spk[mask]\n",
    "        if len(qt_spike) > 0:\n",
    "            q_values = np.quantile(qt_spike, [0.25, 0.5, 0.75])\n",
    "        else:\n",
    "            q_values = [np.nan, np.nan, np.nan]\n",
    "        p25.append(q_values[0])\n",
    "        p50.append(q_values[1])\n",
    "        p75.append(q_values[2])\n",
    "\n",
    "    # --- Subsampling 10% randomly ---\n",
    "    ten_point = np.random.randint(0, len(velocity), size=int(np.ceil(len(velocity) * 0.1)))\n",
    "\n",
    "    ax.scatter(\n",
    "        velocity[ten_point],\n",
    "        smooth_spk[ten_point],\n",
    "        s=2,\n",
    "        edgecolors='white',\n",
    "        facecolors='cyan',\n",
    "        linewidths=0.1,\n",
    "        marker='o',\n",
    "        alpha=0.15\n",
    "    )\n",
    "    ax.plot(bin_point, p50, 'k.', markersize=2)\n",
    "    ax.plot(bin_point, p25, 'k-')\n",
    "    ax.plot(bin_point, p75, 'k-')\n",
    "    ax.yaxis.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    speed_score = df['speed_score'].loc[index]\n",
    "    y_max = ax.get_ylim()[1]\n",
    "    bar_height = y_max * 0.1\n",
    "    ax.text(0.25, y_max * 0.95, f'r = {speed_score:.2f}', ha='center', va='bottom')\n",
    "    # --- Speed score ---\n",
    "\n",
    "    ax.set_xlabel(\"Speed (m/s)\")\n",
    "    ax.set_xticks([0,0.5])\n",
    "    ax.set_xticklabels([0,25])\n",
    "    ax.set_ylabel(\"Firing Rate (Hz)\")\n",
    "    i += 1\n",
    "\n",
    "i=0\n",
    "df = exp_df.loc[top_10_indices_exp]\n",
    "for index in df.index.values:\n",
    "    ax=axes1[i]\n",
    "    smoothed_speed= df['speed_collect'].loc[index] # Example velocity array\n",
    "    smooth_spk = df['speed_fr'].loc[index]\n",
    "    velocity =smoothed_speed[:len(smooth_spk)] \n",
    "    bin_point = np.arange(0, np.nanmax(velocity), 0.04)  # 0 to 0.6 with step 0.04\n",
    "    window = 0.04 * 1.5\n",
    "    \n",
    "    p25, p50, p75 = [], [], []\n",
    "\n",
    "    # --- Quantile sliding window ---\n",
    "    for center in bin_point:\n",
    "        mask = (velocity >= center - window) & (velocity <= center + window)\n",
    "        qt_spike = smooth_spk[mask]\n",
    "        if len(qt_spike) > 0:\n",
    "            q_values = np.quantile(qt_spike, [0.25, 0.5, 0.75])\n",
    "        else:\n",
    "            q_values = [np.nan, np.nan, np.nan]\n",
    "        p25.append(q_values[0])\n",
    "        p50.append(q_values[1])\n",
    "        p75.append(q_values[2])\n",
    "\n",
    "    # --- Subsampling 10% randomly ---\n",
    "    ten_point = np.random.randint(0, len(velocity), size=int(np.ceil(len(velocity) * 0.1)))\n",
    "\n",
    "    ax.scatter(\n",
    "        velocity[ten_point],\n",
    "        smooth_spk[ten_point],\n",
    "        s=2,\n",
    "        edgecolors='white',\n",
    "        facecolors='magenta',\n",
    "        linewidths=0.1,\n",
    "        marker='o',\n",
    "        alpha=0.15\n",
    "    )\n",
    "    ax.plot(bin_point, p50, 'k.', markersize=2)\n",
    "    ax.plot(bin_point, p25, 'k-')\n",
    "    ax.plot(bin_point, p75, 'k-')\n",
    "    ax.yaxis.grid(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    speed_score = df['speed_score'].loc[index]\n",
    "\n",
    "    y_max = ax.get_ylim()[1]\n",
    "    bar_height = y_max * 0.1\n",
    "    ax.text(0.25, y_max * 0.95, f'r = {speed_score:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # --- Speed score ---\n",
    "    ax.set_xlabel(\"Speed (cm/s)\")\n",
    "    ax.set_xticks([0,0.5])\n",
    "    ax.set_xticklabels([0,25])\n",
    "    ax.set_ylabel(\"Firing Rate (Hz)\")\n",
    "    i += 1\n",
    "\n",
    "fig.subplots_adjust(top=0.92, bottom=0.08, left=0.1, right=0.95, hspace=1.1, wspace=1.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb899f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_py[df_py['speed_score'] > 0.3])/len(df_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977fbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "units.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
