{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'Q:\\sachuriga\\Sachuriga_Python/quattrocolo-nwb4fp\\src')\n",
    "\n",
    "from neurochat.nc_data import NData\n",
    "from neurochat.nc_spike import NSpike\n",
    "from neurochat.nc_spatial import NSpatial\n",
    "import neurochat.nc_plot as nc_plot\n",
    "from neurochat.nc_lfp import NLfp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import sys\n",
    "import nwb4fp.analyses.maps as mapp\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap,plot_path\n",
    "from nwb4fp.analyses.fields import separate_fields_by_laplace, separate_fields_by_dilation,find_peaks,separate_fields_by_laplace_of_gaussian,calculate_field_centers,distance_to_edge_function, remove_fields_by_area, map_pass_to_unit_circle,which_field,compute_crossings\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from nwb4fp.analyses import maps\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,unit_location_ch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ast\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_a  = df_good[df_good['session'] == \"A\"]\n",
    "\n",
    "metrics = ['l_ratio', 'isi_violations_ratio', \n",
    "        'amplitude_median', 'snr']\n",
    "\n",
    "titles = ['L ratio', 'ISI violations ratio', \n",
    "        'Amplitude median (mV)', 'Signal to noise ratio']\n",
    "\n",
    "fig = plt.figure(figsize=(7.2, 2.4), dpi=2400)\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "gs = gridspec.GridSpec(1, 4, height_ratios=[.8], width_ratios=[0.8, .8, .8, .8])  # First row taller\n",
    "plt.rcParams.update({\n",
    "    'axes.labelpad': -0.1,\n",
    "    'ytick.major.pad': -0.1,\n",
    "    'xtick.major.pad': -0.1,\n",
    "    'ytick.major.size': 2,\n",
    "    'xtick.major.size': 2\n",
    "})\n",
    "\n",
    "ax1_1 = fig.add_subplot(gs[0, 0])\n",
    "ax1_2 = fig.add_subplot(gs[0, 1])\n",
    "ax1_3 = fig.add_subplot(gs[0, 2])\n",
    "ax1_4 = fig.add_subplot(gs[0, 3])\n",
    "\n",
    "# ax2_1 = fig.add_subplot(gs[1, 0])\n",
    "# ax2_2 = fig.add_subplot(gs[1, 1])\n",
    "# ax2_3 = fig.add_subplot(gs[1, 2])\n",
    "# ax2_4 = fig.add_subplot(gs[1, 3])\n",
    "test_hy = ['two-sided','two-sided','two-sided','two-sided']\n",
    "idx=0\n",
    "\n",
    "for ax in [ax1_1 ,ax1_2 ,ax1_3 ,ax1_4]:\n",
    "    # Load Good units\n",
    "\n",
    "    base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "    control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "    exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "    # Statistical comparisons for scalar metrics\n",
    "\n",
    "    # Define custom colors\n",
    "    control_color = 'blue'  # Dark blue for Control\n",
    "    exp_color = \"red\"  # Light blue for Experimental\n",
    "    metric=metrics[idx]\n",
    "    control_values = control_df[metric].dropna()\n",
    "    exp_values = exp_df[metric].dropna()\n",
    "    \n",
    "    if len(control_values) > 0 and len(exp_values) > 0:\n",
    "        control_mean = control_values.mean()\n",
    "        exp_mean = exp_values.mean()\n",
    "        control_sem = control_values.sem()\n",
    "        exp_sem = exp_values.sem()\n",
    "        print(f\"\\nComparison for {metric}:\")\n",
    "        print(f\"Control mean: {control_mean:.2f} ± {control_sem:.2f}\")\n",
    "        print(f\"Experimental mean: {exp_mean:.2f} ± {exp_sem:.2f}\")\n",
    "        \n",
    "        # Mann-Whitney U test\n",
    "        control_array = np.asarray(control_values.values, dtype=float)\n",
    "        exp_array = np.asarray(exp_values.values, dtype=float)\n",
    "\n",
    "        # Remove NaN values\n",
    "        control_clean = control_array[~np.isnan(control_array)]\n",
    "        exp_clean = exp_array[~np.isnan(exp_array)]\n",
    "\n",
    "        u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative = test_hy[idx])\n",
    "\n",
    "        # Prepare data for Seaborn plotting\n",
    "        plot_df = pd.DataFrame({\n",
    "            'value': pd.concat([control_values, exp_values]),\n",
    "            'group': ['Control'] * len(control_values) + ['Experimental'] * len(exp_values)\n",
    "        })\n",
    "        \n",
    "        # Check if deviation is \"too large\" (using coefficient of variation > 1 as threshold)\n",
    "        all_values = plot_df['value']\n",
    "        cv = all_values.std() / all_values.mean()  # Coefficient of variation\n",
    "        use_log_scale = cv > 1 and all_values.min() > 0  # Ensure positive values for log scale\n",
    "        \n",
    "        # Filter out outliers (e.g., beyond 3 standard deviations)\n",
    "        mean_val = all_values.mean()\n",
    "        std_val = all_values.std()\n",
    "        plot_df_filtered = plot_df[(plot_df['value'] >= mean_val - 3 * std_val) & \n",
    "                                (plot_df['value'] <= mean_val + 3 * std_val)]\n",
    "        \n",
    "        sns.violinplot(\n",
    "                data=plot_df_filtered, x='group', y='value', ax=ax,inner = \"quartiles\",\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color}, width=0.8, cut=0, edgecolor='white'\n",
    "            )\n",
    "        # Add individual points with matching colors\n",
    "        sns.swarmplot(\n",
    "                    data=plot_df_filtered, x='group', y='value', ax=ax, size=0.5,\n",
    "                    hue='group', palette={\"Control\": \"black\", \"Experimental\": \"black\"},\n",
    "                    alpha=1, legend=False\n",
    "                )\n",
    "        ax.set_ylabel(titles[idx])\n",
    "        ax.set_xlabel('')\n",
    "        ax.yaxis.grid(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['left'].set_visible(True)\n",
    "        ax.set_xticklabels(['CRs +', 'CRs -'], rotation = -30)\n",
    "        y_max = ax.get_ylim()[1]\n",
    "        bar_height = y_max * 0.1  # Adjust this value to position the bar above the plot\n",
    "        x_positions = [0, 1]  # Adjusted positions for 'Control' and 'Experimental' groups\n",
    "        if (p_val < 0.05) & (p_val > 0.01):\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'*', ha='center', va='bottom')\n",
    "        elif (p_val < 0.01) & (p_val > 0.001):\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'**', ha='center', va='bottom')\n",
    "        elif p_val < 0.001:\n",
    "            ax.plot([x_positions[0], x_positions[1]], [y_max + bar_height, y_max + bar_height], \n",
    "                                color='black', lw=1.5)\n",
    "            ax.text(0.5, y_max + bar_height * 1.1, f'***', ha='center', va='bottom')\n",
    "    idx += 1\n",
    "    print(idx)\n",
    "\n",
    "# def remove_outliers(df, column):\n",
    "#     \"\"\"Remove outliers using IQR method\"\"\"\n",
    "#     Q1 = df[column].quantile(0.25)\n",
    "#     Q3 = df[column].quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     lower_bound = Q1 - 1.5 * IQR\n",
    "#     upper_bound = Q3 + 1.5 * IQR\n",
    "#     return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "\n",
    "\n",
    "# df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "# # Separate into control and experimental groups\n",
    "\n",
    "# df_good = df_loaded[df_loaded['unit_quality']==\"good\"]\n",
    "# df_a = df_good[(df_good['buzaki_py_cell_type']==\"pyramidal\")&(df_good['session']==\"A\")]\n",
    "# control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "# exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "# # Metrics for analysis\n",
    "# metrics = ['l_ratio', 'isi_violations_ratio', \n",
    "#         'amplitude_median', 'snr']\n",
    "# metrics1  = ['mean_firing_rate']\n",
    "\n",
    "# # metrics = ['amplitude_median','half_width','peak_to_valley','peak_trough_ratio', 'recovery_slope', 'repolarization_slope', \n",
    "# #             'mean_firing_rate',  'mean_inter_spike_interval','bursting_index' ]\n",
    "\n",
    "# axes = [ax2_1 ,ax2_2 ,ax2_3 ,ax2_4]\n",
    "\n",
    "# # Define custom colors\n",
    "# control_color = \"blue\"\n",
    "# exp_color = \"red\"\n",
    "\n",
    "# for idx, metric in enumerate(metrics):\n",
    "#     # Prepare and clean control group data\n",
    "#     control_data = pd.concat([control_df[metrics1[0]], control_df[metric]], axis=1).dropna()\n",
    "#     # control_data = remove_outliers(control_data, metrics1[0])\n",
    "#     # control_data = remove_outliers(control_data, metric)\n",
    "    \n",
    "#     # Prepare and clean experimental group data\n",
    "#     exp_data = pd.concat([exp_df[metrics1[0]], exp_df[metric]], axis=1).dropna()\n",
    "#     # exp_data = remove_outliers(exp_data, metrics1[0])\n",
    "#     # exp_data = remove_outliers(exp_data, metric)\n",
    "\n",
    "#     if len(control_data) > 2 and len(exp_data) > 2:  # Need at least 3 points for meaningful fit\n",
    "#         # Linear regression for control\n",
    "#         # Assuming control_data is a pandas DataFrame or similar\n",
    "#         x = control_data[metrics1[0]]\n",
    "#         y = control_data[metric]\n",
    "\n",
    "#         # Convert to NumPy arrays and ensure they are numeric\n",
    "#         x = np.array(x, dtype=float)\n",
    "#         y = np.array(y, dtype=float)\n",
    "\n",
    "#         # Check for valid lengths\n",
    "#         if len(x) != len(y):\n",
    "#             raise ValueError(f\"Mismatched lengths: len(x) = {len(x)}, len(y) = {len(y)}\")\n",
    "\n",
    "#         # Check for NaN or infinite values\n",
    "#         if np.any(np.isnan(x)) or np.any(np.isnan(y)):\n",
    "#             raise ValueError(\"Input arrays contain NaN values\")\n",
    "#         if np.any(np.isinf(x)) or np.any(np.isinf(y)):\n",
    "#             raise ValueError(\"Input arrays contain infinite values\")\n",
    "\n",
    "#         # Check if arrays have enough data points\n",
    "#         if len(x) < 2:\n",
    "#             raise ValueError(\"Input arrays must have at least 2 data points\")\n",
    "\n",
    "#         # Perform linear regression\n",
    "#         control_slope, control_intercept, control_r, control_p, control_se = stats.linregress(x, y)\n",
    "\n",
    "#         # control_slope, control_intercept, control_r, control_p, control_se = stats.linregress(\n",
    "#         #     control_data[metrics1[0]], control_data[metric])\n",
    "\n",
    "#         x1 = exp_data[metrics1[0]]\n",
    "#         y1 = exp_data[metric]\n",
    "#         x1 = np.array(x1, dtype=float)\n",
    "#         y1 = np.array(y1, dtype=float)\n",
    "#         exp_slope, exp_intercept, exp_r, exp_p, exp_se = stats.linregress(\n",
    "#             x1, y1)\n",
    "\n",
    "#         # Print results\n",
    "#         print(f\"Control: slope = {control_slope:.4f} ± {control_se:.4f}, R² = {control_r**2:.4f}, n = {len(control_data)}\")\n",
    "#         print(f\"Experimental: slope = {exp_slope:.4f} ± {exp_se:.4f}, R² = {exp_r**2:.4f}, n = {len(exp_data)}\")\n",
    "\n",
    "\n",
    "#                 # Given\n",
    "#         slope_diff = control_slope - exp_slope\n",
    "#         se_diff = np.sqrt(control_se**2 + exp_se**2)\n",
    "#         z_stat = slope_diff / se_diff\n",
    "\n",
    "#         # Calculate the two-tailed p-value\n",
    "#         p_value = 2 * (1 - stats.norm.cdf(np.abs(z_stat)))\n",
    "#         print(f\"Slope difference t-statistic: {p_value :.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "#         # Create scatter plot with regression lines\n",
    "#         # Control group\n",
    "#         control_plot = sns.scatterplot(\n",
    "#             data=control_data, \n",
    "#             x=metrics1[0], \n",
    "#             y=metric, \n",
    "#             ax=axes[idx], \n",
    "#             color=control_color,\n",
    "#             label='CRs +',\n",
    "#             s=2\n",
    "#         )\n",
    "#         control_line = axes[idx].plot(control_data[metrics1[0]], \n",
    "#                                     control_slope * control_data[metrics1[0]] + control_intercept, \n",
    "#                                     color=control_color,\n",
    "#                                     label=f'CRs + (R² = {control_r**2:.2f})')\n",
    "\n",
    "#         # Experimental group\n",
    "#         exp_plot = sns.scatterplot(\n",
    "#             data=exp_data, \n",
    "#             x=metrics1[0], \n",
    "#             y=metric, \n",
    "#             ax=axes[idx], \n",
    "#             color=exp_color,\n",
    "#             label='CRs -',\n",
    "#             s=2\n",
    "#         )\n",
    "#         exp_line = axes[idx].plot(exp_data[metrics1[0]], \n",
    "#                                 exp_slope * exp_data[metrics1[0]] + exp_intercept, \n",
    "#                                 color=exp_color,\n",
    "#                                 label=f'CRs - (R² = {exp_r**2:.2f})')\n",
    "\n",
    "#         # Customize plot\n",
    "#         #axes[idx].set_title(f'{metric} vs {metrics1[0]}')\n",
    "#         axes[idx].set_xlabel(metrics1[0])\n",
    "#         axes[idx].set_ylabel(metric)\n",
    "        \n",
    "#         # Update legend with R² values\n",
    "#         axes[idx].legend(handles=[control_line[0], exp_line[0]],\n",
    "#                     labels=[f'CRs + (R² = {control_r**2:.2f})', \n",
    "#                             f'CRs - (R² = {exp_r**2:.2f})'])\n",
    "        \n",
    "\n",
    "#         # Remove top and right spines\n",
    "#         axes[idx].spines['top'].set_visible(False)\n",
    "#         axes[idx].spines['right'].set_visible(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5405238",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_slope, control_intercept, control_r, control_p, control_se = stats.linregress(\n",
    "    control_data[metrics1[0]], control_data[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff879977",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"control_data columns:\", control_data.columns)\n",
    "print(\"metrics1[0]:\", metrics1[0], \"metric:\", metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data[metrics1[0]].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
