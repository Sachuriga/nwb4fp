{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'Q:\\sachuriga\\Sachuriga_Python/quattrocolo-nwb4fp\\src')\n",
    "\n",
    "from neurochat.nc_data import NData\n",
    "from neurochat.nc_spike import NSpike\n",
    "from neurochat.nc_spatial import NSpatial\n",
    "import neurochat.nc_plot as nc_plot\n",
    "from neurochat.nc_lfp import NLfp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import sys\n",
    "import nwb4fp.analyses.maps as mapp\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap,plot_path\n",
    "from nwb4fp.analyses.fields import separate_fields_by_laplace, separate_fields_by_dilation,find_peaks,separate_fields_by_laplace_of_gaussian,calculate_field_centers,distance_to_edge_function, remove_fields_by_area, map_pass_to_unit_circle,which_field,compute_crossings\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from nwb4fp.analyses import maps\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,unit_location_ch\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ast\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_burst_index(spike_times, bin_size=0.001, max_lag=0.1):\n",
    "    \"\"\"\n",
    "    Calculate the burst index from spike times (in seconds) using the auto-correlogram.\n",
    "    \n",
    "    Parameters:\n",
    "    spike_times : array-like\n",
    "        List or array of spike times in seconds.\n",
    "    bin_size : float, optional\n",
    "        Bin size for the auto-correlogram in seconds (default: 0.001 s = 1 ms).\n",
    "    max_lag : float, optional\n",
    "        Maximum lag for the auto-correlogram in seconds (default: 0.05 s = 50 ms).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Burst index ranging from -1 to 1. Returns np.nan if insufficient data.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    spike_times = np.array(spike_times, dtype=float)\n",
    "    if len(spike_times) < 2:\n",
    "        raise ValueError(\"At least two spike times are required.\")\n",
    "    if max_lag <= 0 or bin_size <= 0:\n",
    "        raise ValueError(\"max_lag and bin_size must be positive.\")\n",
    "\n",
    "    # Sort spike times for efficiency\n",
    "    spike_times = np.sort(spike_times)\n",
    "    \n",
    "    # Compute pairwise differences efficiently\n",
    "    diffs = []\n",
    "    for i, t in enumerate(spike_times):\n",
    "        future_spikes = spike_times[i+1:]\n",
    "        valid_diffs = future_spikes - t\n",
    "        valid_diffs = valid_diffs[valid_diffs <= max_lag]\n",
    "        if len(valid_diffs) > 0:\n",
    "            diffs.extend(valid_diffs)\n",
    "            #diffs.extend(-valid_diffs)  # Include negative differences for symmetry\n",
    "\n",
    "    diffs = np.array(diffs)\n",
    "    \n",
    "    # Create bins\n",
    "    bins = np.arange(-max_lag, max_lag + bin_size, bin_size)\n",
    "    \n",
    "    # Compute histogram\n",
    "    hist, bin_edges = np.histogram(diffs, bins=bins)\n",
    "    \n",
    "    # Normalize to probability density (spikes per second)\n",
    "    total_spikes = len(spike_times)\n",
    "    autocorr = hist / (np.sum(hist))\n",
    "\n",
    "    #autocorr = hist / total_pairs if total_pairs > 0 else hist\n",
    "    \n",
    "    # Calculate indices for baseline (40-50 ms = 0.04-0.05 s) and peak (0-10 ms = 0-0.01 s)\n",
    "    baseline_idx = np.where((bins[:-1] >= 0.05) & (bins[:-1] < 0.1))[0]\n",
    "    peak_idx = np.where((bins[:-1] >= 0) & (bins[:-1] <= 0.006))[0]\n",
    "    \n",
    "    # Check if indices are valid\n",
    "    if len(baseline_idx) == 0 or len(peak_idx) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculate baseline (mean value between 40 and 50 ms)\n",
    "    baseline = np.mean(autocorr[baseline_idx])\n",
    "    \n",
    "    # Calculate peak (max value between 0 and 10 ms)\n",
    "    peak = np.max(autocorr[peak_idx]) if len(peak_idx) > 0 else 0\n",
    "    \n",
    "    # Calculate burst amplitude\n",
    "    burst_amplitude = peak - baseline\n",
    "    \n",
    "    # Normalize burst amplitude\n",
    "    if burst_amplitude > 0:\n",
    "        # Normalize to peak for positive amplitudes\n",
    "        burst_index = burst_amplitude / peak if peak != 0 else 0\n",
    "    else:\n",
    "        # Normalize to baseline for negative amplitudes\n",
    "        burst_index = burst_amplitude / baseline if baseline != 0 else 0\n",
    "    \n",
    "    return hist, autocorr, burst_index\n",
    "\n",
    "def calculate_mean_firing_rate(spike_times):\n",
    "    \"\"\"\n",
    "    Calculate mean firing rate (spikes per second) from a list of spike times in seconds.\n",
    "    \n",
    "    Parameters:\n",
    "    - spike_times: List or array of spike times in seconds\n",
    "    \n",
    "    Returns:\n",
    "    - firing_rate: Mean firing rate in Hz (spikes/second)\n",
    "    \"\"\"\n",
    "    if len(spike_times) < 1:\n",
    "        return 0.0\n",
    "    total_spikes = len(spike_times)\n",
    "    time_span = max(spike_times) - min(spike_times) if total_spikes > 1 else 1.0  # Avoid division by zero\n",
    "    return total_spikes / time_span\n",
    "\n",
    "def compute_autocorrelogram(spike_times, bins, max_lag=0.1):\n",
    "    spike_times = np.array(spike_times)\n",
    "    autocorr = np.zeros(len(bins) - 1)\n",
    "    \n",
    "    # Compute differences between all pairs of spikes\n",
    "    for i, t1 in enumerate(spike_times):\n",
    "        diffs = t1 - spike_times[i+1:]  # Exclude self-correlation at lag 0\n",
    "        valid_diffs = diffs[(diffs >= -max_lag) & (diffs <= max_lag)]\n",
    "        hist, _ = np.histogram(valid_diffs, bins=bins)\n",
    "        autocorr += hist\n",
    "    \n",
    "    return autocorr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example spike times in seconds (replace this with your own data)\n",
    "\n",
    "def mean_isi(spike_times):\n",
    "    # Calculate inter-spike intervals (ISI) by subtracting consecutive times\n",
    "    import numpy as np\n",
    "    isi = np.diff(spike_times)\n",
    "    # Calculate the mean ISI\n",
    "    return np.mean(isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "def acg_narrow(spike_times):\n",
    "    bin_size=0.0005\n",
    "    max_lag=0.05\n",
    "    spike_times = np.array(spike_times, dtype=float)\n",
    "    if len(spike_times) < 2:\n",
    "        raise ValueError(\"At least two spike times are required.\")\n",
    "    if max_lag <= 0 or bin_size <= 0:\n",
    "        raise ValueError(\"max_lag and bin_size must be positive.\")\n",
    "\n",
    "    # Sort spike times for efficiency\n",
    "    spike_times = np.sort(spike_times)\n",
    "\n",
    "    # Compute pairwise differences efficiently\n",
    "    diffs = []\n",
    "    for i, t in enumerate(spike_times):\n",
    "        future_spikes = spike_times[i+1:]\n",
    "        valid_diffs = future_spikes - t\n",
    "        valid_diffs = valid_diffs[valid_diffs <= max_lag]\n",
    "        if len(valid_diffs) > 0:\n",
    "            diffs.extend(valid_diffs)\n",
    "            diffs.extend(-valid_diffs)  # Include negative differences for symmetry\n",
    "\n",
    "    diffs = np.array(diffs)\n",
    "\n",
    "    # Create bins\n",
    "    bins = np.arange(-max_lag, max_lag + bin_size, bin_size)\n",
    "\n",
    "    # Compute histogram\n",
    "    hist, bin_edges = np.histogram(diffs, bins=bins) \n",
    "\n",
    "    return hist\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def triple_exp(x, a, b, c, d, e, f, g, h):\n",
    "    return np.maximum(c * (np.exp(-(x - f) / a) - d * np.exp(-(x - f) / b)) + h * np.exp(-(x - f) / g) + e, 0)\n",
    "\n",
    "def fit_ACG(acg_narrow, plots=True):\n",
    "    acg_narrow = acg_narrow.copy()\n",
    "    acg_narrow[99:101, :] = 0  # set time-zero bin to zero (-0.5ms -> 0.5ms)\n",
    "    offset = 100\n",
    "    x = np.arange(0, 100) / 2  # [0, 0.5, 1, ..., 49.5] ms\n",
    "\n",
    "    # Initial guess, lower bounds, upper bounds\n",
    "    p0 = [20, 1, 30, 2, 0.5, 5, 1.5, 2]\n",
    "    lb = [1, 0.1, 0, 0, -30, 0, 0.1, 0]\n",
    "    ub = [500, 50, 500, 15, 50, 20, 5, 100]\n",
    "    bounds = (lb, ub)\n",
    "\n",
    "    n_cells = acg_narrow.shape[1]\n",
    "    fit_params = np.full((8, n_cells), np.nan)\n",
    "    rsquare = np.full(n_cells, np.nan)\n",
    "    first_positive_x = np.full(n_cells, np.nan)  # New array for first x where y > 0\n",
    "    plotf0 = np.zeros((100, n_cells))\n",
    "\n",
    "    for j in range(n_cells):\n",
    "        if not np.any(np.isnan(acg_narrow[:, j])):\n",
    "            y = acg_narrow[(x * 2 + offset).astype(int), j]\n",
    "            try:\n",
    "                popt, pcov = curve_fit(triple_exp, x, y, p0=p0, bounds=bounds, maxfev=10000)\n",
    "                fit_params[:, j] = popt\n",
    "                y_fit = triple_exp(x, *popt)\n",
    "                plotf0[:, j] = y_fit\n",
    "                # R-square calculation\n",
    "                ss_res = np.sum((y - y_fit) ** 2)\n",
    "                ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "                rsquare[j] = 1 - (ss_res / ss_tot)\n",
    "\n",
    "                # Find first x where y > 0 using high-resolution x_fit\n",
    "                x_fit = np.arange(0, 100.1, 0.1) / 2  # [0, 0.05, 0.1, ..., 50] ms\n",
    "                y_fit_hr = triple_exp(x_fit, *popt)\n",
    "                positive_idx = np.where(y_fit_hr > 0)[0]\n",
    "                if positive_idx.size > 0:\n",
    "                    first_positive_x[j] = x_fit[positive_idx[0]]  # First x where y > 0\n",
    "\n",
    "                if plots:\n",
    "                    plt.figure()\n",
    "                    plt.plot(x, y, 'b-', label='ACG')\n",
    "                    plt.plot(x_fit, y_fit_hr, 'r--', label='Fit')\n",
    "                    plt.title(f'Cell {j+1} Fit')\n",
    "                    plt.xlabel('Time (ms)')\n",
    "                    plt.ylabel('Counts')\n",
    "                    plt.legend()\n",
    "                    param_text = '\\n'.join(f'{name}={val:.2f}' for name, val in zip(\n",
    "                        ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'], popt))\n",
    "                    param_text += f'\\nfirst_positive_x={first_positive_x[j]:.2f}'\n",
    "                    plt.text(0.5, 0.5, param_text, transform=plt.gca().transAxes)\n",
    "                    plt.show()\n",
    "\n",
    "            except RuntimeError:\n",
    "                print(f\"Fit failed for cell {j}\")\n",
    "\n",
    "    fit_params_out = {\n",
    "        'acg_tau_decay': fit_params[0, :],\n",
    "        'acg_tau_rise': fit_params[1, :],\n",
    "        'acg_c': fit_params[2, :],\n",
    "        'acg_d': fit_params[3, :],\n",
    "        'acg_asymptote': fit_params[4, :],\n",
    "        'acg_refrac': fit_params[5, :],\n",
    "        'acg_tau_burst': fit_params[6, :],\n",
    "        'acg_h': fit_params[7, :],\n",
    "        'acg_fit_rsquare': rsquare,\n",
    "        'acg_first_positive_x': first_positive_x  # New output parameter\n",
    "    }\n",
    "\n",
    "    return fit_params_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, levene, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "#import scikit_posthocs as sp\n",
    "\n",
    "# Folder path\n",
    "folder_path = r\"S:\\Sachuriga\\file_with_table\\ripple_ch/\"\n",
    "\n",
    "# Function to get pickle files\n",
    "def get_pkl_files(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    pkl_files = [f for f in all_files if f.endswith(\"withDLC.pkl\")]\n",
    "    return pkl_files\n",
    "pkl_files = get_pkl_files(folder_path)\n",
    "\n",
    "\n",
    "# Define group prefixes\n",
    "target_prefixes_control = ['65165', '65091', '63383', '66539', '65622']\n",
    "target_prefixes_exp = ['65588', '63385', '66538', '66537', '66922']\n",
    "\n",
    "# Get the list of pickle files\n",
    "pkl_files = get_pkl_files(folder_path)\n",
    "\n",
    "# Initialize a list to store all DataFrames\n",
    "all_dfs = []\n",
    "\n",
    "# Process each pickle file\n",
    "for file in pkl_files:\n",
    "    df = pd.read_pickle(fr\"{folder_path}/{file}\")\n",
    "    df['buzaki_cell_type'] = None\n",
    "    df_good = df\n",
    "    for i in range(len(df_good)):\n",
    "        if (df_good['peak_to_valley'].iloc[i] <= 0.000425)|(df_good['mean_firing_rate'].iloc[i] >= 10):\n",
    "            df_good['buzaki_py_cell_type'].iloc[i] = \"narrow_spike_interneurons\"\n",
    "        #elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & (((df_good['tau_rise_python'].iloc[i]) + (df_good['acg_first_positive_x'].iloc[i])) >= 6):\n",
    "        elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & ((df_good['tau_rise_python'].iloc[i])  >= 6):\n",
    "            df_good['buzaki_py_cell_type'].iloc[i] = \"wide_spike_interneurons\"\n",
    "        #elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10) & (((df_good['tau_rise_python'].iloc[i]) + (df_good['acg_first_positive_x'].iloc[i])) < 6):\n",
    "        elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10) & ((df_good['tau_rise_python'].iloc[i])  < 6):\n",
    "            df_good['buzaki_py_cell_type'].iloc[i] = \"pyramidal\"\n",
    "        \n",
    "    all_dfs.append(df_good.reset_index(drop=True))\n",
    "\n",
    "combines = pd.concat(all_dfs, ignore_index=False)\n",
    "combines.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import mode\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "len(df_loaded)\n",
    "df_good = df_loaded[df_loaded['unit_quality']==\"good\"]\n",
    "\n",
    "df_good.head()\n",
    "# df_good['matlab_acg_tau_rise']\n",
    "# df_good['peak_to_valley']\n",
    "# sns.scatterplot(x='peak_to_valley', y='matlab_acg_tau_rise', hue='cell_type', data=df_good)\n",
    "# plt.ylabel('Tau Rise (ms)')\n",
    "# plt.xlabel('Trough to Peak (ms)')\n",
    "# plt.title('Scatter Plot Colored by Cell Type')\n",
    "# plt.show()\n",
    "bursting_index=[]\n",
    "mean_firing_rate=[]\n",
    "auto_corr=[]\n",
    "df_good['buzaki_cell_type'] = None\n",
    "df_good[\"bursting_index\"] = None\n",
    "df_good[\"auto_corr\"] = None\n",
    "df_good[\"fit_para\"] = None\n",
    "fits_para = []\n",
    "mode_inter_spike_interval = []\n",
    "for i in range(len(df_good)):\n",
    "    autocorr_temp=[]\n",
    "    hist_narrow=[]\n",
    "    spike_times=df_good[\"spike_times\"][:].iloc[i][:]\n",
    "    _, autocorr_temp, bursting_index_temp = calculate_burst_index(spike_times)\n",
    "    #hist_narrow, _, _ = calculate_burst_index(spike_times,bin_size=0.0005, max_lag=0.05)\n",
    "    #temp_fits = fit_ACG(hist_narrow, plots=True)\\hist_narrow\n",
    "    hist_narrow = acg_narrow(spike_times)\n",
    "    fits_para.append(hist_narrow)\n",
    "    bursting_index.append(bursting_index_temp)\n",
    "    auto_corr.append(autocorr_temp)\n",
    "    mean_firing_rate.append(calculate_mean_firing_rate(spike_times)) \n",
    "    isis = np.diff(spike_times)\n",
    "    if (df_good['peak_to_valley'].iloc[i] <= 0.000425)|(df_good['mean_firing_rate'].iloc[i] >= 10):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"narrow_spike_interneurons\"\n",
    "    elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['matlab_acg_tau_rise_1'].iloc[i]> 6):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"wide_spike_interneurons\"\n",
    "    elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"pyramidal\"\n",
    "    # Compute autocorre\n",
    "    mode_inter_spike_interval.append(mode(isis, keepdims=True)[0][0])\n",
    "np.save(r\"Q:\\sachuriga\\CR_CA1_paper\\tables/narrow_acgs.npy\",fits_para)\n",
    "df_good[\"auto_corr\"] =  auto_corr\n",
    "df_good[\"bursting_index\"] = bursting_index\n",
    "df_good[\"mean_firing_rate\"] = mean_firing_rate\n",
    "df_good[\"mode_inter_spike_interval\"] = mode_inter_spike_interval\n",
    "#df_good[\"fit_para\"] =  fits_para\n",
    "df_good.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_good = pd.read_pickle(r\"Q:\\sachuriga\\CR_CA1_paper\\tables/all_units_table_with_waveforms.pkl\")\n",
    "df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "fits_para=[]\n",
    "for i in range(len(df_good)):\n",
    "    hist_narrow=[]\n",
    "    spike_times=df_good[\"spike_times\"][:].iloc[i][:]\n",
    "    hist_narrow = acg_narrow(spike_times)\n",
    "    fits_para.append(hist_narrow)\n",
    "\n",
    "narrow_acgs = np.array(fits_para).T\n",
    "para = fit_ACG(narrow_acgs, plots=False)\n",
    "df_good['tau_rise_python']=None\n",
    "df_good['tau_rise_python']=para['acg_tau_rise']\n",
    "df_good['acg_first_positive_x']=None\n",
    "df_good['acg_first_positive_x']=para['acg_first_positive_x']\n",
    "\n",
    "df_good['buzaki_py_cell_type']=None\n",
    "for i in range(len(df_good)):\n",
    "    if (df_good['peak_to_valley'].iloc[i] <= 0.000425)|(df_good['mean_firing_rate'].iloc[i] >= 10):\n",
    "        df_good['buzaki_py_cell_type'].iloc[i] = \"narrow_spike_interneurons\"\n",
    "    #elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & (((df_good['tau_rise_python'].iloc[i]) + (df_good['acg_first_positive_x'].iloc[i])) >= 6):\n",
    "    elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & ((df_good['tau_rise_python'].iloc[i])  >= 6):\n",
    "        df_good['buzaki_py_cell_type'].iloc[i] = \"wide_spike_interneurons\"\n",
    "    #elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10) & (((df_good['tau_rise_python'].iloc[i]) + (df_good['acg_first_positive_x'].iloc[i])) < 6):\n",
    "    elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10) & ((df_good['tau_rise_python'].iloc[i])  < 6):\n",
    "        df_good['buzaki_py_cell_type'].iloc[i] = \"pyramidal\"\n",
    "\n",
    "#df_good.to_pickle(r\"Q:\\sachuriga\\CR_CA1_paper\\tables/all_units_table_with_waveforms.pkl\")\n",
    "df_good.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_acgs = np.array(fits_para).T\n",
    "para = fit_ACG(narrow_acgs, plots=False)\n",
    "df_good['tau_rise_python']=None\n",
    "df_good['tau_rise_python']=para['acg_tau_rise']\n",
    "df_good['acg_first_positive_x']=None\n",
    "df_good['acg_first_positive_x']=para['acg_first_positive_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_acgs = np.array(fits_para).T\n",
    "narrow_acgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "len_check = 0\n",
    "for u_id in list(np.unique(df_loaded['session_id'])):\n",
    "    animal = u_id.split(\"_\")[0]\n",
    "    day= u_id.split(\"_\")[1]\n",
    "    session = u_id.split(\"_\")[2]\n",
    "    temp = df_loaded[df_loaded['session_id']==u_id]\n",
    "    len_check = len_check + len(temp)\n",
    "\n",
    "    if os.path.exists(fr\"S:\\Sachuriga\\file_with_table\\ripple_ch\\{animal}_{day}_{session}_units_table_withDLC.pkl\"):\n",
    "        os.remove(fr\"S:\\Sachuriga\\file_with_table\\ripple_ch\\{animal}_{day}_{session}_units_table_withDLC.pkl\")\n",
    "    temp.to_pickle(fr\"S:\\Sachuriga\\file_with_table\\ripple_ch\\{animal}_{day}_{session}_units_table_withDLC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good ['buzaki_cell_type'] = None\n",
    "for i in range(len(df_good )):\n",
    "    if (df_good['peak_to_valley'].iloc[i] <= 0.000425)|(df_good['mean_firing_rate'].iloc[i] >= 10):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"narrow_spike_interneurons\"\n",
    "    elif  (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['matlab_acg_tau_rise_1'].iloc[i]> 6):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"wide_spike_interneurons\"\n",
    "    elif (df_good['peak_to_valley'].iloc[i] > 0.000425) & (df_good['mean_firing_rate'].iloc[i] < 10):\n",
    "        df_good['buzaki_cell_type'].iloc[i] = \"pyramidal\"\n",
    "\n",
    "# Select features\n",
    "##the original\n",
    "features = ['mean_firing_rate', 'bursting_index',\"mode_inter_spike_interval\",'peak_to_valley','assy','peak_trough_ratio']\n",
    "#features = ['peak_trough_ratio', 'mean_firing_rate', 'bursting_index',\"mean_inter_spike_interval\",'peak_to_valley']\n",
    "#features = ['Averate_rate', 'bursting_index',\"mode_inter_spike_interval\",'assy','peak_to_valley']\n",
    "### for testing\n",
    "#features = ['peak_trough_ratio', 'mean_firing_rate', 'bursting_index',\"mean_inter_spike_interval\",'peak_to_valley']\n",
    "X = df_good[features].values\n",
    "\n",
    "# Step 1: Z-score the data\n",
    "scaler = StandardScaler()\n",
    "X_zscored = scaler.fit_transform(X)\n",
    "\n",
    "# # Step 2: Apply t-SNE for dimensionality reduction to 3D\n",
    "# group = df_good['genotype']\n",
    "# NDNF-flp +/- and Pde1c +/-\n",
    "# NDNF-flp-/- and Pde1c -/-\n",
    "\n",
    "tsne = TSNE(n_components=3, perplexity=30, n_iter=2000, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_zscored)\n",
    "# Assuming X_tsne and df_good are already defined from your previous steps\n",
    "# If not, ensure X_tsne is a 3D t-SNE output (n_samples, 3)\n",
    "df_loaded=df_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path\n",
    "folder_path = r\"S:\\Sachuriga\\file_with_table\\ripple_ch\\Functional_connections\"\n",
    "\n",
    "# Function to get pickle files\n",
    "def get_pkl_files(folder_path):\n",
    "    all_files = os.listdir(folder_path)\n",
    "    pkl_files = [f for f in all_files if f.endswith(\"withDLC.pkl\")]\n",
    "    return pkl_files\n",
    "pkl_files = get_pkl_files(folder_path)\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_loaded['connectivity']=None\n",
    "\n",
    "for file in pkl_files:\n",
    "    df = pd.read_pickle(fr'{folder_path}/{file}')\n",
    "    session_id = df['session_id'].iloc[0]\n",
    "    df_loaded.loc[df_loaded['session_id']==session_id,'connectivity'] = list(df['connectivity'])\n",
    "\n",
    "df_good['connectivity'] = None\n",
    "df_good['connectivity'] = df_loaded['connectivity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Apply DBSCAN clustering\n",
    "#dbscan = DBSCAN(eps=1.4, min_samples=5)\n",
    "#dbscan = DBSCAN(eps=1.1, min_samples=5)\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=2.229, min_samples=20)\n",
    "clusters = dbscan.fit_predict(X_tsne)\n",
    "\n",
    "# Step 4: Identify the three largest clusters\n",
    "unique_labels = np.unique(clusters)\n",
    "cluster_sizes = np.bincount(clusters + 1)  # +1 to shift -1 (noise) to 0\n",
    "n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)  # Exclude noise\n",
    "\n",
    "# Get sizes for non-noise clusters (exclude index 0, which is noise)\n",
    "non_noise_sizes = cluster_sizes[1:]  # Skip noise (-1, now at index 0)\n",
    "non_noise_labels = unique_labels[unique_labels != -1]  # Exclude noise label\n",
    "\n",
    "# Sort clusters by size and pick the top 3\n",
    "if len(non_noise_labels) >= 3:\n",
    "    sorted_indices = np.argsort(non_noise_sizes)[::-1]  # Descending order\n",
    "    largest_cluster_label = non_noise_labels[sorted_indices[0]]\n",
    "    second_largest_cluster_label = non_noise_labels[sorted_indices[1]]\n",
    "    third_largest_cluster_label = non_noise_labels[sorted_indices[2]]\n",
    "else:\n",
    "    raise ValueError(\"Fewer than 3 clusters found. Adjust DBSCAN parameters.\")\n",
    "\n",
    "##Filter data for the three largest clusters and noise\n",
    "mask_largest = (clusters == largest_cluster_label) \n",
    "mask_second = clusters == second_largest_cluster_label\n",
    "mask_third = clusters == third_largest_cluster_label\n",
    "# mask_largest = df_loaded['buzaki_cell_type']=='pyramidal'\n",
    "# mask_second = df_loaded['buzaki_cell_type']==\"narrow_spike_interneurons\"\n",
    "# mask_third = df_loaded['buzaki_cell_type']==\"wide_spike_interneurons\"\n",
    "\n",
    "mask_pre = list(df_good['connectivity']==\"pre\") & mask_largest\n",
    "mask_post_n = list(df_good['connectivity']==\"post\") & (mask_second)\n",
    "mask_post_w = list(df_good['connectivity']==\"post\") & (mask_third)\n",
    "\n",
    "\n",
    "mask_noise = clusters == -1  # Noise points\n",
    "X_largest_nonpre = (mask_largest == True) & (mask_pre==False)\n",
    "X_second_nonpost = (mask_second == True) & (mask_post_n==False)\n",
    "X_third_nonpost = (mask_third == True) & (mask_post_w==False)\n",
    "\n",
    "X_largest = X_tsne[X_largest_nonpre] \n",
    "X_second = X_tsne[X_second_nonpost]\n",
    "X_third = X_tsne[X_third_nonpost]\n",
    "\n",
    "X_noise = X_tsne[mask_noise]\n",
    "# Step 5: Assign labels to the original DataFrame\n",
    "df_good['cell_type'] = 'noise'  # Default label for all points\n",
    "df_good.loc[clusters == largest_cluster_label, 'cell_type'] = 'pyramidal'  # Largest cluster\n",
    "df_good.loc[clusters == second_largest_cluster_label, 'cell_type'] = 'interneuron'  # Second largest\n",
    "df_good.loc[clusters == third_largest_cluster_label, 'cell_type'] = 'wid_spike_interneuron'  # Third largest\n",
    "color_hue = df_good['Information_content_rate'][df_good['cell_type']=='pyramidal']\n",
    "\n",
    "# --- 3D Spinning GIF ---\n",
    "fig_3d = plt.figure(figsize=(12, 12))\n",
    "ax_3d = fig_3d.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot largest cluster in blue (circle)\n",
    "scatter1 = ax_3d.scatter(X_largest[:, 0], X_largest[:, 1], X_largest[:, 2], c='blue', s=30, label='Pyramidal', marker='o')\n",
    "# Plot second largest cluster in red (circle)\n",
    "scatter2 = ax_3d.scatter(X_second[:, 0], X_second[:, 1], X_second[:, 2], c='red', s=30, label='Interneuron', marker='o')\n",
    "# Plot third largest cluster in green (circle)\n",
    "scatter3 = ax_3d.scatter(X_third[:, 0], X_third[:, 1], X_third[:, 2], c='green', s=10, label='Wid Interneuron?', marker='o')\n",
    "\n",
    "# Overlay mask_pre with triangle marker\n",
    "mask_pre_indices = df_good[mask_pre].index\n",
    "X_pre = X_tsne[mask_pre]\n",
    "\n",
    "# Overlay mask_post with rectangle (square) marker\n",
    "mask_post_indices = df_good[mask_post_n].index\n",
    "X_post_n = X_tsne[mask_post_n]\n",
    "scatter_post = ax_3d.scatter(X_post_n[:, 0], X_post_n[:, 1], X_post_n[:, 2], c='red', s=50, marker='s', alpha=1, edgecolors='black')\n",
    "\n",
    "# Overlay mask_post with rectangle (square) marker\n",
    "mask_post_indices = df_good[mask_post_w].index\n",
    "X_post_w = X_tsne[mask_post_w]\n",
    "scatter_post = ax_3d.scatter(X_post_w[:, 0], X_post_w[:, 1], X_post_w[:, 2], c='green', s=50, marker='s', alpha=1, edgecolors='black')\n",
    "scatter_pre = ax_3d.scatter(X_pre[:, 0], X_pre[:, 1], X_pre[:, 2], c='blue', s=50, marker='^', alpha=1, edgecolors='black')\n",
    "\n",
    "# Customize 3D plot\n",
    "ax_3d.set_title('t-SNE 3D Projection: Three Largest DBSCAN Clusters with Noise').set_visible(False)\n",
    "ax_3d.set_xlabel('t-SNE 1')\n",
    "ax_3d.set_ylabel('t-SNE 2')\n",
    "ax_3d.set_zlabel('t-SNE 3')\n",
    "ax_3d.legend().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "# # Animation function to rotate the plot\n",
    "# def update(frame):\n",
    "#     ax_3d.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "#     return scatter1, scatter2, scatter3,scatter_post,scatter_pre\n",
    "\n",
    "# # Create animation\n",
    "# ani = FuncAnimation(fig_3d, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# # Save the animation as a GIF\n",
    "# ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_clusters_with_noise.gif', writer='pillow', fps=10)\n",
    "# plt.close(fig_3d)  # Close the figure to avoid displaying it statically\n",
    "\n",
    "# --- 2D Static Plot ---\n",
    "fig_2d = plt.figure(figsize=(10, 10))\n",
    "ax_2d = fig_2d.add_subplot(111)\n",
    "\n",
    "# Plot largest cluster in blue (only t-SNE 1 and t-SNE 2)\n",
    "ax_2d.scatter(X_largest[:, 0], X_largest[:, 1], c='blue', s=20, label='Cluster Pyramidal (Largest)')\n",
    "# Plot second largest cluster in red (only t-SNE 1 and t-SNE 2)\n",
    "ax_2d.scatter(X_second[:, 0], X_second[:, 1], c='red', s=20, label='Cluster Interneuron (Second Largest)')\n",
    "# Plot third largest cluster in green (only t-SNE 1 and t-SNE 2)\n",
    "ax_2d.scatter(X_third[:, 0], X_third[:, 1], c='green', s=20, label='Cluster Third Largest')\n",
    "# Plot noise in yellow (only t-SNE 1 and t-SNE 2)\n",
    "#ax_2d.scatter(X_noise[:, 0], X_noise[:, 1], c='yellow', s=20, label='Noise')\n",
    "\n",
    "scatter_pre = ax_2d.scatter(X_pre[:, 0], X_pre[:, 1], c='blue', s=50, marker='^', edgecolors='black')\n",
    "scatter_post = ax_2d.scatter(X_post_n[:, 0], X_post_n[:, 1], c='red', s=50, marker='s', edgecolors='black')\n",
    "scatter_post = ax_2d.scatter(X_post_w[:, 0], X_post_w[:, 1], c='green', s=50, marker='s', edgecolors='black')\n",
    "\n",
    "# Customize 2D plot\n",
    "ax_2d.set_title('t-SNE 2D Projection: Three Largest DBSCAN Clusters with Noise').set_visible(False)\n",
    "ax_2d.set_xlabel('t-SNE 1')\n",
    "ax_2d.set_ylabel('t-SNE 2')\n",
    "ax_2d.legend().set_visible(False)\n",
    "\n",
    "plt.axis('equal') # Ensures equal aspect ratio\n",
    "# Adjust layout and save/show 2D plot\n",
    "plt.tight_layout()\n",
    "# plt.savefig(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/2d_clusters_with_noise.png')  # Save as PNG\n",
    "plt.show()\n",
    "\n",
    "# ## change labels to pkl files\n",
    "# # Function to get pickle files\n",
    "# def get_pkl_files(folder_path):\n",
    "#     all_files = os.listdir(folder_path)\n",
    "#     pkl_files = [f for f in all_files if f.endswith(\"withDLC.pkl\")]\n",
    "#     return pkl_files\n",
    "\n",
    "# folder_path = r\"S:\\Sachuriga\\file_with_table\\ripple_ch\"\n",
    "# pkl_files = get_pkl_files(folder_path)\n",
    "\n",
    "# # Initialize df_good (assuming it's a DataFrame)\n",
    "# df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "# error_log=[]\n",
    "# for file in pkl_files:\n",
    "#     # Read the pickle file\n",
    "#     try:\n",
    "#         df = pd.read_pickle(rf\"{folder_path}/{file}\")\n",
    "#     except Exception as e:\n",
    "#         error_log.append(file)\n",
    "#         continue\n",
    "#     uids = df['session_id'].iloc[0]\n",
    "    \n",
    "#     temp = df_good[df_good['session_id']==uids]\n",
    "#     df['cell_type']=None\n",
    "#     df['cell_type'] = temp['cell_type'].tolist()\n",
    "#     if os.path.exists(rf\"{folder_path}/{file}\"):\n",
    "#         os.remove(rf\"{folder_path}/{file}\")\n",
    "#     df.to_pickle(rf\"{folder_path}/{file}\")\n",
    "\n",
    "# df_good.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "\n",
    "# Print cluster summary\n",
    "print(f\"Number of clusters found: {n_clusters}\")\n",
    "print(f\"Number of noise points: {np.sum(clusters == -1)}\")\n",
    "print(f\"Size of largest cluster (label {largest_cluster_label}): {np.sum(mask_largest)}\")\n",
    "print(f\"Size of second largest cluster (label {second_largest_cluster_label}): {np.sum(mask_second)}\")\n",
    "print(f\"Size of third largest cluster (label {third_largest_cluster_label}): {np.sum(mask_third)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folder_path = r\"S:\\Sachuriga\\file_with_table\\ripple_ch\"\n",
    "# Initialize df_good (assuming it's a DataFrame)\n",
    "df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "error_log=[]\n",
    "for uid in df_good['session_id']:\n",
    "    # Read the pickle file\n",
    "    temp = df_good[df_good['session_id']==uid]\n",
    "    file_name = uid.split('_phy_k_manual.nwb')[0]\n",
    "    if os.path.exists(rf\"{folder_path}/{file_name}_units_table_withDLC.pkl\"):\n",
    "        os.remove(rf\"{folder_path}/{file_name}_units_table_withDLC.pkl\")\n",
    "    temp.to_pickle(rf\"{folder_path}/{file_name}_units_table_withDLC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_log=[]\n",
    "folder_path=r'S:\\Sachuriga\\file_with_table\\ripple_ch'\n",
    "for file in pkl_files:\n",
    "    # Read the pickle file\n",
    "    try:\n",
    "        df = pd.read_pickle(rf\"{folder_path}/{file}\")\n",
    "    except Exception as e:\n",
    "        error_log.append(file)\n",
    "        continue\n",
    "    uids = df['session_id'].iloc[0]\n",
    "    \n",
    "    temp = df_good[df_good['session_id']==uids]\n",
    "    df['cell_type']=None\n",
    "    df['cell_type'] = temp['cell_type'].tolist()\n",
    "    if os.path.exists(rf\"{folder_path}/{file}\"):\n",
    "        os.remove(rf\"{folder_path}/{file}\")\n",
    "    df.to_pickle(rf\"{folder_path}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_units_df = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "assy=[]\n",
    "for wave in all_units_df['waveform']:\n",
    "    a = np.max(wave[:29])\n",
    "    b = np.max(wave[29:])\n",
    "    temp = (b-a)/(a+b)\n",
    "    assy.append(temp)\n",
    "all_units_df['assy']=None\n",
    "all_units_df['assy']=assy\n",
    "all_units_df['cell_type']=None\n",
    "all_units_df['buzaki_cell_type']=None\n",
    "\n",
    "all_units_df.loc[:,\"assy\"] = assy\n",
    "all_units_df.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_good, X_tsne, mask, and other variables are defined\n",
    "mask = (df_good['cell_type'] == 'pyramidal') & (df_good['genotype'] == 'NDNF-flp-/- and Pde1c -/-') \n",
    "#mask = (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype'] == 'NDNF-flp-/- and Pde1c -/-')\n",
    "#mask = (df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype'] == 'NDNF-flp-/- and Pde1c -/-')\n",
    "#color_hue = df_good['Averate_rate'][mask]  # Use 'Averate_rate' as hue\n",
    "\n",
    "color_hue = df_good['Averate_rate'][mask]  # Use 'Averate_rate' as hue\n",
    "X_largest = X_tsne[mask, :]  # 3D t-SNE data\n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax.scatter(X_largest[:, 0], X_largest[:, 1], X_largest[:, 2], \n",
    "                    c=color_hue, cmap='hot', vmin=0, vmax=8)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# Add color bar with range 0 to 12\n",
    "cbar = plt.colorbar(scatter, label='Averate_rate')\n",
    "\n",
    "\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "    return scatter,\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_clusters_CRs-_spi.gif', writer='pillow', fps=10)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax1.scatter(X_largest[:, 0], X_largest[:, 1], \n",
    "                    c=color_hue, cmap='hot', vmin=0, vmax=8, s=100)\n",
    "ax1.set_xlabel('t-SNE 1')\n",
    "ax1.set_ylabel('t-SNE 2')\n",
    "ax1.set_xlim([-18, 15])\n",
    "ax1.set_ylim([-20, 15])\n",
    "\n",
    "\n",
    "high_mask = (df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')  &  (df_good['Averate_rate']>2) \n",
    "low_mask = (df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')  &  (df_good['Averate_rate']<=2) \n",
    "\n",
    "# Create a DataFrame similar to iris, combining superficial and deep data\n",
    "data_superficial = pd.DataFrame({\n",
    "    'tSNE_1': X_tsne[high_mask, 0],\n",
    "    'tSNE_2': X_tsne[high_mask, 1],\n",
    "    'sub_population': 'high rate'\n",
    "})\n",
    "data_deep = pd.DataFrame({\n",
    "    'tSNE_1': X_tsne[low_mask, 0],\n",
    "    'tSNE_2': X_tsne[low_mask, 1],\n",
    "    'sub_population': 'low rate'\n",
    "})\n",
    "df_plot = pd.concat([data_superficial, data_deep], ignore_index=True)\n",
    "\n",
    "# Set up the figure\n",
    "#f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax1.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"tSNE_1\",\n",
    "    y=\"tSNE_2\",\n",
    "    hue=\"sub_population\",\n",
    "    palette=['red', 'black'],\n",
    "    thresh=0.1,\n",
    "    ax=ax1\n",
    ")\n",
    "plt.axis('equal')\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=(df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "mask=(df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') \n",
    "#mask=(df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') \n",
    "#color_hue = df_good['Averate_rate'][mask]  # Use 'Averate_rate' as hue\n",
    "\n",
    "\n",
    "color_hue = df_good['Averate_rate'][mask]  # Use 'Averate_rate' as hue\n",
    "X_largest = X_tsne[mask, :]  # 3D t-SNE data\n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax.scatter(X_largest[:, 0], X_largest[:, 1], X_largest[:, 2], \n",
    "                    c=color_hue, cmap='hot', vmin=0, vmax=8)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "# Add color bar with range 0 to 12\n",
    "cbar = plt.colorbar(scatter, label='Averate_rate')\n",
    "\n",
    "\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "    return scatter,\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_clusters_CRs+_spi.gif', writer='pillow', fps=10)\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax1.scatter(X_largest[:, 0], X_largest[:, 1], \n",
    "                    c=color_hue, cmap='hot', vmin=0, vmax=8, s=100)\n",
    "ax1.set_xlabel('t-SNE 1')\n",
    "ax1.set_ylabel('t-SNE 2')\n",
    "ax1.set_xlim([-18, 15])\n",
    "ax1.set_ylim([-20, 15])\n",
    "\n",
    "high_mask = (df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')  &  (df_good['Averate_rate']>2) \n",
    "low_mask = (df_good['cell_type'] == 'pyramidal') &  (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')  &  (df_good['Averate_rate']<=2) \n",
    "\n",
    "# Create a DataFrame similar to iris, combining superficial and deep data\n",
    "data_superficial = pd.DataFrame({\n",
    "    'tSNE_1': X_tsne[high_mask, 0],\n",
    "    'tSNE_2': X_tsne[high_mask, 1],\n",
    "    'sub_population': 'high rate'\n",
    "})\n",
    "data_deep = pd.DataFrame({\n",
    "    'tSNE_1': X_tsne[low_mask, 0],\n",
    "    'tSNE_2': X_tsne[low_mask, 1],\n",
    "    'sub_population': 'low rate'\n",
    "})\n",
    "df_plot = pd.concat([data_superficial, data_deep], ignore_index=True)\n",
    "\n",
    "# Set up the figure\n",
    "#f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax1.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"tSNE_1\",\n",
    "    y=\"tSNE_2\",\n",
    "    hue=\"sub_population\",\n",
    "    palette=['red', 'black'],\n",
    "    thresh=0.1,\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=(df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "mask_sup=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') & (df_good['sub_population'] == 'superficial') \n",
    "mask_deep=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') & (df_good['sub_population'] == 'deep')\n",
    "\n",
    "\n",
    "X_superficial = X_tsne[mask_sup, :]  # 3D t-SNE data\n",
    "X_deep = X_tsne[mask_deep, :] \n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax.scatter(X_superficial[:, 0], X_superficial[:, 1], X_superficial[:, 2], c='blue', s=20)\n",
    "scatter = ax.scatter(X_deep[:, 0], X_deep[:, 1], X_deep[:, 2], c='black', s=20)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "    return scatter,\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "# Save the animation as a GIF\n",
    "ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_clusters_CRs+_subpopulation.gif', writer='pillow', fps=10)\n",
    "# Show plot\n",
    "plt.show()\n",
    "# Create figure and 3D axes\n",
    "color1 = sns.color_palette(\"hls\", 8)[1]\n",
    "color2 = sns.color_palette(\"hls\", 8)[-2]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "#mask=(df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "mask_sup=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') & (df_good['sub_population'] == 'superficial') \n",
    "mask_deep=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-') & (df_good['sub_population'] == 'deep')\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax1.scatter(X_superficial[:, 0],X_superficial[:, 1], c=color1, s=20)\n",
    "scatter = ax1.scatter(X_deep[:, 0],X_deep[:, 1], c=color2, s=20)\n",
    "\n",
    "ax1.set_xlabel('t-SNE 1')\n",
    "ax1.set_ylabel('t-SNE 2')\n",
    "ax1.set_xlim([-18, 15])\n",
    "ax1.set_ylim([-20, 15])\n",
    "\n",
    "\n",
    "# Create a DataFrame similar to iris, combining superficial and deep data\n",
    "data_superficial = pd.DataFrame({\n",
    "    'tSNE_1': X_superficial[:, 0],\n",
    "    'tSNE_2': X_superficial[:, 1],\n",
    "    'sub_population': 'superficial'\n",
    "})\n",
    "data_deep = pd.DataFrame({\n",
    "    'tSNE_1': X_deep[:, 0],\n",
    "    'tSNE_2': X_deep[:, 1],\n",
    "    'sub_population': 'deep'\n",
    "})\n",
    "df_plot = pd.concat([data_superficial, data_deep], ignore_index=True)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "# Set up the figure\n",
    "#f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax1.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"tSNE_1\",\n",
    "    y=\"tSNE_2\",\n",
    "    hue=\"sub_population\",\n",
    "    palette=[color1, color2],\n",
    "    thresh=0.1,\n",
    "    ax=ax1\n",
    ")\n",
    "# Set transparent background\n",
    "fig.patch.set_facecolor('none')  # Transparent figure background\n",
    "ax1.set_facecolor('none')      # Transparent axes background\n",
    "plt.axis('equal')\n",
    "plt.grid(False)\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=(df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "mask_sup=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype'] == 'NDNF-flp-/- and Pde1c -/-') & (df_good['sub_population'] == 'superficial') \n",
    "mask_deep=(df_good['cell_type'] == 'pyramidal') & (df_good['genotype'] == 'NDNF-flp-/- and Pde1c -/-') & (df_good['sub_population'] == 'deep') \n",
    " \n",
    "\n",
    "X_superficial = X_tsne[mask_sup, :]  # 3D t-SNE data\n",
    "X_deep = X_tsne[mask_deep, :] \n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax.scatter(X_superficial[:, 0], X_superficial[:, 1], X_superficial[:, 2], c='blue')\n",
    "scatter = ax.scatter(X_deep[:, 0], X_deep[:, 1], X_deep[:, 2], c='black')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_zlabel('t-SNE 3')\n",
    "ax.legend().set_visible(False)\n",
    "\n",
    "\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "    return scatter,\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_clusters_CRs+_subpopulation.gif', writer='pillow', fps=10)\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create figure and 3D axes\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "# Scatter plot with 3D coordinates and color based on color_hue\n",
    "scatter = ax1.scatter(X_superficial[:, 0],X_superficial[:, 1], c=color1, s=20)\n",
    "scatter = ax1.scatter(X_deep[:, 0],X_deep[:, 1], c=color2, s=20)\n",
    "\n",
    "ax1.set_xlabel('t-SNE 1')\n",
    "ax1.set_ylabel('t-SNE 2')\n",
    "ax1.set_xlim([-18, 15])\n",
    "ax1.set_ylim([-20, 15])\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame similar to iris, combining superficial and deep data\n",
    "data_superficial = pd.DataFrame({\n",
    "    'tSNE_1': X_superficial[:, 0],\n",
    "    'tSNE_2': X_superficial[:, 1],\n",
    "    'sub_population': 'superficial'\n",
    "})\n",
    "data_deep = pd.DataFrame({\n",
    "    'tSNE_1': X_deep[:, 0],\n",
    "    'tSNE_2': X_deep[:, 1],\n",
    "    'sub_population': 'deep'\n",
    "})\n",
    "df_plot = pd.concat([data_superficial, data_deep], ignore_index=True)\n",
    "\n",
    "# Set up the figure\n",
    "#f, ax = plt.subplots(figsize=(8, 8))\n",
    "ax1.set_aspect(\"equal\")\n",
    "\n",
    "# Draw a contour plot to represent each bivariate density\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"tSNE_1\",\n",
    "    y=\"tSNE_2\",\n",
    "    hue=\"sub_population\",\n",
    "    thresh=0.1,\n",
    "    palette=[color1, color2],\n",
    "    ax=ax1\n",
    ")\n",
    "# Set transparent background\n",
    "fig.patch.set_facecolor('none')  # Transparent figure background\n",
    "ax1.set_facecolor('none')      # Transparent axes background\n",
    "plt.axis('equal')\n",
    "plt.grid(False)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask=(df_good['cell_type'] == 'pyramidal') & (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "mask= (df_good['buzaki_cell_type']=='pyramidal') & (df_good['genotype']=='NDNF-flp +/- and Pde1c +/-')\n",
    "color_hue = df_good['Information_content_rate'][mask]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # For better color handling with hue\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Assuming df_good, X_largest, and X_second_largest are defined\n",
    "# color_hue for pyramidal cells\n",
    "color_hue = df_good['Information_content_rate'][mask]\n",
    "\n",
    "X_largest = X_tsne[mask,:]\n",
    "# Plot largest cluster in blue with hue based on Information_content_rate\n",
    "sns.scatterplot(x=X_largest[:, 0], y=X_largest[:, 1], hue=color_hue, palette='cool',\n",
    "                ax=ax)\n",
    "\n",
    "# # Plot second largest cluster in red (assuming X_second_largest is defined)\n",
    "# sns.scatterplot(x=X_second_largest[:, 0], y=X_second_largest[:, 1], color='red', \n",
    "#                 label='Cluster Pyramidal (Second Largest)', ax=ax)\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_tsne and df_good are already defined from your previous steps\n",
    "# Step 3 and beyond remain unchanged until plotting\n",
    "\n",
    "# --- 3D Spinning GIF ---\n",
    "fig_3d = plt.figure(figsize=(12, 12))\n",
    "ax_3d = fig_3d.add_subplot(111, projection='3d')\n",
    "\n",
    "# Define conditions for plotting based on genotype and cell_type\n",
    "exp = \"NDNF-flp +/- and Pde1c +/-\"\n",
    "control = \"NDNF-flp-/- and Pde1c -/-\"\n",
    "\n",
    "# Masks for genotype and cell type combinations\n",
    "mask_control_pyramidal = (df_good['genotype'] == control) & (df_good['cell_type'] == 'pyramidal')\n",
    "mask_exp_pyramidal = (df_good['genotype'] == exp) & (df_good['cell_type'] == 'pyramidal')\n",
    "mask_control_interneuron = (df_good['genotype'] == control) & (df_good['cell_type'] == 'interneuron')\n",
    "mask_exp_interneuron = (df_good['genotype'] == exp) & (df_good['cell_type'] == 'interneuron')\n",
    "\n",
    "mask_control_interneuron_w = (df_good['genotype'] == control) & (df_good['cell_type'] == 'wid_spike_interneuron')\n",
    "mask_exp_interneuron_w = (df_good['genotype'] == exp) & (df_good['cell_type'] == 'wid_spike_interneuron')\n",
    "mask_noise = clusters == -1  # Noise points\n",
    "\n",
    "# # Masks for genotype and cell type combinations\n",
    "# mask_control_pyramidal = (df_good['genotype'] == control) & (df_loaded['buzaki_cell_type'] == 'pyramidal')\n",
    "# mask_exp_pyramidal = (df_good['genotype'] == exp) & (df_loaded['buzaki_cell_type'] == 'pyramidal')\n",
    "# mask_control_interneuron = (df_good['genotype'] == control) & (df_loaded['buzaki_cell_type'] == 'narrow_spike_interneurons')\n",
    "# mask_exp_interneuron = (df_good['genotype'] == exp) & (df_loaded['buzaki_cell_type'] == 'narrow_spike_interneurons')\n",
    "\n",
    "\n",
    "# Extract t-SNE coordinates for each group\n",
    "X_control_pyramidal = X_tsne[mask_control_pyramidal]\n",
    "X_exp_pyramidal = X_tsne[mask_exp_pyramidal]\n",
    "X_control_interneuron = X_tsne[mask_control_interneuron]\n",
    "X_exp_interneuron = X_tsne[mask_exp_interneuron]\n",
    "X_control_interneuron_w = X_tsne[mask_control_interneuron_w]\n",
    "X_exp_interneuron_w = X_tsne[mask_exp_interneuron_w]\n",
    "\n",
    "\n",
    "X_noise = X_tsne[mask_noise]\n",
    "\n",
    "# Plot with specified colors\n",
    "scatter1 = ax_3d.scatter(X_control_pyramidal[:, 0], X_control_pyramidal[:, 1], X_control_pyramidal[:, 2], \n",
    "                         c='blue', s=30, label='Control Pyramidal')\n",
    "scatter2 = ax_3d.scatter(X_exp_pyramidal[:, 0], X_exp_pyramidal[:, 1], X_exp_pyramidal[:, 2], \n",
    "                         c='cyan', s=30, label='Exp Pyramidal')\n",
    "scatter3 = ax_3d.scatter(X_control_interneuron[:, 0], X_control_interneuron[:, 1], X_control_interneuron[:, 2], \n",
    "                         c='red', s=30, label='Control Interneuron')\n",
    "scatter4 = ax_3d.scatter(X_exp_interneuron[:, 0], X_exp_interneuron[:, 1], X_exp_interneuron[:, 2], \n",
    "                         c='magenta', s=30, label='Exp Interneuron')\n",
    "scatter5 = ax_3d.scatter(X_control_interneuron_w[:, 0], X_control_interneuron_w[:, 1], X_control_interneuron_w[:, 2], \n",
    "                         c='green', s=30, label='Control Interneuron')\n",
    "scatter6 = ax_3d.scatter(X_exp_interneuron_w[:, 0], X_exp_interneuron_w[:, 1], X_exp_interneuron_w[:, 2], \n",
    "                         c='lime', s=30, label='Exp Interneuron')\n",
    "\n",
    "\n",
    "# scatter5 = ax_3d.scatter(X_noise[:, 0], X_noise[:, 1], X_noise[:, 2], \n",
    "#                          c='yellow', s=10, label='Noise')\n",
    "\n",
    "# Customize 3D plot\n",
    "ax_3d.set_title('t-SNE 3D Projection: Genotype and Cell Type Classification').set_visible(False)\n",
    "ax_3d.set_xlabel('t-SNE 1')\n",
    "ax_3d.set_ylabel('t-SNE 2')\n",
    "ax_3d.set_zlabel('t-SNE 3')\n",
    "ax_3d.legend().set_visible(False)\n",
    "\n",
    "# Animation function to rotate the plot\n",
    "def update(frame):\n",
    "    ax_3d.view_init(elev=15, azim=frame)  # Rotate around z-axis\n",
    "    return scatter1, scatter2, scatter3, scatter4, scatter5, scatter6\n",
    "\n",
    "# Create animation\n",
    "ani = FuncAnimation(fig_3d, update, frames=np.arange(0, 360, 2), interval=50, blit=True)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/spinning_3d_genotype_celltype.gif', writer='pillow', fps=10)\n",
    "plt.close(fig_3d)  # Close the figure to avoid displaying it statically\n",
    "\n",
    "# --- 2D Static Plot ---\n",
    "fig_2d = plt.figure(figsize=(10, 10))\n",
    "ax_2d = fig_2d.add_subplot(111)\n",
    "\n",
    "# Plot with specified colors (2D projection)\n",
    "ax_2d.scatter(X_control_pyramidal[:, 0], X_control_pyramidal[:, 1], c='blue', s=20, label='Control Pyramidal')\n",
    "ax_2d.scatter(X_exp_pyramidal[:, 0], X_exp_pyramidal[:, 1], c='cyan', s=20, label='Exp Pyramidal')\n",
    "ax_2d.scatter(X_control_interneuron[:, 0], X_control_interneuron[:, 1], c='red', s=20, label='Control Interneuron')\n",
    "ax_2d.scatter(X_exp_interneuron[:, 0], X_exp_interneuron[:, 1], c='magenta', s=20, label='Exp Interneuron')\n",
    "ax_2d.scatter(X_noise[:, 0], X_noise[:, 1], c='yellow', s=20, label='Noise')\n",
    "\n",
    "# Customize 2D plot\n",
    "ax_2d.set_title('t-SNE 2D Projection: Genotype and Cell Type Classification')\n",
    "ax_2d.set_xlabel('t-SNE 1')\n",
    "ax_2d.set_ylabel('t-SNE 2')\n",
    "ax_2d.legend()\n",
    "\n",
    "plt.axis('equal')  # Ensures equal aspect ratio\n",
    "# Adjust layout and save/show 2D plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(r'Q:\\sachuriga/CR_CA1_paper/Results/Cell_type/2d_genotype_celltype.png')  # Save as PNG\n",
    "plt.show()\n",
    "\n",
    "# Save the DataFrame\n",
    "# df_good.to_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/good_units_with_tsnLabels.pkl')\n",
    "\n",
    "# Print summary (unchanged)\n",
    "print(f\"Number of clusters found: {n_clusters}\")\n",
    "print(f\"Number of noise points: {np.sum(clusters == -1)}\")\n",
    "print(f\"Size of largest cluster (label {largest_cluster_label}): {np.sum(mask_largest)}\")\n",
    "print(f\"Size of second largest cluster (label {second_largest_cluster_label}): {np.sum(mask_second)}\")\n",
    "print(f\"Size of third largest cluster (label {third_largest_cluster_label}): {np.sum(mask_third)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_loaded=df_good\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_py = df_good[df_good['buzaki_py_cell_type']=='pyramidal']\n",
    "df = df_py\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "session = [\"A\", \"B\", \"C\", \"Total\"]\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# ... (Your existing code for loading data, filtering, and setting up the figure remains unchanged)\n",
    "test_hy = ['greater','less','greater','less','less','two-sided']\n",
    "for session in session:\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "    # Set Seaborn theme\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "\n",
    "    # Statistical comparisons for scalar metrics\n",
    "    metrics = ['Information_content_rate', 'Sparsity', 'Selectivity', 'Averate_rate', 'Field_size', 'matlab_stability_smooth1']\n",
    "\n",
    "    # Create figure with 2 rows and 6 columns\n",
    "    fig, axes = plt.subplots(2, 6, figsize=(18, 10), width_ratios=[1, 0.5, 1, 0.5, 1, 0.5])\n",
    "    axes = axes.flatten()  # Flatten for easier iteration\n",
    "\n",
    "    # Define custom colors\n",
    "    control_color = sns.color_palette(palette='flag')[-1]  # Dark blue for Control\n",
    "    exp_color = \"cyan\"  # Light blue for Experimental\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        control_values = control_df[metric].dropna()\n",
    "        exp_values = exp_df[metric].dropna()\n",
    "        \n",
    "        if len(control_values) > 0 and len(exp_values) > 0:\n",
    "            control_mean = control_values.mean()\n",
    "            exp_mean = exp_values.mean()\n",
    "            control_sem = control_values.sem()\n",
    "            exp_sem = exp_values.sem()\n",
    "            \n",
    "            print(f\"\\nComparison for {metric}:\")\n",
    "            print(f\"Control mean: {control_mean:.2f} ± {control_sem:.2f}\")\n",
    "            print(f\"Experimental mean: {exp_mean:.2f} ± {exp_sem:.2f}\")\n",
    "            \n",
    "            # Mann-Whitney U test\n",
    "            control_array = np.asarray(control_values.values, dtype=float)\n",
    "            exp_array = np.asarray(exp_values.values, dtype=float)\n",
    "\n",
    "            # Remove NaN values\n",
    "            control_clean = control_array[~np.isnan(control_array)]\n",
    "            exp_clean = exp_array[~np.isnan(exp_array)]\n",
    "\n",
    "            # Perform Mann-Whitney U test\n",
    "            #u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative='two-sided')\n",
    "\n",
    "            # Step 1: Test normality\n",
    "            shapiro_control = stats.shapiro(control_clean)\n",
    "            shapiro_exp = stats.shapiro(exp_clean)\n",
    "            print(\"Shapiro-Wilk Test - Control: p-value =\", shapiro_control.pvalue)\n",
    "            print(\"Shapiro-Wilk Test - Experimental: p-value =\", shapiro_exp.pvalue)\n",
    "\n",
    "            # Step 2: Calculate means and standard deviations\n",
    "            print(\"Control Mean:\", np.mean(control_clean), \"SD:\", np.std(control_clean, ddof=1))\n",
    "            print(\"Experimental Mean:\", np.mean(exp_clean), \"SD:\", np.std(exp_clean, ddof=1))\n",
    "\n",
    "            # Step 3: Check variance equality\n",
    "            levene_test = stats.levene(control_clean, exp_clean)\n",
    "            print(\"Levene's Test for equal variances: p-value =\", levene_test.pvalue)\n",
    "\n",
    "            # Step 4: Choose and perform test\n",
    "            alpha = 0.05\n",
    "            if shapiro_control.pvalue > alpha and shapiro_exp.pvalue > alpha:\n",
    "                print(\"Both groups are normally distributed.\")\n",
    "                if levene_test.pvalue > alpha:\n",
    "                    print(\"Variances are equal. Performing two-sample t-test.\")\n",
    "                    t_stat, t_pval = stats.ttest_ind(control_clean, exp_clean, equal_var=True)\n",
    "                    print(\"Two-sample t-test: t =\", t_stat, \"p-value =\", t_pval)\n",
    "                    if t_pval < alpha:\n",
    "                        print(\"Reject H0: Means differ significantly.\")\n",
    "                    else:\n",
    "                        print(\"Fail to reject H0: No significant difference in means.\")\n",
    "                else:\n",
    "                    print(\"Variances are unequal. Consider Welch's t-test or Mann-Whitney U.\")\n",
    "                    u_stat, p_val = stats.ttest_ind(control_clean, exp_clean, equal_var=False)\n",
    "                    print(\"Welch's t-test: t =\", t_stat, \"p-value =\", t_pval)\n",
    "                    if t_pval < alpha:\n",
    "                        print(\"Reject H0: Means differ significantly.\")\n",
    "                    else:\n",
    "                        print(\"Fail to reject H0: No significant difference in means.\")\n",
    "            else:\n",
    "                print(\"At least one group is non-normal. Performing Mann-Whitney U test.\")\n",
    "                test_name = test_hy[idx]\n",
    "                u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative=fr'{test_name}')\n",
    "                print(\"Mann-Whitney U Test: U =\", u_stat, \"p-value =\", p_val)\n",
    "                if p_val < alpha:\n",
    "                    print(\"Reject H0: Distributions differ significantly.\")\n",
    "                else:\n",
    "                    print(\"Fail to reject H0: No significant difference in distributions.\")\n",
    "            \n",
    "            # Prepare data for Seaborn plotting\n",
    "            plot_df = pd.DataFrame({\n",
    "                'value': pd.concat([control_values, exp_values]),\n",
    "                'group': ['Control'] * len(control_values) + ['Experimental'] * len(exp_values)\n",
    "            })\n",
    "            \n",
    "            # Check if deviation is \"too large\" (using coefficient of variation > 1 as threshold)\n",
    "            all_values = plot_df['value']\n",
    "            cv = all_values.std() / all_values.mean()  # Coefficient of variation\n",
    "            use_log_scale = cv > 1 and all_values.min() > 0  # Ensure positive values for log scale\n",
    "            \n",
    "            # Filter out outliers (e.g., beyond 3 standard deviations)\n",
    "            mean_val = all_values.mean()\n",
    "            std_val = all_values.std()\n",
    "            plot_df_filtered = plot_df[(plot_df['value'] >= mean_val - 3 * std_val) & \n",
    "                                       (plot_df['value'] <= mean_val + 3 * std_val)]\n",
    "            \n",
    "            # Boxplot (left subplot for each metric)\n",
    "            box_ax = axes[idx * 2]  # Left column for boxplot\n",
    "            sns.boxplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=box_ax,\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color},\n",
    "                width=0.5\n",
    "            )\n",
    "            \n",
    "            # Add individual points with matching colors\n",
    "            sns.stripplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=box_ax,\n",
    "                size=4,\n",
    "                hue='group',\n",
    "                palette={\"Control\": \"black\", \"Experimental\": \"black\"},\n",
    "                alpha=0.4,\n",
    "                jitter=0.1,\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Set title and labels for boxplot\n",
    "            box_ax.set_title(f'{metric} Comparison')\n",
    "            box_ax.set_ylabel(metric)\n",
    "            box_ax.set_xlabel('Group')\n",
    "            box_ax.yaxis.grid(False)\n",
    "            box_ax.set(xlabel=\"\")\n",
    "            \n",
    "            # Add p-value at the top of the boxplot\n",
    "            box_ax.text(0.5, 0.95, f'p = {p_val:.4f}', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='top', \n",
    "                        transform=box_ax.transAxes, \n",
    "                        fontsize=10)\n",
    "            \n",
    "            # # Add N values above each boxplot bar\n",
    "            # n_control = len(control_clean)\n",
    "            # n_exp = len(exp_clean)\n",
    "            # max_y = plot_df_filtered['value'].max()  # Get max y-value for positioning\n",
    "            # y_offset = max_y * - 0.1  # Slightly above the max value\n",
    "            # box_ax.text(0, y_offset, f'N={n_control}', \n",
    "            #             horizontalalignment='center', \n",
    "            #             fontsize=8, color=control_color)\n",
    "            # box_ax.text(1, y_offset, f'N={n_exp}', \n",
    "            #             horizontalalignment='center', \n",
    "            #             fontsize=8, color=exp_color)\n",
    "            \n",
    "            # Remove top and right spines\n",
    "            box_ax.spines['top'].set_visible(False)\n",
    "            box_ax.spines['right'].set_visible(False)\n",
    "            box_ax.spines['bottom'].set_visible(True)\n",
    "            box_ax.spines['left'].set_visible(True)\n",
    "\n",
    "            # KDE plot (right subplot for each metric) as probability density\n",
    "            kde_ax = axes[idx * 2 + 1]  # Right column for KDE\n",
    "            sns.kdeplot(\n",
    "                data=plot_df_filtered,\n",
    "                y='value',\n",
    "                hue='group',\n",
    "                ax=kde_ax,\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color},\n",
    "                fill=True,\n",
    "                alpha=0.3,\n",
    "                common_norm=False,  # Each group's KDE integrates to 1\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Match y-axis limits with boxplot\n",
    "            kde_ax.set_ylim(box_ax.get_ylim())\n",
    "            kde_ax.set_xticks([])  # Remove x-axis ticks\n",
    "            kde_ax.set_yticks([])  # Remove y-axis ticks\n",
    "            kde_ax.set_xlabel('')\n",
    "            kde_ax.set_ylabel('')\n",
    "            \n",
    "            # Remove spines for KDE plot\n",
    "            kde_ax.spines['top'].set_visible(False)\n",
    "            kde_ax.spines['right'].set_visible(False)\n",
    "            kde_ax.spines['bottom'].set_visible(False)\n",
    "            kde_ax.spines['left'].set_visible(False)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# ... (Your existing code for loading data, filtering, and setting up variables remains unchanged)\n",
    "# Assuming df, control_ids, exp_ids, and session are defined as in your original code\n",
    "\n",
    "df_good = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_py = df_good[df_good['buzaki_py_cell_type']=='pyramidal']\n",
    "df = df_py\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\"]\n",
    "\n",
    "\n",
    "for session in sessions:\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "    # Set Seaborn theme\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "\n",
    "    # Statistical comparisons for scalar metrics\n",
    "    metrics = ['Information_content_rate', 'Sparsity', 'Selectivity', 'Averate_rate', 'Field_size', 'matlab_stability_smooth1']\n",
    "    metrics_labels = ['Information content rate (spikes/bit)', 'Sparsity', 'Selectivity', 'Averate firing rate (Hz)', 'Field size (percentage)', 'Within session stability']\n",
    "    # Create figure with 1 row and 6 columns (one per metric)\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(18, 5))\n",
    "    axes = axes.flatten()  # Flatten for easier iteration\n",
    "\n",
    "    # Define custom colors\n",
    "    # control_color = sns.color_palette(palette='flag')[-1]  # Dark blue for Control\n",
    "    # exp_color = \"cyan\"  # Light blue for Experimental\n",
    "    control_color = '#2b4d5e'  # Dark blue for Control\n",
    "    exp_color = '#BC554E'  # Light blue for Experimental\n",
    "\n",
    "    i4label=0\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        control_values = control_df[metric].dropna()\n",
    "        exp_values = exp_df[metric].dropna()\n",
    "        \n",
    "        if len(control_values) > 0 and len(exp_values) > 0:\n",
    "            control_mean = control_values.mean()\n",
    "            control_sem = control_values.sem()\n",
    "            exp_mean = exp_values.mean()\n",
    "            exp_sem = exp_values.sem()\n",
    "            \n",
    "            print(f\"\\nComparison for {metric}:\")\n",
    "            print(f\"Control mean: {control_mean:.2f} ± {control_sem:.2f}\")\n",
    "            print(f\"Experimental mean: {exp_mean:.2f} ± {exp_sem:.2f}\")\n",
    "            \n",
    "            # Mann-Whitney U test\n",
    "            control_array = np.asarray(control_values.values, dtype=float)\n",
    "            exp_array = np.asarray(exp_values.values, dtype=float)\n",
    "\n",
    "            # Remove NaN values\n",
    "            control_clean = control_array[~np.isnan(control_array)]\n",
    "            exp_clean = exp_array[~np.isnan(exp_array)]\n",
    "\n",
    "            # Perform Mann-Whitney U test\n",
    "            u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative='two-sided')\n",
    "\n",
    "            print(f\"Mann-Whitney U statistic: {u_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "            \n",
    "            # Prepare data for Seaborn plotting\n",
    "            plot_df = pd.DataFrame({\n",
    "                'value': pd.concat([control_values, exp_values]),\n",
    "                'group': ['Control'] * len(control_values) + ['Experimental'] * len(exp_values)\n",
    "            })\n",
    "            \n",
    "            # Check if deviation is \"too large\" (using coefficient of variation > 1 as threshold)\n",
    "            all_values = plot_df['value']\n",
    "            cv = all_values.std() / all_values.mean()  # Coefficient of variation\n",
    "            use_log_scale = cv > 1 and all_values.min() > 0  # Ensure positive values for log scale\n",
    "            \n",
    "            # Filter out outliers (e.g., beyond 3 standard deviations)\n",
    "            mean_val = all_values.mean()\n",
    "            std_val = all_values.std()\n",
    "            plot_df_filtered = plot_df[(plot_df['value'] >= mean_val - 3 * std_val) & \n",
    "                                       (plot_df['value'] <= mean_val + 3 * std_val)]\n",
    "            \n",
    "            # Bar plot\n",
    "            ax = axes[idx]\n",
    "            sns.barplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=ax,\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color},\n",
    "                errorbar='se',  # Show SEM as error bars\n",
    "                capsize=0.1,\n",
    "                alpha=1,\n",
    "            )\n",
    "            \n",
    "            # Add individual points with matching colors\n",
    "            sns.stripplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=ax,\n",
    "                size=2,\n",
    "                hue='group',\n",
    "                palette={\"Control\": \"#ECE0CA\", \"Experimental\": \"#ECE0CA\"},\n",
    "                alpha=1,\n",
    "                jitter=0.2,\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Set title and labels for bar plot\n",
    "            #ax.set_title(f'{metric} Comparison')\n",
    "            ax.set_ylabel(metrics_labels[idx])\n",
    "            ax.set_xlabel('Group')\n",
    "            ax.yaxis.grid(False)\n",
    "            ax.set(xlabel=\"\")\n",
    "            ax.set_ylim(0)\n",
    "            ax.set_xticklabels(['CRs +', 'CRs -'])\n",
    "            # Add p-value at the top of the bar plot\n",
    "            ax.text(0.5, 0.95, f'p = {p_val:.4f}', \n",
    "                    horizontalalignment='center', \n",
    "                    verticalalignment='top', \n",
    "                    transform=ax.transAxes, \n",
    "                    fontsize=10)\n",
    "            \n",
    "            # Remove top and right spines\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['bottom'].set_visible(True)\n",
    "            ax.spines['left'].set_visible(True)\n",
    "        i4label =+ 1\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap_ax,plot_path\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,Speed_filtered_spikes\n",
    "\n",
    "base_nwb_folder = fr\"S:\\Sachuriga\\nwb\\test4neo\"\n",
    "df=control_df.reset_index(drop=True)\n",
    "\n",
    "sublayer = \"superficial\"\n",
    "if sublayer:\n",
    "    df = control_df[control_df['sub_population']==sublayer].reset_index(drop=True)\n",
    "map_color = \"jet\"\n",
    "\n",
    "for temp_name in np.unique(df['session_id']):\n",
    "    print(temp_name)\n",
    "    npdata = nap.load_file(fr\"{base_nwb_folder }/{temp_name}\")\n",
    "    pos_cord = load_speed_fromNWB(npdata['XY_mid_brain'])\n",
    "\n",
    "    raw_pos,combined_array, mask,speeds,smoothed_speed,filtered_speed = pos2speed(pos_cord[:,0], # times\n",
    "                            pos_cord[:,1], # x\n",
    "                            pos_cord[:,2], # y\n",
    "                            filter_speed=True, \n",
    "                            min_speed = 0.05)\n",
    "    \n",
    "    \n",
    "\n",
    "    temp_table = df[df['session_id']==temp_name]\n",
    "    for i in range(len(temp_table)):\n",
    "\n",
    "        spike_times = Speed_filtered_spikes(temp_table['spike_times'].iloc[i],\n",
    "                            pos_cord[:,0],mask)\n",
    "        \n",
    "        maps = mapp.SpatialMap(box_size=[1.0, 1.0], bin_size=0.01, smoothing=0.1)\n",
    "        rate_map = maps.rate_map(combined_array[:,1], combined_array[:,2], combined_array[:,0], spike_times)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, xlim=[0, 1], ylim=[0, 1], aspect=1)\n",
    "        ax.imshow(rate_map, interpolation='none', origin='upper',\n",
    "                extent=(0, 1, 0, 1), vmin=0.01, cmap=fr'{map_color}')\n",
    "        ax.grid(False)\n",
    "                    # Remove top and right spines\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        id=temp_table.index[i]\n",
    "        ax.set_axis_off()\n",
    "        if sublayer:\n",
    "            fig.savefig(fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\control/{sublayer}/{map_color}/{id}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        else:\n",
    "            fig.savefig(fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\control/{map_color}/{id}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设你的数据是一个Series\n",
    "df = df.reset_index(drop=True)['Information_content_rate']\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def group_indices_by_step(df_col, step=0.075):\n",
    "    used_indices = set()\n",
    "    result = []\n",
    "    values = df_col.copy()\n",
    "    max_val = values.max()\n",
    "\n",
    "    while len(used_indices) < len(values):\n",
    "        remaining = values[~values.index.isin(used_indices)]\n",
    "        if remaining.empty:\n",
    "            break\n",
    "\n",
    "        current_group = []\n",
    "        current_val = remaining.min()\n",
    "        current_idx = remaining.idxmin()\n",
    "        current_group.append(current_idx)\n",
    "        used_indices.add(current_idx)\n",
    "\n",
    "        while True:\n",
    "            target_val = current_val + step\n",
    "            remaining = values[~values.index.isin(used_indices)]\n",
    "            if remaining.empty:\n",
    "                break\n",
    "\n",
    "            # 找到大于等于 target_val 的值中最接近 target_val 的那个\n",
    "            diffs = remaining - target_val\n",
    "            diffs = diffs[diffs >= 0]\n",
    "            if diffs.empty:\n",
    "                break\n",
    "\n",
    "            next_idx = diffs.idxmin()\n",
    "            current_val = values[next_idx]\n",
    "            current_group.append(next_idx)\n",
    "            used_indices.add(next_idx)\n",
    "\n",
    "        result.append(current_group)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "results = group_indices_by_step(df)\n",
    "results\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "\n",
    "# Function to load and plot an image with dynamic size adjustment\n",
    "def plot_image_at_xy(ax, img_path, x, y, max_size=0.09):\n",
    "    if os.path.exists(img_path):\n",
    "        img = plt.imread(img_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        aspect_ratio = img_width / img_height\n",
    "\n",
    "        # Calculate zoom based on max_size and aspect ratio\n",
    "        trans = ax.transData\n",
    "        fig = ax.get_figure()\n",
    "        dpi = fig.dpi\n",
    "        xlim = ax.get_xlim()\n",
    "        data_width = xlim[1] - xlim[0]\n",
    "        bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axes_width_pixels = bbox.width * dpi\n",
    "        pixels_per_data = axes_width_pixels / data_width\n",
    "        size_pixels = max_size * pixels_per_data\n",
    "        zoom = size_pixels / max(img_width, img_height / aspect_ratio)\n",
    "\n",
    "        imagebox = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0)\n",
    "        ax.add_artist(ab)\n",
    "        return ab\n",
    "    else:\n",
    "        print(f\"Image {img_path} not found\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a figure and axis with increased height\n",
    "fig, ax = plt.subplots(figsize=(24, 8.5))\n",
    "map_color='jet'\n",
    "# Assuming matrix and data are defined elsewhere\n",
    "# Example placeholder for matrix and data\n",
    "i_row=0\n",
    "base_y = 0.35\n",
    "y_step = 0.5\n",
    "# Iterate through each bin (column of the matrix)\n",
    "\n",
    "for indices in results:\n",
    "    y_coord = base_y + (i_row * y_step)\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        values = [df[i] for i in indices]\n",
    "        num_ratemaps = len(indices)\n",
    "        for i, (idx, value) in enumerate(zip(indices, values)):\n",
    "            if sublayer:\n",
    "                img_path = fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\control/{sublayer}/{map_color}/{idx}.png\"\n",
    "            else:\n",
    "\n",
    "                img_path = fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\control/{map_color}/{idx}.png\"\n",
    "\n",
    "            plot_image_at_xy(ax, img_path, value, y_coord,  max_size=0.014)\n",
    "    \n",
    "    i_row += 1\n",
    "# # Set plot limits with increased y-range\n",
    "ax.set_xlim(0, 4.5)\n",
    "ax.set_ylim(0, 8.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Set labels and title\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.set_xlabel(\"Information Content Rate (spikes / bit)\", fontsize=24)\n",
    "# Add vertical dashed lines at x = [1, 2, 3, 4]\n",
    "ax.set_yticks([])\n",
    "ax.vlines(x=[1, 2, 3, 4], ymin=0, ymax=8.5, colors='grey', linestyles='dashed', linewidth=3)\n",
    "# Remove y-ticks since we're using bin labels\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynapple as nap\n",
    "import numpy as np\n",
    "import os \n",
    "os.chdir(r'Q:\\sachuriga\\Sachuriga_Python/quattrocolo-nwb4fp\\src')\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap_ax,plot_path\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,Speed_filtered_spikes\n",
    "map_color='jet'\n",
    "base_nwb_folder = fr\"S:\\Sachuriga\\nwb\\test4neo\"\n",
    "df = exp_df.reset_index(drop=True)\n",
    "\n",
    "sublayer = \"deep\"\n",
    "if sublayer:\n",
    "    df = exp_df[exp_df['sub_population']==sublayer].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "for temp_name in np.unique(df['session_id']):\n",
    "    print(temp_name)\n",
    "    npdata = nap.load_file(fr\"{base_nwb_folder }/{temp_name}\")\n",
    "    pos_cord = load_speed_fromNWB(npdata['XY_mid_brain'])\n",
    "\n",
    "    raw_pos,combined_array, mask,speeds,smoothed_speed,filtered_speed = pos2speed(pos_cord[:,0], # times\n",
    "                            pos_cord[:,1], # x\n",
    "                            pos_cord[:,2], # y\n",
    "                            filter_speed=True, \n",
    "                            min_speed = 0.05)\n",
    "    \n",
    "    \n",
    "\n",
    "    temp_table = df[df['session_id']==temp_name]\n",
    "    for i in range(len(temp_table)):\n",
    "\n",
    "        spike_times = Speed_filtered_spikes(temp_table['spike_times'].iloc[i],\n",
    "                            pos_cord[:,0],mask)\n",
    "        \n",
    "        maps = mapp.SpatialMap(box_size=[1.0, 1.0], bin_size=0.01, smoothing=0.1)\n",
    "        rate_map = maps.rate_map(combined_array[:,1], combined_array[:,2], combined_array[:,0], spike_times)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, xlim=[0, 1], ylim=[0, 1], aspect=1)\n",
    "        ax.imshow(rate_map, interpolation='none', origin='upper',\n",
    "                extent=(0, 1, 0, 1), vmin=0.01, cmap=fr'{map_color}')\n",
    "        ax.grid(False)\n",
    "                    # Remove top and right spines\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        id=temp_table.index[i]\n",
    "        ax.set_axis_off()\n",
    "        if sublayer:\n",
    "            fig.savefig(fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\exp/{sublayer}/{map_color}/{id}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        else:\n",
    "            fig.savefig(fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\exp/{map_color}/{id}.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设你的数据是一个Series\n",
    "df =  df.reset_index(drop=True)['Information_content_rate']\n",
    "\n",
    "\n",
    "def group_indices_by_step(df_col, step=0.075):\n",
    "    used_indices = set()\n",
    "    result = []\n",
    "    values = df_col.copy()\n",
    "    max_val = values.max()\n",
    "\n",
    "    while len(used_indices) < len(values):\n",
    "        remaining = values[~values.index.isin(used_indices)]\n",
    "        if remaining.empty:\n",
    "            break\n",
    "\n",
    "        current_group = []\n",
    "        current_val = remaining.min()\n",
    "        current_idx = remaining.idxmin()\n",
    "        current_group.append(current_idx)\n",
    "        used_indices.add(current_idx)\n",
    "\n",
    "        while True:\n",
    "            target_val = current_val + step\n",
    "            remaining = values[~values.index.isin(used_indices)]\n",
    "            if remaining.empty:\n",
    "                break\n",
    "\n",
    "            # 找到大于等于 target_val 的值中最接近 target_val 的那个\n",
    "            diffs = remaining - target_val\n",
    "            diffs = diffs[diffs >= 0]\n",
    "            if diffs.empty:\n",
    "                break\n",
    "\n",
    "            next_idx = diffs.idxmin()\n",
    "            current_val = values[next_idx]\n",
    "            current_group.append(next_idx)\n",
    "            used_indices.add(next_idx)\n",
    "\n",
    "        result.append(current_group)\n",
    "\n",
    "    return result\n",
    "\n",
    "results = group_indices_by_step(df)\n",
    "results\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import os\n",
    "\n",
    "# Function to load and plot an image with dynamic size adjustment\n",
    "def plot_image_at_xy(ax, img_path, x, y, max_size=0.09):\n",
    "    if os.path.exists(img_path):\n",
    "        img = plt.imread(img_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        aspect_ratio = img_width / img_height\n",
    "\n",
    "        # Calculate zoom based on max_size and aspect ratio\n",
    "        trans = ax.transData\n",
    "        fig = ax.get_figure()\n",
    "        dpi = fig.dpi\n",
    "        xlim = ax.get_xlim()\n",
    "        data_width = xlim[1] - xlim[0]\n",
    "        bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axes_width_pixels = bbox.width * dpi\n",
    "        pixels_per_data = axes_width_pixels / data_width\n",
    "        size_pixels = max_size * pixels_per_data\n",
    "        zoom = size_pixels / max(img_width, img_height / aspect_ratio)\n",
    "\n",
    "        imagebox = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(imagebox, (x, y), frameon=False, pad=0)\n",
    "        ax.add_artist(ab)\n",
    "        return ab\n",
    "    else:\n",
    "        print(f\"Image {img_path} not found\")\n",
    "        return None\n",
    "\n",
    "# Create a figure and axis with increased height\n",
    "fig, ax = plt.subplots(figsize=(24, 8.5))\n",
    "\n",
    "# Assuming matrix and data are defined elsewhere\n",
    "# Example placeholder for matrix and data\n",
    "i_row=0\n",
    "base_y = 0.35\n",
    "y_step = 0.5\n",
    "# Iterate through each bin (column of the matrix)\n",
    "\n",
    "for indices in results:\n",
    "    y_coord = base_y + (i_row * y_step)\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        values = [df[i] for i in indices]\n",
    "        num_ratemaps = len(indices)\n",
    "        for i, (idx, value) in enumerate(zip(indices, values)):\n",
    "            if sublayer:\n",
    "                img_path = fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\exp\\{sublayer}/{map_color}/{idx}.png\"\n",
    "            else:\n",
    "\n",
    "                img_path = fr\"Q:\\sachuriga\\CR_CA1_paper\\Results\\rate map histogram\\exp\\/{map_color}/{idx}.png\"\n",
    "\n",
    "            plot_image_at_xy(ax, img_path, value, y_coord,  max_size=0.014)\n",
    "    i_row += 1\n",
    "\n",
    "# # Set plot limits with increased y-range\n",
    "ax.set_xlim(0, 4.5)\n",
    "ax.set_ylim(0, 8.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "ax.spines['left'].set_visible(False)\n",
    "# Set labels and title\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "ax.set_xlabel(\"Information Content Rate (spikes / bit)\", fontsize=24)\n",
    "# Add vertical dashed lines at x = [1, 2, 3, 4]\n",
    "ax.set_yticks([])\n",
    "ax.vlines(x=[1, 2, 3, 4], ymin=0, ymax=8.5, colors='grey', linestyles='dashed', linewidth=3)\n",
    "# Set labels and title\n",
    "\n",
    "# Remove y-ticks since we're using bin labels\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_py = df_good[df_good['cell_type'] == \"interneuron\"]\n",
    "df = df_py\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "session = [\"A\", \"B\", \"C\", \"Total\"]\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# ... (Your existing code for loading data, filtering, and setting up the figure remains unchanged)\n",
    "\n",
    "for session in session:\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "\n",
    "    # Separate into control and experimental groups\n",
    "    control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "    exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "\n",
    "    # Set Seaborn theme\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "\n",
    "    # Statistical comparisons for scalar metrics\n",
    "    metrics = ['matlab_speedScores', 'Averate_rate']\n",
    "\n",
    "    # Create figure with 2 rows and 6 columns\n",
    "    fig, axes = plt.subplots(2, 6, figsize=(18, 10), width_ratios=[1, 0.5, 1, 0.5, 1, 0.5])\n",
    "    axes = axes.flatten()  # Flatten for easier iteration\n",
    "\n",
    "    # Define custom colors\n",
    "    control_color = \"red\"  # Dark blue for Control\n",
    "    exp_color = \"magenta\"  # Light blue for Experimental\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        control_values = control_df[metric].dropna()\n",
    "        exp_values = exp_df[metric].dropna()\n",
    "        \n",
    "        if len(control_values) > 0 and len(exp_values) > 0:\n",
    "            control_mean = control_values.mean()\n",
    "            exp_mean = exp_values.mean()\n",
    "            control_sem = control_values.sem()\n",
    "            exp_sem = exp_values.sem()\n",
    "            \n",
    "            print(f\"\\nComparison for {metric}:\")\n",
    "            print(f\"Control mean: {control_mean:.2f} ± {control_sem:.2f}\")\n",
    "            print(f\"Experimental mean: {exp_mean:.2f} ± {exp_sem:.2f}\")\n",
    "            \n",
    "            # Mann-Whitney U test\n",
    "            control_array = np.asarray(control_values.values, dtype=float)\n",
    "            exp_array = np.asarray(exp_values.values, dtype=float)\n",
    "\n",
    "            # Remove NaN values\n",
    "            control_clean = control_array[~np.isnan(control_array)]\n",
    "            exp_clean = exp_array[~np.isnan(exp_array)]\n",
    "\n",
    "            # Perform Mann-Whitney U test\n",
    "            u_stat, p_val = stats.mannwhitneyu(control_clean, exp_clean, alternative='two-sided')\n",
    "\n",
    "            print(f\"Mann-Whitney U statistic: {u_stat:.2f}, p-value: {p_val:.4f}\")\n",
    "            \n",
    "            # Prepare data for Seaborn plotting\n",
    "            plot_df = pd.DataFrame({\n",
    "                'value': pd.concat([control_values, exp_values]),\n",
    "                'group': ['Control'] * len(control_values) + ['Experimental'] * len(exp_values)\n",
    "            })\n",
    "            \n",
    "            # Check if deviation is \"too large\" (using coefficient of variation > 1 as threshold)\n",
    "            all_values = plot_df['value']\n",
    "            cv = all_values.std() / all_values.mean()  # Coefficient of variation\n",
    "            use_log_scale = cv > 1 and all_values.min() > 0  # Ensure positive values for log scale\n",
    "            \n",
    "            # Filter out outliers (e.g., beyond 3 standard deviations)\n",
    "            mean_val = all_values.mean()\n",
    "            std_val = all_values.std()\n",
    "            plot_df_filtered = plot_df[(plot_df['value'] >= mean_val - 3 * std_val) & \n",
    "                                       (plot_df['value'] <= mean_val + 3 * std_val)]\n",
    "            \n",
    "            # Boxplot (left subplot for each metric)\n",
    "            box_ax = axes[idx * 2]  # Left column for boxplot\n",
    "            sns.boxplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=box_ax,\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color},\n",
    "                width=0.5\n",
    "            )\n",
    "            \n",
    "            # Add individual points with matching colors\n",
    "            sns.stripplot(\n",
    "                data=plot_df_filtered,\n",
    "                x='group',\n",
    "                y='value',\n",
    "                ax=box_ax,\n",
    "                size=4,\n",
    "                hue='group',\n",
    "                palette={\"Control\": \"black\", \"Experimental\": \"black\"},\n",
    "                alpha=0.4,\n",
    "                jitter=0.1,\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Set title and labels for boxplot\n",
    "            box_ax.set_title(f'{metric} Comparison')\n",
    "            box_ax.set_ylabel(metric)\n",
    "            box_ax.set_xlabel('Group')\n",
    "            box_ax.yaxis.grid(False)\n",
    "            box_ax.set(xlabel=\"\")\n",
    "            \n",
    "            # Add p-value at the top of the boxplot\n",
    "            box_ax.text(0.5, 0.95, f'p = {p_val:.4f}', \n",
    "                        horizontalalignment='center', \n",
    "                        verticalalignment='top', \n",
    "                        transform=box_ax.transAxes, \n",
    "                        fontsize=10)\n",
    "        \n",
    "            \n",
    "            # Remove top and right spines\n",
    "            box_ax.spines['top'].set_visible(False)\n",
    "            box_ax.spines['right'].set_visible(False)\n",
    "            box_ax.spines['bottom'].set_visible(True)\n",
    "            box_ax.spines['left'].set_visible(True)\n",
    "\n",
    "            # KDE plot (right subplot for each metric) as probability density\n",
    "            kde_ax = axes[idx * 2 + 1]  # Right column for KDE\n",
    "            sns.kdeplot(\n",
    "                data=plot_df_filtered,\n",
    "                y='value',\n",
    "                hue='group',\n",
    "                ax=kde_ax,\n",
    "                palette={\"Control\": control_color, \"Experimental\": exp_color},\n",
    "                fill=True,\n",
    "                alpha=0.3,\n",
    "                common_norm=False,  # Each group's KDE integrates to 1\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Match y-axis limits with boxplot\n",
    "            kde_ax.set_ylim(box_ax.get_ylim())\n",
    "            kde_ax.set_xticks([])  # Remove x-axis ticks\n",
    "            kde_ax.set_yticks([])  # Remove y-axis ticks\n",
    "            kde_ax.set_xlabel('')\n",
    "            kde_ax.set_ylabel('')\n",
    "            \n",
    "            # Remove spines for KDE plot\n",
    "            kde_ax.spines['top'].set_visible(False)\n",
    "            kde_ax.spines['right'].set_visible(False)\n",
    "            kde_ax.spines['bottom'].set_visible(False)\n",
    "            kde_ax.spines['left'].set_visible(False)\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "len(df_loaded)\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_py = df_good[df_loaded['buzaki_py_cell_type']=='pyramidal']\n",
    "df = df_py\n",
    "\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\", \"B\", \"C\", \"Total\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "spi = 1.69\n",
    "for idx, session in enumerate(sessions):\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['h_0_place_cell'] == 1) & \n",
    "                                      (control_df['Information_content_rate'] >= spi) & \n",
    "                                      (control_df['matlab_maxfsize'] >= 20) ]\n",
    "        exp_df_place = exp_df[(exp_df['h_0_place_cell'] == 1) & \n",
    "                              (exp_df['Information_content_rate'] >= spi) & \n",
    "                              (exp_df['matlab_maxfsize'] >= 20) ]\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['h_0_place_cell'] == 1) & \n",
    "                                      (control_df['Information_content_rate'] >= spi) & \n",
    "                                      (control_df['matlab_maxfsize'] >= 20) ]\n",
    "        exp_df_place = exp_df[(exp_df['h_0_place_cell'] == 1) & \n",
    "                              (exp_df['Information_content_rate'] >= spi) & \n",
    "                              (exp_df['matlab_maxfsize'] >= 20) ]\n",
    "\n",
    "    # Calculate numbers for pie charts\n",
    "    control_place = len(control_df_place)\n",
    "    control_non_place = len(control_df) - control_place\n",
    "    exp_place = len(exp_df_place)\n",
    "    exp_non_place = len(exp_df) - exp_place\n",
    "\n",
    "    # Z-Test for Two Proportions\n",
    "    control_successes = control_place  # Number of place cells in control\n",
    "    control_trials = len(control_df)   # Total pyramidal cells in control\n",
    "    exp_successes = exp_place          # Number of place cells in experimental\n",
    "    exp_trials = len(exp_df)           # Total pyramidal cells in experimental\n",
    "\n",
    "    # Proportions\n",
    "    p1 = control_successes / control_trials if control_trials > 0 else 0\n",
    "    p2 = exp_successes / exp_trials if exp_trials > 0 else 0\n",
    "    p_pooled = (control_successes + exp_successes) / (control_trials + exp_trials) if (control_trials + exp_trials) > 0 else 0\n",
    "\n",
    "    from scipy.stats import binomtest\n",
    "    result = binomtest(exp_place, len(exp_df), p=(control_place /len(control_df)), alternative='less')\n",
    "    p_value = result.pvalue\n",
    "    # Data for pie charts\n",
    "    control_data = [control_place, control_non_place]\n",
    "    exp_data = [exp_place, exp_non_place]\n",
    "    labels = ['Place Cells', 'Non-Place Cells']\n",
    "    colors = ['blue', 'lightblue']\n",
    "    colors1 = ['cyan', 'lightcyan']\n",
    "\n",
    "    # Create pie charts\n",
    "    ax = axes[idx]\n",
    "    ax.pie(control_data, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(-1, 0))\n",
    "    ax.pie(exp_data, labels=labels, colors=colors1, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(1, 0))\n",
    "    \n",
    "    # Add title and p-value\n",
    "    ax.set_title(f'Session {session}\\np-value: {p_value:.4f}', pad=20)\n",
    "    \n",
    "    # Add group labels\n",
    "    ax.text(-1, 1.2, 'Control', ha='center')\n",
    "    ax.text(1, 1.2, 'Experimental', ha='center')\n",
    "\n",
    "#fig.savefig(fr'{base_folder}/Functional_number_of_placecells.eps', format='eps', bbox_inches='tight')\n",
    "#fig.savefig(fr'{base_folder}/Functional_number_of_placecells.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_loaded is already defined\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/good_units_with_tsnLabels.pkl')\n",
    "len(df_loaded)\n",
    "df_good = df_loaded[df_loaded['unit_quality']==\"good\"]\n",
    "df_py = df_good[df_good['cell_type']==\"interneuron\"]\n",
    "df=df_py\n",
    "\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\", \"B\", \"C\", \"Total\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, session in enumerate(sessions):\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['matlab_speedScores'] >= 0.3)]\n",
    "        exp_df_place = exp_df[(exp_df['matlab_speedScores'] >= 0.3)]\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['matlab_speedScores'] >= 0.3)]\n",
    "        exp_df_place = exp_df[(exp_df['matlab_speedScores'] >= 0.3)]\n",
    "\n",
    "    # Calculate numbers for pie charts\n",
    "    control_place = len(control_df_place)\n",
    "    control_non_place = len(control_df) - control_place\n",
    "    exp_place = len(exp_df_place)\n",
    "    exp_non_place = len(exp_df) - exp_place\n",
    "\n",
    "    # Binomial test\n",
    "    control_successes = control_place\n",
    "    control_trials = len(control_df)\n",
    "    exp_successes = exp_place\n",
    "    exp_trials = len(exp_df)\n",
    "\n",
    "    # Control proportion as null hypothesis\n",
    "    p0 = control_successes / control_trials if control_trials > 0 else 0\n",
    "    result = stats.binomtest(exp_successes, exp_trials, p=p0, alternative='two-sided')\n",
    "    p_value = result.pvalue\n",
    "\n",
    "    # Data for pie charts\n",
    "    control_data = [control_place, control_non_place]\n",
    "    exp_data = [exp_place, exp_non_place]\n",
    "    labels = ['Speend Cells', 'Non-Speed Cells']\n",
    "    colors = ['red', 'lightcoral']  # instead of 'red', 'lightred'\n",
    "    colors1 = ['magenta', 'lightpink']  # instead of 'magenta', 'lightmagenta'\n",
    "\n",
    "    # Create pie charts\n",
    "    ax = axes[idx]\n",
    "    ax.pie(control_data, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(-1, 0))\n",
    "    ax.pie(exp_data, labels=labels, colors=colors1, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(1, 0))\n",
    "    \n",
    "    # Add title and p-value\n",
    "    ax.set_title(f'Session {session}\\np-value: {p_value:.4f}', pad=20)\n",
    "    \n",
    "    # Add group labels\n",
    "    ax.text(-1, 1.2, 'Control', ha='center')\n",
    "    ax.text(1, 1.2, 'Experimental', ha='center')\n",
    "fig.savefig(fr'{base_folder}/Functional_number_of_speedcells.eps', format='eps', bbox_inches='tight')\n",
    "fig.savefig(fr'{base_folder}/Functional_number_of_speedcells.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df = df_good\n",
    "base_folder = r\"Q:\\sachuriga\\CR_CA1_paper\\Results\\Cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\", \"B\", \"C\", \"Total\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, session in enumerate(sessions):\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_py = control_df[control_df['cell_type'] == \"pyramidal\"]\n",
    "        control_df_int = control_df[(control_df['cell_type'] == \"interneuron\")]\n",
    "        exp_df_py = exp_df[exp_df['cell_type'] == \"pyramidal\"]\n",
    "        exp_df_int = exp_df[(exp_df['cell_type'] == \"interneuron\")]\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_py = control_df[control_df['cell_type'] == \"pyramidal\"]\n",
    "        control_df_int = control_df[(control_df['cell_type'] == \"interneuron\")]\n",
    "        exp_df_py = exp_df[exp_df['cell_type'] == \"pyramidal\"]\n",
    "        exp_df_int = exp_df[(exp_df['cell_type'] == \"interneuron\")]\n",
    "\n",
    "    # Calculate numbers for pie charts\n",
    "    control_py = len(control_df_py)\n",
    "    control_int = len(control_df_int)\n",
    "    exp_py = len(exp_df_py)\n",
    "    exp_int = len(exp_df_int)\n",
    "\n",
    "    # Z-Test for Two Proportions\n",
    "    control_successes = control_py  # Number of pyramidal cells in control\n",
    "    control_trials = control_py + control_int  # Total cells in control\n",
    "    exp_successes = exp_py  # Number of pyramidal cells in experimental\n",
    "    exp_trials = exp_py + exp_int  # Total cells in experimental\n",
    "\n",
    "    # Proportions\n",
    "    p1 = control_successes / control_trials if control_trials > 0 else 0\n",
    "    p2 = exp_successes / exp_trials if exp_trials > 0 else 0\n",
    "    p_pooled = (control_successes + exp_successes) / (control_trials + exp_trials) if (control_trials + exp_trials) > 0 else 0\n",
    "\n",
    "    # Standard error\n",
    "    if p_pooled == 0 or p_pooled == 1 or control_trials == 0 or exp_trials == 0:\n",
    "        z_stat = 0\n",
    "        p_value = 1.0  # No difference if proportions are 0 or 1, or no data\n",
    "    else:\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/control_trials + 1/exp_trials))\n",
    "        z_stat = (p1 - p2) / se if se != 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))  # Two-tailed test\n",
    "\n",
    "    # Data for pie charts\n",
    "    control_data = [control_successes, control_int]\n",
    "    exp_data = [exp_successes, exp_int]\n",
    "\n",
    "    labels = ['Pyramidal', 'Interneuron']\n",
    "    colors = ['blue', 'red']\n",
    "    colors1 = ['cyan', 'magenta']\n",
    "\n",
    "    # Create pie charts\n",
    "    ax = axes[idx]\n",
    "    ax.pie(control_data, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(-1, 0))\n",
    "    ax.pie(exp_data, labels=labels, colors=colors1, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(1, 0))\n",
    "    \n",
    "    # Add title and p-value\n",
    "    ax.set_title(f'Session {session}\\np-value: {p_value:.4f}', pad=20)\n",
    "    \n",
    "    # Add group labels\n",
    "    ax.text(-1, 1.2, 'Control', ha='center')\n",
    "    ax.text(1, 1.2, 'Experimental', ha='center')\n",
    "\n",
    "fig.savefig(fr'{base_folder}/PyvsInt.eps', format='eps', bbox_inches='tight')\n",
    "fig.savefig(fr'{base_folder}/PyvsInt.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/functional_properties_with_python_measurements.pkl')\n",
    "len(df_loaded)\n",
    "df_good = df_loaded[df_loaded['unit_quality'] == \"good\"]\n",
    "df_py = df_good[df_good['cell_type'] == \"pyramidal\"]\n",
    "df = df_py\n",
    "\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "axes = axes\n",
    "spi = 1.69\n",
    "for idx, session in enumerate(sessions):\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['h_0_place_cell'] == 1) & \n",
    "                                      (control_df['Information_content_rate'] >= spi) & \n",
    "                                      (control_df['matlab_maxfsize'] >= 20) &\n",
    "                                      (control_df['firing_range'] < 10)]\n",
    "        exp_df_place = exp_df[(exp_df['h_0_place_cell'] == 1) & \n",
    "                              (exp_df['Information_content_rate'] >= spi) & \n",
    "                              (exp_df['matlab_maxfsize'] >= 20) &\n",
    "                              (exp_df['firing_range'] < 10)]\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['h_0_place_cell'] == 1) & \n",
    "                                      (control_df['Information_content_rate'] >= spi) & \n",
    "                                      (control_df['matlab_maxfsize'] >= 20) &\n",
    "                                      (control_df['firing_range'] < 10)]\n",
    "        exp_df_place = exp_df[(exp_df['h_0_place_cell'] == 1) & \n",
    "                              (exp_df['Information_content_rate'] >= spi) & \n",
    "                              (exp_df['matlab_maxfsize'] >= 20) &\n",
    "                              (exp_df['firing_range'] < 10)]\n",
    "\n",
    "    # Calculate numbers for pie charts\n",
    "    control_place = len(control_df_place)\n",
    "    control_non_place = len(control_df) - control_place\n",
    "    exp_place = len(exp_df_place)\n",
    "    exp_non_place = len(exp_df) - exp_place\n",
    "\n",
    "    # Z-Test for Two Proportions\n",
    "    control_successes = control_place  # Number of place cells in control\n",
    "    control_trials = len(control_df)   # Total pyramidal cells in control\n",
    "    exp_successes = exp_place          # Number of place cells in experimental\n",
    "    exp_trials = len(exp_df)           # Total pyramidal cells in experimental\n",
    "\n",
    "    # Proportions\n",
    "    p1 = control_successes / control_trials if control_trials > 0 else 0\n",
    "    p2 = exp_successes / exp_trials if exp_trials > 0 else 0\n",
    "    p_pooled = (control_successes + exp_successes) / (control_trials + exp_trials) if (control_trials + exp_trials) > 0 else 0\n",
    "\n",
    "    # Standard error and Z-test\n",
    "    if p_pooled == 0 or p_pooled == 1 or control_trials == 0 or exp_trials == 0:\n",
    "        z_stat = 0\n",
    "        p_value = 1.0  # No difference if proportions are 0 or 1, or no data\n",
    "    else:\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/control_trials + 1/exp_trials))\n",
    "        z_stat = (p1 - p2) / se if se != 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))  # Two-tailed test\n",
    "\n",
    "    # Data for pie charts\n",
    "    control_data = [control_place, control_non_place]\n",
    "    exp_data = [exp_place, exp_non_place]\n",
    "    labels = ['Place Cells', 'Non-Place Cells']\n",
    "    colors = ['blue', 'lightblue']\n",
    "    colors1 = ['cyan', 'lightcyan']\n",
    "\n",
    "    # Create pie charts\n",
    "    ax = axes\n",
    "    ax.pie(control_data, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(-1, 0))\n",
    "    ax.pie(exp_data, labels=labels, colors=colors1, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(1, 0))\n",
    "    \n",
    "    # Add title and p-value\n",
    "    ax.set_title(f'Session {session}\\np-value: {p_value:.4f}', pad=20)\n",
    "    \n",
    "    # Add group labels\n",
    "    ax.text(-1, 1.2, 'Control', ha='center')\n",
    "    ax.text(1, 1.2, 'Experimental', ha='center')\n",
    "\n",
    "#fig.savefig(fr'{base_folder}/Functional_number_of_placecells.eps', format='eps', bbox_inches='tight')\n",
    "#fig.savefig(fr'{base_folder}/Functional_number_of_placecells.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_loaded is already defined\n",
    "# Load Good units\n",
    "df_loaded = pd.read_pickle(r'Q:/sachuriga/CR_CA1_paper/tables/good_units_with_tsnLabels.pkl')\n",
    "len(df_loaded)\n",
    "df_good = df_loaded[df_loaded['unit_quality']==\"good\"]\n",
    "df_py = df_good[df_good['cell_type']==\"interneuron\"]\n",
    "df=df_py\n",
    "\n",
    "base_folder = r\"Q:/sachuriga/CR_CA1_paper/Results/functional_cell_type\"\n",
    "control_ids = ['65165', '65091', '63383', '66539', '65622']\n",
    "exp_ids = ['65588', '63385', '66538', '66537', '66922']\n",
    "sessions = [\"A\"]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "axes = axes\n",
    "\n",
    "for idx, session in enumerate(sessions):\n",
    "    # Filter for sessions\n",
    "    if session == \"Total\":\n",
    "        df_a = df\n",
    "\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['matlab_speedScores'] >= 0.3)]\n",
    "        exp_df_place = exp_df[(exp_df['matlab_speedScores'] >= 0.3)]\n",
    "    else:\n",
    "        df_a = df[df['session'] == session]\n",
    "        control_df = df_a[df_a['animal_id'].isin(control_ids)]\n",
    "        exp_df = df_a[df_a['animal_id'].isin(exp_ids)]\n",
    "        control_df_place = control_df[(control_df['matlab_speedScores'] >= 0.3)]\n",
    "        exp_df_place = exp_df[(exp_df['matlab_speedScores'] >= 0.3)]\n",
    "\n",
    "    # Calculate numbers for pie charts\n",
    "    control_place = len(control_df_place)\n",
    "    control_non_place = len(control_df) - control_place\n",
    "    exp_place = len(exp_df_place)\n",
    "    exp_non_place = len(exp_df) - exp_place\n",
    "\n",
    "    # Binomial test\n",
    "    control_successes = control_place\n",
    "    control_trials = len(control_df)\n",
    "    exp_successes = exp_place\n",
    "    exp_trials = len(exp_df)\n",
    "\n",
    "    # Control proportion as null hypothesis\n",
    "    p0 = control_successes / control_trials if control_trials > 0 else 0\n",
    "    result = stats.binomtest(exp_successes, exp_trials, p=p0, alternative='two-sided')\n",
    "    p_value = result.pvalue\n",
    "\n",
    "    # Data for pie charts\n",
    "    control_data = [control_place, control_non_place]\n",
    "    exp_data = [exp_place, exp_non_place]\n",
    "    labels = ['Speend Cells', 'Non-Speed Cells']\n",
    "    colors = ['red', 'lightcoral']  # instead of 'red', 'lightred'\n",
    "    colors1 = ['magenta', 'lightpink']  # instead of 'magenta', 'lightmagenta'\n",
    "\n",
    "    # Create pie charts\n",
    "    ax = axes\n",
    "    ax.pie(control_data, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(-1, 0))\n",
    "    ax.pie(exp_data, labels=labels, colors=colors1, autopct='%1.1f%%', \n",
    "           startangle=90, radius=0.8, center=(1, 0))\n",
    "    \n",
    "    # Add title and p-value\n",
    "    ax.set_title(f'Session {session}\\np-value: {p_value:.4f}', pad=20)\n",
    "    \n",
    "    # Add group labels\n",
    "    ax.text(-1, 1.2, 'Control', ha='center')\n",
    "    ax.text(1, 1.2, 'Experimental', ha='center')\n",
    "fig.savefig(fr'{base_folder}/Functional_number_of_speedcells.eps', format='eps', bbox_inches='tight')\n",
    "fig.savefig(fr'{base_folder}/Functional_number_of_speedcells.png', format='png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
