{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(r'Q:\\sachuriga\\Sachuriga_Python/quattrocolo-nwb4fp\\src')\n",
    "\n",
    "from neurochat.nc_data import NData\n",
    "from neurochat.nc_spike import NSpike\n",
    "from neurochat.nc_spatial import NSpatial\n",
    "import neurochat.nc_plot as nc_plot\n",
    "from neurochat.nc_lfp import NLfp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pynwb import NWBHDF5IO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pynapple as nap\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import sys\n",
    "import nwb4fp.analyses.maps as mapp\n",
    "from nwb4fp.analyses.examples.tracking_plot import plot_ratemap_ax,plot_path\n",
    "from nwb4fp.analyses.fields import separate_fields_by_laplace, separate_fields_by_dilation,find_peaks,separate_fields_by_laplace_of_gaussian,calculate_field_centers,distance_to_edge_function, remove_fields_by_area, map_pass_to_unit_circle,which_field,compute_crossings\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from nwb4fp.analyses import maps\n",
    "from nwb4fp.analyses.data import pos2speed,speed_filtered_spikes,load_speed_fromNWB,load_units_fromNWB,get_filed_num,Speed_filtered_spikes\n",
    "from nwb4fp.data.helpers import unit_location_ch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from nwb4fp.analyses.phase_precession import cl_corr\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.signal import hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "import nwb4fp.analyses.maps as mapp\n",
    "import nwb4fp.analyses.maps as mapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)  # 前后向滤波，避免相位移\n",
    "    return y\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_psd(freqs, psd, theta_range=(6, 12)):\n",
    "    \"\"\"\n",
    "    Plot the power spectral density with theta range highlighted.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(freqs, psd, 'b-', label='PSD')\n",
    "    \n",
    "    # Highlight theta range\n",
    "    plt.axvspan(theta_range[0], theta_range[1], color='gray', alpha=0.2, label='Theta range (6-12 Hz)')\n",
    "    \n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power Spectral Density')\n",
    "    plt.title('Power Spectral Density of Spike Train Autocorrelogram')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 50)  # Limit to 50 Hz for better visualization of theta range\n",
    "    plt.show()\n",
    "    \n",
    "def ThetaModulationIndex(spikes):\n",
    "    # Convert spikes to milliseconds\n",
    "    spikes_ms = spikes * 1e3\n",
    "    binSize_ms = 5\n",
    "    \n",
    "    # Initialize array for mean sums\n",
    "    sumsMean = np.zeros(100)\n",
    "    \n",
    "    # Process each spike\n",
    "    for i in range(len(spikes_ms)):\n",
    "        curSpike = spikes_ms[i]\n",
    "        low_edge = curSpike\n",
    "        upper_edge = curSpike + 500\n",
    "        # Create bin edges\n",
    "        edges = np.arange(low_edge, upper_edge + binSize_ms, binSize_ms)\n",
    "        # Count spikes in bins\n",
    "        N = np.histogram(spikes_ms, bins=edges)[0]\n",
    "        # Subtract 1 from first bin to not count the current spike\n",
    "        N[0] = N[0] - 1\n",
    "        # Add to running sum\n",
    "        sumsMean = sumsMean + N\n",
    "    \n",
    "    # Define bin ranges (converting time to bin indices)\n",
    "    throughBins = [int(50/binSize_ms) + 1, int(70/binSize_ms) + 1]\n",
    "    peakBins = [int(100/binSize_ms) + 1, int(140/binSize_ms) + 1]\n",
    "    \n",
    "    # Calculate means for through and peak periods\n",
    "    through = np.mean(sumsMean[throughBins[0]-1:throughBins[1]])\n",
    "    peak = np.mean(sumsMean[peakBins[0]-1:peakBins[1]])\n",
    "    \n",
    "    # Calculate theta modulation index\n",
    "    thIndex = (peak- through) / (through + peak)\n",
    "    \n",
    "    return thIndex\n",
    "\n",
    "# Example usage:\n",
    "# spikes = np.array([0.1, 0.2, 0.3, 0.4])  # example spike times in seconds\n",
    "# result = ThetaModulationIndex(spikes)\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def calculate_spike_theta_modulation(spike_times, fs=1000, freq_range=(0, 125), theta_range=(6, 12)):\n",
    "    \"\"\"\n",
    "    Calculate theta modulation index for a spike train and return PSD and ACG for plotting.\n",
    "    Excludes zero-lag from autocorrelation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spike_times : array-like\n",
    "        Array of spike timestamps in seconds\n",
    "    fs : float\n",
    "        Sampling frequency in Hz (default: 1000 Hz)\n",
    "    freq_range : tuple\n",
    "        Frequency range for total power calculation (default: 0-125 Hz)\n",
    "    theta_range : tuple\n",
    "        Frequency range for theta band (default: 6-12 Hz)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : Whether the spike train is theta modulated (index > 5)\n",
    "    float : Theta modulation index\n",
    "    array : Frequencies from PSD\n",
    "    array : Power spectral density values\n",
    "    array : Time lags for ACG\n",
    "    array : Autocorrelogram values\n",
    "    \"\"\"\n",
    "    #spike_train=spikes_time\n",
    "    # Convert spike times to binary spike train\n",
    "    try:\n",
    "        duration = spike_times[-1] - spike_times[0]\n",
    "        n_samples = int(duration * fs) + 1\n",
    "        spike_train = np.zeros(n_samples)\n",
    "        spike_indices = ((spike_times - spike_times[0]) * fs).astype(int)\n",
    "        spike_train[spike_indices] = 1\n",
    "        \n",
    "        ##Calculate autocorrelogram (full mode)\n",
    "        autocorr = signal.correlate(spike_train, spike_train, mode='full')\n",
    "        \n",
    "        # Exclude the zero-lag point (center of the autocorrelation)\n",
    "        center = len(autocorr) // 2\n",
    "        autocorr[center] = 0  # Set the zero-lag to 0\n",
    "        autocorr = gaussian_filter1d(autocorr, sigma=2)\n",
    "        # Take only positive lags for PSD calculation\n",
    "        autocorr_psd = autocorr[center + 1:]  # Start from t=1\n",
    "        \n",
    "        # Calculate power spectral density\n",
    "        freqs, psd = signal.welch(autocorr_psd, fs=fs, nperseg=min(1024, len(autocorr_psd)))\n",
    "        \n",
    "        # Find indices for frequency ranges\n",
    "        freq_mask_total = (freqs >= freq_range[0]) & (freqs <= freq_range[1])\n",
    "        freq_mask_theta = (freqs >= theta_range[0]) & (freqs <= theta_range[1])\n",
    "        \n",
    "        # Find peak theta frequency\n",
    "        theta_psd = psd[freq_mask_theta]\n",
    "        theta_freqs = freqs[freq_mask_theta]\n",
    "        peak_theta_idx = np.argmax(theta_psd)\n",
    "        peak_theta_freq = theta_freqs[peak_theta_idx]\n",
    "        \n",
    "        # Calculate power in 2 Hz window around peak theta frequency\n",
    "        theta_window_mask = (freqs >= (peak_theta_freq - 1)) & (freqs <= (peak_theta_freq + 1))\n",
    "        \n",
    "        # Calculate power ratios\n",
    "        total_power = np.sum(psd[freq_mask_total])\n",
    "        theta_power = np.sum(psd[theta_window_mask])\n",
    "        \n",
    "        # Calculate modulation index\n",
    "        modulation_index = (theta_power / total_power) * 100\n",
    "        \n",
    "        # Check if theta modulated (index > 5)\n",
    "        is_theta_modulated = modulation_index > 5\n",
    "        \n",
    "        # Prepare ACG for plotting (full range with positive and negative lags)\n",
    "        autocorr_full = signal.correlate(spike_train, spike_train, mode='full')\n",
    "        autocorr_full[center] = 0  # Exclude zero-lag\n",
    "        lags = np.arange(-center, center + 1) / fs  # Time lags in seconds\n",
    "        \n",
    "        return is_theta_modulated, modulation_index, freqs, psd, lags, autocorr_full\n",
    "    except Exception as e:\n",
    "        is_theta_modulated=False\n",
    "        modulation_index=0\n",
    "        freqs=0\n",
    "        psd=0\n",
    "        lags=0\n",
    "        autocorr_full=0\n",
    "\n",
    "def plot_acg_and_psd(lags, autocorr, freqs, psd, theta_range=(6, 12)):\n",
    "    \"\"\"\n",
    "    Plot the autocorrelogram (ACG) and power spectral density (PSD) with theta range highlighted.\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    \n",
    "    # Plot ACG\n",
    "    ax1.plot(lags, autocorr, 'b-', label='Autocorrelogram')\n",
    "    ax1.set_xlabel('Time Lag (s)')\n",
    "    ax1.set_ylabel('Correlation')\n",
    "    ax1.set_title('Spike Train Autocorrelogram (Zero-lag Excluded)')\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlim(-0.5, 0.5)  # Limit to ±0.5 seconds for better visualization\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot PSD\n",
    "    ax2.plot(freqs, psd, 'b-', label='PSD')\n",
    "    ax2.axvspan(theta_range[0], theta_range[1], color='gray', alpha=0.2, label='Theta range (6-12 Hz)')\n",
    "    ax2.set_xlabel('Frequency (Hz)')\n",
    "    ax2.set_ylabel('Power Spectral Density')\n",
    "    ax2.set_title('Power Spectral Density')\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xlim(0, 50)  # Limit to 50 Hz for better visualization of theta range\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with synthetic spike times\n",
    "\n",
    "# #spikes_time = np.sort(np.random.uniform(0, 10, 100))  # 100 random spikes over 10 seconds\n",
    "# is_modulated, mod_index, freqs, psd, lags, autocorr = calculate_spike_theta_modulation(spikes_time)\n",
    "\n",
    "# print(f\"Theta modulation index: {mod_index:.2f}\")\n",
    "# print(f\"Is theta modulated: {is_modulated}\")\n",
    "\n",
    "# # Plot both ACG and PSD\n",
    "# plot_acg_and_psd(lags, autocorr, freqs, psd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folser = r\"S:\\Sachuriga\\nwb\\test4neo\"\n",
    "temp_nwb = pd.read_pickle(fr\"Q:\\sachuriga\\CR_CA1_paper\\tables/functional_properties_with_python_measurements_with_stability.pkl\")\n",
    "nwb_files = np.unique(temp_nwb[\"session_id\"])\n",
    "all_temp_nwb = []\n",
    "temp_nwb[\"PS_p1\"] = None\n",
    "temp_nwb[\"spike_phase\"] = None\n",
    "temp_nwb[\"PS_cr1\"] = None\n",
    "temp_nwb[\"PS_slope1\"] = None\n",
    "temp_nwb[\"PS_phi1\"] = None\n",
    "temp_nwb[\"r1\"] = None\n",
    "temp_nwb[\"PS_p2\"] = None\n",
    "temp_nwb[\"PS_cr2\"] = None\n",
    "temp_nwb[\"PS_slope2\"] = None\n",
    "temp_nwb[\"PS_phi2\"] = None\n",
    "temp_nwb[\"r2\"] = None\n",
    "temp_nwb[ \"PS_p3\"] = None\n",
    "temp_nwb[ \"PS_cr3\"] = None\n",
    "temp_nwb[\"PS_slope3\"] = None\n",
    "temp_nwb[\"PS_phi3\"] = None\n",
    "temp_nwb[\"r3\"] = None\n",
    "temp_nwb[\"prefered_phase\"] = None\n",
    "temp_nwb[\"min_phase\"] = None\n",
    "temp_nwb[\"min_phase\"] = None\n",
    "temp_nwb[\"theta_index\"] = None\n",
    "temp_nwb[\"prefered_phase_smooth\"] = None\n",
    "temp_nwb[\"theta_caca\"] = None\n",
    "\n",
    "whole_phase=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in nwb_files:\n",
    "    \n",
    "    pd_temp = temp_nwb[temp_nwb[\"session_id\"]==file]\n",
    "    unit_nums = pd_temp['unit_name']\n",
    "    npdata = nap.load_file(fr\"{base_folser}/{file}\")\n",
    "    position_cord = load_speed_fromNWB(npdata['XY_mid_brain'])\n",
    "    lfp_times = npdata['lfp_times']\n",
    "    lfp = npdata['lfp_raw']\n",
    "    ## filter speed\n",
    "    raw_pos,combined_array, mask,speeds,smoothed_speed,filtered_speed = pos2speed(position_cord[:,0], # times\n",
    "                                position_cord[:,1], # x\n",
    "                                position_cord[:,2], # y\n",
    "                                filter_speed=True, \n",
    "                                min_speed = 0.1)\n",
    "    units=npdata['units']\n",
    "    spike_phase_couple=[]\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    p3 = []\n",
    "    cr1 = []\n",
    "    cr2 = []\n",
    "    cr3 = []\n",
    "    r1=[]\n",
    "    r2=[]\n",
    "    r3=[]\n",
    "    slope1 = []\n",
    "    slope2 = []\n",
    "    slope3 = []\n",
    "\n",
    "    phi1 = []\n",
    "    phi2 = []\n",
    "    phi3 = []\n",
    "\n",
    "    prefered_phase = []\n",
    "    firing_phase = []\n",
    "    min_phase = []\n",
    "    theta_index = []  \n",
    "    prefered_phase_smooth = []\n",
    "    theta_caca=[]\n",
    "\n",
    "    for unit_num in unit_nums:\n",
    "        #unit_num = unit_nums[82]\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "        ## filter spikes with speed\n",
    "        raw_pos = combined_array\n",
    "        # ## filter spikes with speed\n",
    "        # spk = speed_filtered_spikes(spikes_time,\n",
    "        #                             pos_cord[:,0], # times\n",
    "        #                             mask)\n",
    "        #for i in range(40):\n",
    "        # unit_idx = units[units['unit_name']==str(unit_num)].index[0]\n",
    "        \n",
    "        # spikes_time = np.array(units[unit_idx].as_series().index)\n",
    "        spikes_time =pd_temp.loc[(pd_temp[\"session_id\"] == file)& (pd_temp[\"unit_name\"] == unit_num), \"spike_times\"].values[0]\n",
    "\n",
    "        spikes_time = Speed_filtered_spikes(spikes_time,\n",
    "                            position_cord[:,0],mask)\n",
    "        #temp_caca = ThetaModulationIndex(spikes_time)\n",
    "        spk = speed_filtered_spikes(spikes_time,\n",
    "                                    position_cord[:,0])\n",
    "\n",
    "        is_modulated, mod_index, freqs, psd, lags, autocorr = calculate_spike_theta_modulation(spikes_time)\n",
    "        theta_index.append(mod_index)\n",
    "        #theta_caca.append(temp_caca)\n",
    "\n",
    "        # x_input = npdata['units']['x'][unit_idx]\n",
    "        # y_input = npdata['units']['y'][unit_idx]\n",
    "\n",
    "        #ch_num = unit_location_ch(x=x_input,y=y_input)\n",
    "        ch_num = pd_temp.loc[(pd_temp[\"session_id\"] == file)& (pd_temp[\"unit_name\"] == unit_num), \"ripple_ch_3std\"].values[0]\n",
    "        ## get rate_maps\n",
    "        maps = mapp.SpatialMap(box_size=[1.0, 1.0], \n",
    "                            bin_size=0.05,\n",
    "                            smoothing=0.1)\n",
    "\n",
    "        ## generate ratemaps\n",
    "        rate_map = maps.rate_map(raw_pos[:,1], \n",
    "                                raw_pos[:,2], \n",
    "                                raw_pos[:,0], \n",
    "                                spikes_time)\n",
    "\n",
    "        ## get_fileds with center of the files\n",
    "        fields = separate_fields_by_laplace_of_gaussian(rate_map, \n",
    "                                            minimum_field_area=9)\n",
    "        fiesld_afremoval = remove_fields_by_area(fields, minimum_field_area=9)\n",
    "        bc = calculate_field_centers(rate_map, fiesld_afremoval, center_method='center_of_mass')\n",
    "        v = get_filed_num(fiesld_afremoval)\n",
    "        original_field = fiesld_afremoval.copy()\n",
    "        filed_size = []\n",
    "        filde_name = []\n",
    "        y_c=[]\n",
    "        x_c=[]\n",
    "        field_name = v[0]\n",
    "        each_field = []\n",
    "        ## get the center of the fields\n",
    "        for field_nums in v:\n",
    "            y_c.append(bc[field_nums-1][0])\n",
    "            x_c.append(bc[field_nums-1][1])\n",
    "            filed_size.append(len(fiesld_afremoval[fiesld_afremoval==field_nums]))\n",
    "            filde_name.append(field_nums)\n",
    "            current_field = original_field.copy()\n",
    "            current_field[current_field != field_nums] = 0\n",
    "            each_field.append(current_field)\n",
    "\n",
    "        number = 0\n",
    "        ## crosssings\n",
    "        f = which_field(raw_pos[:,1],raw_pos[:,2],each_field[number],[1.0,1.0])\n",
    "        in_field = np.array(np.where(f==filde_name[number]))\n",
    "        indices = np.zeros(len(raw_pos[:,1]))\n",
    "        indices[in_field]=1\n",
    "        en,ex = compute_crossings(indices)\n",
    "        filter_loger_runs = ex-en\n",
    "        filtered_enter = en[filter_loger_runs>50]\n",
    "        filtered_exit = ex[filter_loger_runs>50]\n",
    "\n",
    "        restrcir_en=[]\n",
    "        restrcir_ex=[]\n",
    "\n",
    "        for i in range(len(filtered_enter)):\n",
    "            if np.mean(smoothed_speed[filtered_enter[i]:filtered_exit[i]]) >= 0.05:\n",
    "                restrcir_en.append(filtered_enter[i])\n",
    "                restrcir_ex.append(filtered_exit[i])\n",
    "\n",
    "        ## infields cords\n",
    "        pos_cord=raw_pos\n",
    "        xf = pos_cord[:,1][in_field]\n",
    "        yf = pos_cord[:,2][in_field]\n",
    "        tf = pos_cord[:,0][in_field]#\n",
    "        spk_in = spk[in_field-1]\n",
    "\n",
    "        x = pos_cord[:,1]\n",
    "        y = pos_cord[:,2]\n",
    "        t = pos_cord[:,0]\n",
    "\n",
    "        full_phase=[]\n",
    "        full_x=[]\n",
    "        full_r=[]\n",
    "        full_theta = []\n",
    "\n",
    "        fs = 1000\n",
    "        # 1. 带通滤波 (6-11 Hz)\n",
    "        lfp_filtered = bandpass_filter(lfp[:,ch_num], 5, 12, fs)\n",
    "        # 2. 使用希尔伯特变换计算瞬时相位\n",
    "        analytic_signal = hilbert(lfp_filtered)\n",
    "        # 计算相位（弧度）\n",
    "        phase_rad = np.angle(analytic_signal)\n",
    "        # 展开相位，避免-π到π的跳跃\n",
    "        phase_rad_unwrapped = np.unwrap(phase_rad)\n",
    "        # 转换为角度\n",
    "        phase_deg = phase_rad_unwrapped * (180 / np.pi)\n",
    "        theta_phase = phase_deg % 360 # 取模720，或者根据需求自定义\n",
    "\n",
    "        for slide_s,slide_stop in zip(restrcir_en, restrcir_ex):\n",
    "            #plot_path(x[slide_s:slide_stop],y[slide_s:slide_stop],t[slide_s:slide_stop],box_size=1,spike_times = spikes_time, ax=ax3)\n",
    "            r, theta, pdcd, pdmd = map_pass_to_unit_circle(x[slide_s:slide_stop],y[slide_s:slide_stop],t[slide_s:slide_stop], x_c[number]/20, y_c[number]/20, field=each_field[number], box_size=[1.0, 1.0])\n",
    "            phase_value=[]\n",
    "\n",
    "            temp_time = t[slide_s:slide_stop]\n",
    "            temp = spikes_time[spikes_time>t[slide_s]]\n",
    "            temp1 = temp[temp<=t[slide_stop-1]]\n",
    "            phase_value=[]\n",
    "            phase_temp = []\n",
    "            pdcd_temp = []\n",
    "            r_temp = []\n",
    "            \n",
    "            if len(temp1)>0:\n",
    "                for t1 in temp1:\n",
    "                    index_run = np.searchsorted(temp_time, t1)\n",
    "                    index_theta = np.searchsorted(lfp_times, t1)\n",
    "                    phase_value.append(theta_phase[index_theta])\n",
    "                    phase_temp.append(theta[index_run])\n",
    "                    r_temp.append(r[index_run])\n",
    "                    pdcd_temp.append(pdcd[index_run])\n",
    "\n",
    "                    full_r.append(r[index_run])\n",
    "                    full_phase.append(theta_phase[index_theta])\n",
    "                    full_x.append(pdcd[index_run])\n",
    "                    full_theta.append(theta[index_run])\n",
    "\n",
    "        # Convert the list to a NumPy array for element-wise operations\n",
    "        spike_phase = np.array(full_phase)\n",
    "\n",
    "        bins = 360  # 分成 20 个区间，每区间 18 度\n",
    "        hist, bin_edges = np.histogram(spike_phase, bins=bins, range=(0, 360))\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 每个区间的中心点\n",
    "\n",
    "        # Step 3: 应用高斯平滑，sigma = 45 度\n",
    "        # 因为 bin 的宽度是 18 度，sigma = 45 度需要换算成 bin 单位\n",
    "        sigma_in_bins = 45/ (360 / bins)  # 45 度除以每个 bin 的宽度\n",
    "        smoothed_hist = gaussian_filter1d(hist, sigma=sigma_in_bins, mode='wrap')  # 'wrap' 处理周期性边界\n",
    "        max_value = np.max(smoothed_hist)\n",
    "        peak_indices = np.where(smoothed_hist == max_value)[0]  # Find all indices with the max value\n",
    "        peak_phases = bin_centers[peak_indices]  # Corresponding phase values\n",
    "        preferred_phase = np.mean(peak_phases)\n",
    "\n",
    "        prefered_phase.append(preferred_phase)\n",
    "        firing_phase.append(np.max(hist))\n",
    "\n",
    "\n",
    "        print(fr\"prefers {preferred_phase}\")\n",
    "\n",
    "        # 步骤 1：将尖峰分到1°的bin中\n",
    "        bins = np.arange(0, 360, 1)  # 360个bin，从0°到359°\n",
    "        hist, bin_edges = np.histogram(full_phase, bins=bins, range=(0, 360))\n",
    "\n",
    "        sigma = 45  # 标准差45°\n",
    "        hist_smoothed = gaussian_filter1d(hist, sigma=sigma)  # 平滑\n",
    "        prefered_phase_smooth.append(bin_centers[np.argmax(smoothed_hist)])\n",
    "\n",
    "        # 步骤 3：找到最小尖峰数的相位\n",
    "        min_phase_idx = np.argmin(hist_smoothed)  # 最小值的索引\n",
    "        phase_zero = bins[min_phase_idx]  # 定义为相位零点\n",
    "        min_phase.append(phase_zero)\n",
    "\n",
    "        # 可选：调整相位（如果需要）\n",
    "        # 如果想把所有相位相对于 phase_zero 重新定义\n",
    "        adjusted_phases = (spike_phase + phase_zero) % 360\n",
    "\n",
    "        degrees_list = adjusted_phases\n",
    "        radians_list = []\n",
    "        full_x=np.array(full_x)\n",
    "\n",
    "        for deg in degrees_list:\n",
    "            radians_list.append(math.radians(deg))\n",
    "\n",
    "        radians_list=[]\n",
    "        full_x_stacked = np.hstack([full_x, full_x])\n",
    "        full_adjusted_phases = np.hstack([adjusted_phases, adjusted_phases+360])\n",
    "        for deg in adjusted_phases:\n",
    "            radians_list.append(math.radians(deg))\n",
    "            \n",
    "        spike_phase_couple.append(radians_list)\n",
    "        \n",
    "        whole_phase.append(radians_list) \n",
    "        mask_pos = (full_x_stacked <= 1) & (full_x_stacked >= -1)\n",
    "\n",
    "        #slope_range = np.tan(np.linspace(-0.0333, -0.00033, 1000))\n",
    "\n",
    "        try:\n",
    "            circ_lin_corr, p_value, best_slope, theta_0, max_R = cl_corr(full_x, np.array(radians_list), -0.5, -0.025, 0.05, 1000, return_pval=True)       \n",
    "            # circ_lin_corr, pp1, slope11, phi11, RR = cl_corr(full_x, np.array(radians_list), -0.5, -0.05, 0.05, 1000, return_pval=True)  \n",
    "   \n",
    "            # best_slope, max_R, theta_0 = circular_linear_fit(full_x, np.array(radians_list), slope_range)  \n",
    "            # p_value = permutation_test(full_x, np.array(radians_list), best_slope, max_R, n_permutations=1000)\n",
    "\n",
    "            first_idx = (full_x <= 0) & (full_x >= -1)\n",
    "            secound_idx = (full_x > 0) & (full_x <= 1)\n",
    "            print(fr\"p val:{p_value}\")\n",
    "            print(fr\"slope:{best_slope}\")\n",
    "            print(fr\"R:{max_R}\")\n",
    "\n",
    "            p1.append(p_value)\n",
    "            cr1.append(circ_lin_corr)\n",
    "            slope1.append(best_slope)\n",
    "            phi1.append(theta_0)\n",
    "            r1.append(max_R)\n",
    "        except Exception as e:\n",
    "            p1.append(np.nan)\n",
    "            cr1.append(np.nan)\n",
    "            slope1.append(np.nan)\n",
    "            phi1.append(np.nan)\n",
    "            r1.append(np.nan)\n",
    "        try:\n",
    "            circ_lin_corr, p_value, best_slope, theta_0, max_R = cl_corr(full_x[first_idx], np.array(radians_list)[first_idx], -0.5, -0.025, 0.05, 1000, return_pval=True)\n",
    "            # best_slope, max_R, theta_0 = circular_linear_fit(full_x[first_idx], np.array(radians_list)[first_idx], slope_range)  \n",
    "            # p_value = permutation_test(full_x[first_idx], np.array(radians_list)[first_idx], best_slope, max_R, n_permutations=1000)\n",
    "\n",
    "            print(fr\"p val:{p_value}\")\n",
    "            print(fr\"slope:{best_slope}\")\n",
    "            print(fr\"corr:{max_R}\")\n",
    "            p2.append(p_value)         # Appending results\n",
    "            cr2.append(circ_lin_corr)\n",
    "            slope2.append(best_slope)\n",
    "            phi2.append(theta_0)\n",
    "            r2.append(max_R)\n",
    "        except Exception as e:\n",
    "            p2.append(np.nan)         # Appending results\n",
    "            cr2.append(np.nan)\n",
    "            slope2.append(np.nan)\n",
    "            phi2.append(np.nan)\n",
    "            r2.append(max_R)\n",
    "        \n",
    "        try:\n",
    "            circ_lin_corr, p_value, best_slope, theta_0, max_R = cl_corr(full_x[secound_idx], np.array(radians_list)[secound_idx], -0.5, -0.025, 0.05, 1000, return_pval=True)\n",
    "\n",
    "            # best_slope, max_R, theta_0 = circular_linear_fit(full_x[secound_idx], np.array(radians_list)[secound_idx], slope_range)  \n",
    "            # p_value = permutation_test(full_x[secound_idx], np.array(radians_list)[secound_idx], best_slope, max_R, n_permutations=1000)\n",
    "\n",
    "            print(fr\"p val:{p_value}\")\n",
    "            print(fr\"slope:{best_slope}\")\n",
    "            print(fr\"corr:{max_R}\")\n",
    "            p3.append(p_value)         # Appending results\n",
    "            cr3.append(circ_lin_corr)\n",
    "            slope3.append(best_slope)\n",
    "            phi3.append(theta_0)\n",
    "            r3.append(max_R)\n",
    "        except Exception as e:\n",
    "\n",
    "            p3.append(np.nan)         # Appending results\n",
    "            cr3.append(np.nan)\n",
    "            slope3.append(np.nan)\n",
    "            phi3.append(np.nan)\n",
    "            r3.append(max_R)\n",
    "        \n",
    "\n",
    "    # # Assigning results to DataFrame (Correct approach using .loc)\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p1\"] = p1\n",
    "    # #temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"spike_phase\"] = pd.Series(spike_phase_couple)\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr1\"] = cr1\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope1\"] = slope1\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi1\"] = phi1\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"r1\"] = r1\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p2\"] = p2\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr2\"] = cr2\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope2\"] = slope2\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi2\"] = phi2\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"r2\"] = r2\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p3\"] = p3\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr3\"] = cr3\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope3\"] = slope3\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi3\"] = phi3\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"r3\"] = r3\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"prefered_phase\"] = prefered_phase\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"min_phase\"] = min_phase\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"min_phase\"] = firing_phase\n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"theta_index\"] = theta_index \n",
    "    # temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"prefered_phase_smooth\"] = prefered_phase_smooth\n",
    "\n",
    "        # Assigning results to DataFrame (Correct approach using .loc)\n",
    "    pd_temp [\"PS_p1\"] = p1\n",
    "    #temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"spike_phase\"] = pd.Series(spike_phase_couple)\n",
    "    pd_temp [\"PS_cr1\"] = cr1\n",
    "    pd_temp [\"PS_slope1\"] = slope1\n",
    "    pd_temp [\"PS_phi1\"] = phi1\n",
    "    pd_temp [\"r1\"] = r1\n",
    "    pd_temp [\"PS_p2\"] = p2\n",
    "    pd_temp [\"PS_cr2\"] = cr2\n",
    "    pd_temp [\"PS_slope2\"] = slope2\n",
    "    pd_temp [ \"PS_phi2\"] = phi2\n",
    "    pd_temp [\"r2\"] = r2\n",
    "    pd_temp [ \"PS_p3\"] = p3\n",
    "    pd_temp [\"PS_cr3\"] = cr3\n",
    "    pd_temp [\"PS_slope3\"] = slope3\n",
    "    pd_temp [\"PS_phi3\"] = phi3\n",
    "    pd_temp [\"r3\"] = r3\n",
    "    pd_temp [\"prefered_phase\"] = prefered_phase\n",
    "    pd_temp [\"min_phase\"] = min_phase\n",
    "    pd_temp [ \"min_phase\"] = firing_phase\n",
    "    pd_temp [\"theta_index\"] = theta_index \n",
    "    pd_temp [\"prefered_phase_smooth\"] = prefered_phase_smooth\n",
    "    #temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"theta_caca\"] = theta_caca\n",
    "    all_temp_nwb.append(pd_temp)\n",
    "\n",
    "# Concatenate all temp_nwb DataFrames into a single DataFrame\n",
    "combined_temp_nwb = pd.concat(all_temp_nwb, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a pickle file\n",
    "combined_temp_nwb.to_pickle(r\"Q:\\sachuriga\\CR_CA1_paper\\tables/functional_properties_with_python_measurements_pycirc.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_temp_nwb.to_pickle(r\"Q:\\sachuriga\\CR_CA1_paper\\tables/functional_properties_with_python_measurements_pycirc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_temp_nwb[\"spike_phase\"]=None\n",
    "combined_temp_nwb[\"spike_phase\"]=pd.Series(whole_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import circmean, circvar\n",
    "\n",
    "def circular_linear_fit(theta, x, slope_range):\n",
    "    \"\"\"\n",
    "    Perform circular-linear analysis to quantify theta phase precession.\n",
    "    \n",
    "    Parameters:\n",
    "    - theta: Array of instantaneous theta phases (in radians) for each spike.\n",
    "    - x: Array of spatial positions of the animal at spike times.\n",
    "    - slope_range: Array of slopes to test (in cycles/cm).\n",
    "    \n",
    "    Returns:\n",
    "    - best_slope: Slope that maximizes the resultant length (R).\n",
    "    - max_R: Maximum resultant length indicating model fit.\n",
    "    - theta_0: Phase offset for the best fit.\n",
    "    \"\"\"\n",
    "    def calculate_residuals(theta, x, slope, theta_0):\n",
    "        \"\"\"Calculate angular residuals for a given slope and phase offset.\"\"\"\n",
    "        theta_pred = (theta_0 + 2 * np.pi * slope * x) % (2 * np.pi)  # Predicted phase\n",
    "        residuals = (theta - theta_pred) % (2 * np.pi)\n",
    "        residuals = np.where(residuals > np.pi, residuals - 2 * np.pi, residuals)  # Wrap to [-π, π]\n",
    "        return residuals\n",
    "\n",
    "    def resultant_length(residuals):\n",
    "        \"\"\"Calculate resultant length (R) of angular residuals.\"\"\"\n",
    "        cos_sum = np.sum(np.cos(residuals))\n",
    "        sin_sum = np.sum(np.sin(residuals))\n",
    "        R = np.sqrt(cos_sum**2 + sin_sum**2) / len(residuals)\n",
    "        return R\n",
    "\n",
    "    best_R = -np.inf\n",
    "    best_slope = None\n",
    "    best_theta_0 = None\n",
    "\n",
    "    # Test each slope in the provided range\n",
    "    for slope in slope_range:\n",
    "        # Estimate theta_0 using circular mean of residuals\n",
    "        theta_pred = (2 * np.pi * slope * x) % (2 * np.pi)\n",
    "        residuals = (theta - theta_pred) % (2 * np.pi)\n",
    "        theta_0 = circmean(residuals, high=2*np.pi, low=0)\n",
    "        \n",
    "        # Calculate residuals and resultant length\n",
    "        residuals = calculate_residuals(theta, x, slope, theta_0)\n",
    "        R = resultant_length(residuals)\n",
    "        \n",
    "        # Update best fit if R is larger\n",
    "        if R > best_R:\n",
    "            best_R = R\n",
    "            best_slope = slope\n",
    "            best_theta_0 = theta_0\n",
    "\n",
    "    return best_slope, best_R, best_theta_0\n",
    "\n",
    "def permutation_test(theta, x, best_slope, best_R, n_permutations=1000):\n",
    "    \"\"\"\n",
    "    Perform permutation test to estimate statistical significance of the fit.\n",
    "    \n",
    "    Parameters:\n",
    "    - theta: Array of theta phases.\n",
    "    - x: Array of spatial positions.\n",
    "    - best_slope: Slope from the original fit.\n",
    "    - best_R: Resultant length from the original fit.\n",
    "    - n_permutations: Number of permutations for the test.\n",
    "    \n",
    "    Returns:\n",
    "    - p_value: P-value indicating significance of the fit.\n",
    "    \"\"\"\n",
    "    perm_R = []\n",
    "    for _ in range(n_permutations):\n",
    "        # Randomly permute theta values\n",
    "        theta_perm = np.random.permutation(theta)\n",
    "        slope, R, _ = circular_linear_fit(theta_perm, x, [best_slope])\n",
    "        perm_R.append(R)\n",
    "    \n",
    "    # Calculate p-value as proportion of permutations with R >= best_R\n",
    "    p_value = np.sum(np.array(perm_R) >= best_R) / n_permutations\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= nwb_files[74]\n",
    "\n",
    "pd_temp = temp_nwb[temp_nwb[\"session_id\"]==file]\n",
    "unit_nums = pd_temp['unit_name']\n",
    "npdata = nap.load_file(fr\"{base_folser}/{file}\")\n",
    "position_cord = load_speed_fromNWB(npdata['XY_mid_brain'])\n",
    "lfp_times = npdata['lfp_times']\n",
    "lfp = npdata['lfp_raw']\n",
    "## filter speed\n",
    "raw_pos,combined_array, mask,speeds,smoothed_speed,filtered_speed = pos2speed(position_cord[:,0], # times\n",
    "                            position_cord[:,1], # x\n",
    "                            position_cord[:,2], # y\n",
    "                            filter_speed=True, \n",
    "                            min_speed = 0.1)\n",
    "units=npdata['units']\n",
    "\n",
    "p1 = []\n",
    "p2 = []\n",
    "p3 = []\n",
    "cr1 = []\n",
    "cr2 = []\n",
    "cr3 = []\n",
    "\n",
    "slope1 = []\n",
    "slope2 = []\n",
    "slope3 = []\n",
    "\n",
    "phi1 = []\n",
    "phi2 = []\n",
    "phi3 = []\n",
    "\n",
    "prefered_phase = []\n",
    "firing_phase = []\n",
    "min_phase = []\n",
    "theta_index = []  \n",
    "prefered_phase_smooth = []\n",
    "\n",
    "for unit_num in unit_nums:\n",
    "    #unit_num = unit_nums[82]\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "    ## filter spikes with speed\n",
    "    raw_pos = combined_array\n",
    "    # ## filter spikes with speed\n",
    "    # spk = speed_filtered_spikes(spikes_time,\n",
    "    #                             pos_cord[:,0], # times\n",
    "    #                             mask)\n",
    "    #for i in range(40):\n",
    "    unit_idx = units[units['unit_name']==str(unit_num)].index[0]\n",
    "    spikes_time = np.array(units[unit_idx].as_series().index)\n",
    "    spikes_time = Speed_filtered_spikes(spikes_time,\n",
    "                        position_cord[:,0],mask)\n",
    "\n",
    "    spk = speed_filtered_spikes(spikes_time,\n",
    "                                position_cord[:,0])\n",
    "\n",
    "    is_modulated, mod_index, freqs, psd, lags, autocorr = calculate_spike_theta_modulation(spikes_time)\n",
    "    theta_index.append(mod_index)\n",
    "\n",
    "    x_input = npdata['units']['x'][unit_idx]\n",
    "    y_input = npdata['units']['y'][unit_idx]\n",
    "\n",
    "    ch_num = unit_location_ch(x=x_input,y=y_input)\n",
    "    ## get rate_maps\n",
    "    maps = mapp.SpatialMap(box_size=[1.0, 1.0], \n",
    "                        bin_size=0.05,\n",
    "                        smoothing=0.1)\n",
    "\n",
    "    ## generate ratemaps\n",
    "    rate_map = maps.rate_map(raw_pos[:,1], \n",
    "                            raw_pos[:,2], \n",
    "                            raw_pos[:,0], \n",
    "                            spikes_time)\n",
    "\n",
    "    ## get_fileds with center of the files\n",
    "    fields = separate_fields_by_laplace_of_gaussian(rate_map, \n",
    "                                        minimum_field_area=9)\n",
    "    fiesld_afremoval = remove_fields_by_area(fields, minimum_field_area=9)\n",
    "    bc = calculate_field_centers(rate_map, fiesld_afremoval, center_method='center_of_mass')\n",
    "    v = get_filed_num(fiesld_afremoval)\n",
    "    original_field = fiesld_afremoval.copy()\n",
    "    filed_size = []\n",
    "    filde_name = []\n",
    "    y_c=[]\n",
    "    x_c=[]\n",
    "    field_name = v[0]\n",
    "    each_field = []\n",
    "    ## get the center of the fields\n",
    "    for field_nums in v:\n",
    "        y_c.append(bc[field_nums-1][0])\n",
    "        x_c.append(bc[field_nums-1][1])\n",
    "        filed_size.append(len(fiesld_afremoval[fiesld_afremoval==field_nums]))\n",
    "        filde_name.append(field_nums)\n",
    "        current_field = original_field.copy()\n",
    "        current_field[current_field != field_nums] = 0\n",
    "        each_field.append(current_field)\n",
    "\n",
    "    number = 0\n",
    "    ## crosssings\n",
    "    f = which_field(raw_pos[:,1],raw_pos[:,2],each_field[number],[1.0,1.0])\n",
    "    in_field = np.array(np.where(f==filde_name[number]))\n",
    "    indices = np.zeros(len(raw_pos[:,1]))\n",
    "    indices[in_field]=1\n",
    "    en,ex = compute_crossings(indices)\n",
    "    filter_loger_runs = ex-en\n",
    "    filtered_enter = en[filter_loger_runs>50]\n",
    "    filtered_exit = ex[filter_loger_runs>50]\n",
    "\n",
    "    restrcir_en=[]\n",
    "    restrcir_ex=[]\n",
    "\n",
    "    for i in range(len(filtered_enter)):\n",
    "        if np.mean(smoothed_speed[filtered_enter[i]:filtered_exit[i]]) >= 0.05:\n",
    "            restrcir_en.append(filtered_enter[i])\n",
    "            restrcir_ex.append(filtered_exit[i])\n",
    "\n",
    "    ## infields cords\n",
    "    pos_cord=raw_pos\n",
    "    xf = pos_cord[:,1][in_field]\n",
    "    yf = pos_cord[:,2][in_field]\n",
    "    tf = pos_cord[:,0][in_field]#\n",
    "    spk_in = spk[in_field-1]\n",
    "\n",
    "    x = pos_cord[:,1]\n",
    "    y = pos_cord[:,2]\n",
    "    t = pos_cord[:,0]\n",
    "\n",
    "    full_phase=[]\n",
    "    full_x=[]\n",
    "    full_r=[]\n",
    "    full_theta = []\n",
    "\n",
    "    fs = 1000\n",
    "    # 1. 带通滤波 (6-11 Hz)\n",
    "    lfp_filtered = bandpass_filter(lfp[:,ch_num], 5, 12, fs)\n",
    "    # 2. 使用希尔伯特变换计算瞬时相位\n",
    "    analytic_signal = hilbert(lfp_filtered)\n",
    "    # 计算相位（弧度）\n",
    "    phase_rad = np.angle(analytic_signal)\n",
    "    # 展开相位，避免-π到π的跳跃\n",
    "    phase_rad_unwrapped = np.unwrap(phase_rad)\n",
    "    # 转换为角度\n",
    "    phase_deg = phase_rad_unwrapped * (180 / np.pi)\n",
    "    theta_phase = phase_deg % 360 # 取模720，或者根据需求自定义\n",
    "\n",
    "    for slide_s,slide_stop in zip(restrcir_en, restrcir_ex):\n",
    "        #plot_path(x[slide_s:slide_stop],y[slide_s:slide_stop],t[slide_s:slide_stop],box_size=1,spike_times = spikes_time, ax=ax3)\n",
    "        r, theta, pdcd, pdmd = map_pass_to_unit_circle(x[slide_s:slide_stop],y[slide_s:slide_stop],t[slide_s:slide_stop], x_c[number]/20, y_c[number]/20, field=each_field[number], box_size=[1.0, 1.0])\n",
    "        phase_value=[]\n",
    "\n",
    "        temp_time = t[slide_s:slide_stop]\n",
    "        temp = spikes_time[spikes_time>t[slide_s]]\n",
    "        temp1 = temp[temp<=t[slide_stop-1]]\n",
    "        phase_value=[]\n",
    "        phase_temp = []\n",
    "        pdcd_temp = []\n",
    "        r_temp = []\n",
    "        \n",
    "        if len(temp1)>0:\n",
    "            for t1 in temp1:\n",
    "                index_run = np.searchsorted(temp_time, t1)\n",
    "                index_theta = np.searchsorted(lfp_times, t1)\n",
    "                phase_value.append(theta_phase[index_theta])\n",
    "                phase_temp.append(theta[index_run])\n",
    "                r_temp.append(r[index_run])\n",
    "                pdcd_temp.append(pdcd[index_run])\n",
    "\n",
    "                full_r.append(r[index_run])\n",
    "                full_phase.append(theta_phase[index_theta])\n",
    "                full_x.append(pdcd[index_run])\n",
    "                full_theta.append(theta[index_run])\n",
    "\n",
    "    # Convert the list to a NumPy array for element-wise operations\n",
    "    spike_phase = np.array(full_phase)\n",
    "\n",
    "    bins = 360  # 分成 20 个区间，每区间 18 度\n",
    "    hist, bin_edges = np.histogram(spike_phase, bins=bins, range=(0, 360))\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # 每个区间的中心点\n",
    "\n",
    "    # Step 3: 应用高斯平滑，sigma = 45 度\n",
    "    # 因为 bin 的宽度是 18 度，sigma = 45 度需要换算成 bin 单位\n",
    "    sigma_in_bins = 5/ (360 / bins)  # 45 度除以每个 bin 的宽度\n",
    "    smoothed_hist = gaussian_filter1d(hist, sigma=sigma_in_bins, mode='wrap')  # 'wrap' 处理周期性边界\n",
    "    max_value = np.max(smoothed_hist)\n",
    "    peak_indices = np.where(smoothed_hist == max_value)[0]  # Find all indices with the max value\n",
    "    peak_phases = bin_centers[peak_indices]  # Corresponding phase values\n",
    "    preferred_phase = np.mean(peak_phases)\n",
    "\n",
    "    prefered_phase.append(preferred_phase)\n",
    "    firing_phase.append(np.max(hist))\n",
    "\n",
    "\n",
    "    print(fr\"prefers {preferred_phase}\")\n",
    "\n",
    "    # 步骤 1：将尖峰分到1°的bin中\n",
    "    bins = np.arange(0, 360, 1)  # 360个bin，从0°到359°\n",
    "    hist, bin_edges = np.histogram(full_phase, bins=bins, range=(0, 360))\n",
    "\n",
    "    sigma = 45  # 标准差45°\n",
    "    hist_smoothed = gaussian_filter1d(hist, sigma=sigma)  # 平滑\n",
    "    prefered_phase_smooth.append(bin_centers[np.argmax(smoothed_hist)])\n",
    "\n",
    "    # 步骤 3：找到最小尖峰数的相位\n",
    "    min_phase_idx = np.argmin(hist_smoothed)  # 最小值的索引\n",
    "    phase_zero = bins[min_phase_idx]  # 定义为相位零点\n",
    "    min_phase.append(phase_zero)\n",
    "\n",
    "    # 可选：调整相位（如果需要）\n",
    "    # 如果想把所有相位相对于 phase_zero 重新定义\n",
    "    adjusted_phases = (spike_phase + phase_zero) % 360\n",
    "\n",
    "    degrees_list = adjusted_phases\n",
    "    radians_list = []\n",
    "    full_x=np.array(full_x)\n",
    "\n",
    "    for deg in degrees_list:\n",
    "        radians_list.append(math.radians(deg))\n",
    "\n",
    "    radians_list=[]\n",
    "    full_x_stacked = np.hstack([full_x, full_x])\n",
    "    full_adjusted_phases = np.hstack([adjusted_phases, adjusted_phases+360])\n",
    "    for deg in adjusted_phases:\n",
    "        radians_list.append(math.radians(deg))\n",
    "    mask_pos = (full_x_stacked <= 1) & (full_x_stacked >= -1)\n",
    "\n",
    "\n",
    "    try:\n",
    "        #circ_lin_corr, ci, slope, phi0, RR = cl_corr(full_x[mask], np.array(radians_list)[mask], -0.4, -0.001, 0.05, 1000, return_pval=True)       \n",
    "        circ_lin_corr, pp1, slope11, phi11, RR = cl_corr(full_x, np.array(radians_list), -0.5, -0.01, 0.05, 1000, return_pval=True)       \n",
    "        first_idx = (full_x <= 0) & (full_x >= -1)\n",
    "        secound_idx = (full_x > 0) & (full_x <= 1)\n",
    "        print(fr\"p val:{pp1}\")\n",
    "        print(fr\"slope:{slope11}\")\n",
    "        print(fr\"corr:{circ_lin_corr}\")\n",
    "        p1.append(pp1)\n",
    "        cr1.append(circ_lin_corr)\n",
    "        slope1.append(slope11)\n",
    "        phi1.append(phi11)\n",
    "    except Exception as e:\n",
    "        p1.append(np.nan)\n",
    "        cr1.append(np.nan)\n",
    "        slope1.append(np.nan)\n",
    "        phi1.append(np.nan)\n",
    "    try:\n",
    "        circ_lin_corr, pp2, slope22, phi22, RR = cl_corr(full_x[first_idx], np.array(radians_list)[first_idx], -0.5, -0.01, 0.05, 1000, return_pval=True)\n",
    "        print(fr\"p val:{pp2}\")\n",
    "        print(fr\"slope:{slope22}\")\n",
    "        print(fr\"corr:{circ_lin_corr}\")\n",
    "        p2.append(pp2)         # Appending results\n",
    "        cr2.append(circ_lin_corr)\n",
    "        slope2.append(slope22)\n",
    "        phi2.append(phi22)\n",
    "    except Exception as e:\n",
    "        p2.append(np.nan)         # Appending results\n",
    "        cr2.append(np.nan)\n",
    "        slope2.append(np.nan)\n",
    "        phi2.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        circ_lin_corr, pp3, slope33, phi33, RR = cl_corr(full_x[secound_idx], np.array(radians_list)[secound_idx], -0.5, -0.01, 0.05, 1000, return_pval=True)\n",
    "        print(fr\"p val:{pp3}\")\n",
    "        print(fr\"slope:{slope33}\")\n",
    "        print(fr\"corr:{circ_lin_corr}\")\n",
    "        p3.append(pp3)         # Appending results\n",
    "        cr3.append(circ_lin_corr)\n",
    "        slope3.append(slope33)\n",
    "        phi3.append(phi33)\n",
    "    except Exception as e:\n",
    "\n",
    "        p3.append(np.nan)         # Appending results\n",
    "        cr3.append(np.nan)\n",
    "        slope3.append(np.nan)\n",
    "        phi3.append(np.nan)\n",
    "\n",
    "# Assigning results to DataFrame (Correct approach using .loc)\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p1\"] = p1\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr1\"] = cr1\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope1\"] = slope1\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi1\"] = phi1\n",
    "\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p2\"] = p2\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr2\"] = cr2\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope2\"] = slope2\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi2\"] = phi2\n",
    "\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_p3\"] = p3\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_cr3\"] = cr3\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_slope3\"] = slope3\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"PS_phi3\"] = phi3\n",
    "\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"prefered_phase\"] = prefered_phase\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"min_phase\"] = min_phase\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"min_phase\"] = firing_phase\n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"theta_index\"] = theta_index \n",
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, \"prefered_phase_smooth\"] = prefered_phase_smooth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nwb.loc[temp_nwb[\"session_id\"] == file, [\"cell_type\",\"theta_index\", \"PS_p1\", \"PS_slope1\"]] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb4fp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
